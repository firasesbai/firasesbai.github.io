<!DOCTYPE html>
<html lang="en">
  
  <!-- Cookie Consent CSS -->
  <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/cookieconsent@3/build/cookieconsent.min.css" />

  <!-- D3js -->
  <script src="https://d3js.org/d3.v7.min.js"></script>

<!-- MailerLite Universal -->
<script>
  (function(w,d,e,u,f,l,n){w[f]=w[f]||function(){(w[f].q=w[f].q||[])
  .push(arguments);},l=d.createElement(e),l.async=1,l.src=u,
  n=d.getElementsByTagName(e)[0],n.parentNode.insertBefore(l,n);})
  (window,document,'script','https://assets.mailerlite.com/js/universal.js','ml');
  ml('account', '1240462');
</script>
<!-- End MailerLite Universal --><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Data engineering 201: In-depth Guide - Part 2 | Firas Esbai</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Data engineering 201: In-depth Guide - Part 2" />
<meta name="author" content="Firas Esbai" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Deep dive into data ingestion and integration techniques, popular methods for data processing and transformation and comparison of different storage types" />
<meta property="og:description" content="Deep dive into data ingestion and integration techniques, popular methods for data processing and transformation and comparison of different storage types" />
<link rel="canonical" href="https://www.firasesbai.com/articles/2023/03/12/data-engineering-201-part-2.html" />
<meta property="og:url" content="https://www.firasesbai.com/articles/2023/03/12/data-engineering-201-part-2.html" />
<meta property="og:site_name" content="Firas Esbai" />
<meta property="og:image" content="https://www.firasesbai.com/assets/images/articles/12_data_warehouse_vs_data_lake_vs_data_lakehouse.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-03-12T00:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://www.firasesbai.com/assets/images/articles/12_data_warehouse_vs_data_lake_vs_data_lakehouse.png" />
<meta property="twitter:title" content="Data engineering 201: In-depth Guide - Part 2" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Firas Esbai"},"dateModified":"2023-03-12T00:00:00+00:00","datePublished":"2023-03-12T00:00:00+00:00","description":"Deep dive into data ingestion and integration techniques, popular methods for data processing and transformation and comparison of different storage types","headline":"Data engineering 201: In-depth Guide - Part 2","image":"https://www.firasesbai.com/assets/images/articles/12_data_warehouse_vs_data_lake_vs_data_lakehouse.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.firasesbai.com/articles/2023/03/12/data-engineering-201-part-2.html"},"url":"https://www.firasesbai.com/articles/2023/03/12/data-engineering-201-part-2.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://www.firasesbai.com/feed.xml" title="Firas Esbai" /><!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id='G-3ET85T3WD3'"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3ET85T3WD3');
</script>
</head>
<!-- insert favicons. use https://realfavicongenerator.net/ -->
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon.png?v=1">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png?v=1">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png?v=1">
  <link rel="manifest" href="/assets/favicon/site.webmanifest">
  <link rel="mask-icon" href="/assets/favicon/safari-pinned-tab.svg?v=1" color="#5bbad5">
  <link rel="shortcut icon" href="/assets/favicon/favicon.ico?v=1">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <!-- service Worker Logic -->	
  <script type="text/javascript" src="/js/service-worker/service-worker.js"></script>
  
  
  	<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id='G-3ET85T3WD3'"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3ET85T3WD3');
</script>

  
  
  <body><header class="site-header" role="banner">
   <div class="wrapper"><a class="site-title" href="/" style="font-size: 26px"> Firas Esbai </a><nav class="site-nav">
         <input type="checkbox" id="nav-trigger" class="nav-trigger" />
         <label for="nav-trigger">
            <span class="menu-icon">
               <svg viewBox="0 0 18 15" width="18px" height="15px">
                  <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
               </svg>
            </span>
         </label>
         <div class="trigger">
            <!--
               my_page.autogen is populated by the pagination logic for all pages
                               that are automatically created by the gem. Check for non-existence to exclude pagination pages from site.pages iterators
               -->
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
            
               
                  <a class="page-link" href="/blog/index.html" style="font-size: 20px">Blog</a>
               
            
               
                  <a class="page-link" href="/contact/" style="font-size: 20px">Contact</a>
               
            

         </div>
      </nav></div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <link rel="stylesheet" href="/assets/css/post.css">

<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <nav aria-label="breadcrumb">
    <p class="breadcrumb">
      <a href="/blog">Blog</a>
      
        
        
        > <a href="/categories/data-engineering">Data Engineering</a>
      
      > <span>Data engineering 201: In-depth Guide - Part 2</span>
    </p>
  </nav>

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Data engineering 201: In-depth Guide - Part 2</h1>
    <p class="post-meta"><time class="dt-published" datetime="2023-03-12T00:00:00+00:00" itemprop="datePublished">
        Mar 12, 2023 - 
      </time>
      
      <span class="reading-time" title="Estimated read time">
  
  17 min read
</span>
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name"> - Firas Esbai</span></span></p><p class="post-meta last-updated">
        Last updated:<time class="dt-modified" datetime="2025-05-18T00:00:00+00:00" itemprop="dateModified">
          May 18, 2025
        </time>
      </p></header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><em>This is part 2 of our in-depth article discussing the different stages of data flow inside an organisation.</em></p>

<p>We will discover how data in motion and data at rest is handled through different techniques and methods and the importance of choosing the right storage technology.</p>

<p>If you have missed the first part, you can find it <a href="https://www.firasesbai.com/articles/2023/03/11/data-engineering-201.html">here</a>.</p>

<p>So buckle up, folks! This is going to be a long ride. But don’t worry, it’s worth it. Grab a snack, get comfy, and let’s dive in!”</p>

<hr />

<h1> Contents </h1>
<ul id="markdown-toc">
  <li><a href="#ingestion" id="markdown-toc-ingestion">Ingestion</a></li>
  <li><a href="#transformation-batch-vs-streaming" id="markdown-toc-transformation-batch-vs-streaming">Transformation: Batch vs Streaming</a></li>
  <li><a href="#storage" id="markdown-toc-storage">Storage</a>    <ul>
      <li><a href="#oltp-vs-olap" id="markdown-toc-oltp-vs-olap">OLTP vs OLAP</a></li>
      <li><a href="#oltp-databases" id="markdown-toc-oltp-databases">OLTP Databases</a>        <ul>
          <li><a href="#sql-vs-nosql" id="markdown-toc-sql-vs-nosql">SQL vs NoSQL</a></li>
          <li><a href="#acid-vs-base" id="markdown-toc-acid-vs-base">ACID vs BASE</a></li>
        </ul>
      </li>
      <li><a href="#olap-databases" id="markdown-toc-olap-databases">OLAP Databases</a>        <ul>
          <li><a href="#data-warehouse" id="markdown-toc-data-warehouse">Data warehouse</a></li>
          <li><a href="#data-lake" id="markdown-toc-data-lake">Data lake</a></li>
          <li><a href="#data-lakehouse" id="markdown-toc-data-lakehouse">Data Lakehouse</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#recap" id="markdown-toc-recap">Recap</a></li>
  <li><a href="#resources" id="markdown-toc-resources">Resources</a></li>
</ul>
<hr />

<h2 id="ingestion">Ingestion</h2>

<p><strong>ETL (Extract, Transform, Load)</strong> and <strong>ELT (Extract, Load, Transform)</strong> are both data integration techniques used to move data from multiple sources to a single destination, such as a data warehouse or a data lake (more on this later in the Storage section).</p>

<p>In ETL, data is extracted from source systems, transformed into a format suitable for the destination system, and then loaded into the destination system. 
The transformation is actually done in what is often referred to as a staging area. 
This approach is typically used in traditional data warehousing systems. 
Any data you load into your data warehouse must be transformed into a relational format before the data warehouse can ingest it. 
As a part of this data transformation process, data mapping may also be necessary to combine multiple data sources based on correlating information. 
In addition, ETL can help with data privacy and compliance by cleaning sensitive and secure data even before loading into the data warehouse.</p>

<p>ETL processes come in two primary forms: <strong>Initial</strong> and <strong>Incremental</strong>. An <strong>Initial ETL</strong> is typically a one-time, comprehensive data migration performed when a data warehouse is first launched. It loads all necessary historical data, including what’s definitely and potentially needed for business intelligence and analytics. This process might need to be repeated if the data warehouse encounters significant issues. In contrast, <strong>Incremental ETL</strong> handles the ongoing updates to the data warehouse by processing only new, modified, or deleted data. Common patterns for incremental ETL include <strong>append</strong>, which adds new data; <strong>in-place update</strong>, which modifies existing records; <strong>complete replacement</strong>, which refreshes entire datasets; and <strong>rolling append</strong>, which maintains a specific historical window of data.</p>

<p>In ELT on the other hand, data is first extracted from source systems and loaded into the destination system in its raw form, where it is then transformed into the desired format. 
This approach is typically used in big data environments, where the target system, such as a data lake, is designed to handle large amounts of unstructured and semi-structured data and can perform the transformations in parallel.</p>

<p>Rather than obsessing over this ETL vs ELT cage fight, just try to take away the following:</p>

<p>Sometimes you may want to optimize/reshape your data sooner (because you know that’s how everyone wants to use it). 
Other times, you want to leave the schema flexible (and just let the user’s queries/views do the work) to avoid having to maintain lots of tables/views/jobs.</p>

<h2 id="transformation-batch-vs-streaming">Transformation: Batch vs Streaming</h2>

<p><strong>Batch</strong> and <strong>Stream</strong> processing are two popular methods for data processing and transformation.</p>

<p>In batch processing, we wait for a certain amount of raw data to “pile up” before running an ETL job. 
Typically this means data is between an hour to a few days old before it is made available for analysis. 
Batch ETL jobs will typically be run on a set schedule (e.g. every 24 hours), or in some cases once the amount of data reaches a certain threshold.
You should lean towards batch processing when:</p>
<ul>
  <li>Data freshness is not a mission-critical issue</li>
  <li>You are working with large datasets and are running a complex algorithm that requires access to the entire batch – e.g., sorting the entire dataset</li>
  <li>You get access to the data in batches rather than in streams</li>
  <li>When you are joining tables in relational databases</li>
</ul>

<p>In stream processing, we process data as soon as it arrives in the storage layer – which would often also be very close to the time it was generated (although this would not always be the case). 
This would typically be in sub-second timeframes, so that for the end user the processing happens in real-time. 
These operations would typically not be stateful, or would only be able to store a ‘small’ state, so would usually involve a relatively simple transformation or calculation.</p>

<p>For example, events from an IoT device where each event is processed individually is stateless because we don’t maintain any state or knowledge of the previous events. On the other hand, a stateful example would be calculating the volume of a particular product sold in a particular time interval like an hour for an e-commerce application.</p>

<p>Another alternative is <strong>micro-batch</strong> processing. 
In micro-batch processing, we run batch processes on much smaller accumulations of data – typically less than a minute’s worth of data. 
This means data is available in near real-time. 
In practice, there is little difference between micro-batching and stream processing, and the terms would often be used interchangeably in data architecture descriptions and software platform descriptions.
Microbatch processing is useful when we need very fresh data, but not necessarily real-time – meaning we can’t wait an hour or a day for a batch processing to run, but we also don’t need to know what happened in the last few seconds. 
Example scenarios could include web analytics (clickstream) or user behavior.</p>

<p>In general, any application cannot run for an infinite amount of time even if we want them to do that, for two practical reasons:</p>
<ol>
  <li>Applications often suffer system failures or cluster crashes.</li>
  <li>Systems sometimes need to be brought down for periodic maintenance.</li>
</ol>

<p>Therefore, we want the application to recover gracefully when this happens. This is where checkpointing comes into picture as a fault tolerance mechanism. It involves periodically saving the state of your stream processing application to durable storage. This saved state, or “checkpoint,” allows the system to recover and resume processing from the point of the last successful checkpoint. This prevents data loss and ensures that processing can continue with minimal interruption and without reprocessing the entire data stream. When recovering from a checkpoint, the system might however process some data again. This requires the processing logic to be <strong>idempotent</strong>, which means that reprocessing the same data multiple times won’t cause unintended side effects or inconsistencies in the final results.</p>

<p>In real-world streaming scenarios, data doesn’t always arrive in perfect temporal order due to network latency, processing delays in upstream systems, or other unforeseen issues. If these late-arriving records are simply ignored, the results of windowed computations can be incomplete and inaccurate. <strong>Watermarking</strong> is a common approach for handling late data. A watermark is a heuristic that estimates how far behind the current processing time the event stream is likely to be. The system uses this watermark to determine when it’s “safe” to finalize a window, assuming that no more data for that window is expected to arrive. Late data arriving after the watermark needs to be handled using other strategies. One way is to route it to another system, usually referred to as a Dead-Letter Queue, for further analysis or potential reprocessing in a batch-oriented manner. This prevents late data from indefinitely delaying the processing of subsequent events.</p>

<h2 id="storage">Storage</h2>

<p>Two different types of data are used today in an organization; <strong>Operational</strong> and <strong>Analytical</strong>. 
Both operational and analytical data are important for organizations, but they serve different purposes and are used in different ways.</p>

<ul>
  <li>​​Operational data refers to the data that is used in day-to-day business operations to support critical functions such as sales, marketing, and customer service. Operational data is often used to support short-term decision making and is focused on current and immediate needs.</li>
  <li>Analytical data, on the other hand, is used for long-term strategic decision making. Analytical data is used to support trend analysis, business intelligence, and other data-driven decision making processes.</li>
</ul>

<h3 id="oltp-vs-olap">OLTP vs OLAP</h3>

<p><strong>OLTP (Online Transaction Processing)</strong> and <strong>OLAP (Online Analytical Processing)</strong> are two different types of data processing systems that are often used to manage operational and analytical data, respectively.</p>

<p>OLTP</p>
<ul>
  <li>OLTP systems are used to process operational data and are designed to support rapid data insertion, updates, and retrievals.</li>
  <li>Make sure that the systems can keep up with high volumes of transactions but often very small and fast in nature (e.g. online banking, FinTech application).</li>
</ul>

<p>OLAP</p>
<ul>
  <li>OLAP systems are used to process analytical data and are designed to support large-scale data analysis.</li>
  <li>Make sure that you can crunch through millions or billions of rows of data for your complex and large theories, where they need to run some fancy aggregation or calculations for data Analytics purposes.</li>
</ul>

<p><strong><em>Example: Online Store</em></strong></p>

<p>OLTP</p>
<ul>
  <li>Store user data, passwords, previous transactions, find user, change its name,… basically perform INSERT, UPDATE, DELETE operations</li>
  <li>Store actual products, their associated prices</li>
</ul>

<p>OLAP</p>
<ul>
  <li>Find out the “total money spent by all users”</li>
  <li>Find out “what is the most sold product”</li>
</ul>

<h3 id="oltp-databases">OLTP Databases</h3>

<h4 id="sql-vs-nosql">SQL vs NoSQL</h4>

<p>OLTP databases can use either <strong>SQL (Structured Query Language)</strong> or <strong>NoSQL (Not only SQL)</strong> technologies.</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th style="text-align: center">SQL Database</th>
      <th style="text-align: center">NoSQL Database</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Data storage model</strong></td>
      <td style="text-align: center">Tables with fixed rows and columns</td>
      <td style="text-align: center">Document: JSON Documents <br /> Key-value: key-value pairs <br /> Wide-Columns: Tables with rows and dynamic columns <br /> Graph</td>
    </tr>
    <tr>
      <td><strong>Development history</strong></td>
      <td style="text-align: center">Developed in the 1970s with a focus on reducing data duplication</td>
      <td style="text-align: center">Developed in the late 2000s with a focus on scaling and allowing for rapid application change driven by agile and DevOps practices</td>
    </tr>
    <tr>
      <td><strong>Primary purpose</strong></td>
      <td style="text-align: center">General purpose</td>
      <td style="text-align: center">Document: general purpose <br /> Key-value: large amounts of data with simple lookup queries <br /> Wide-column: large amounts of data with predictable query patterns <br /> Graph: analyzing and traversing relationships between connected data</td>
    </tr>
    <tr>
      <td><strong>Schema</strong></td>
      <td style="text-align: center">Rigid</td>
      <td style="text-align: center">Flexible (Implicit schema!, querying time)</td>
    </tr>
    <tr>
      <td><strong>Scaling</strong></td>
      <td style="text-align: center">Vertical (scale-up with a larger server)</td>
      <td style="text-align: center">Horizontal (scale-out across commodity servers)</td>
    </tr>
    <tr>
      <td><strong>Joins</strong></td>
      <td style="text-align: center">Typically required</td>
      <td style="text-align: center">Typically not required</td>
    </tr>
  </tbody>
</table>

<p style="text-align:center;">Table 1: SQL vs NoSQL Databases</p>

<p>SQL databases are based on a relational model and use a structured data model, where data is organized into tables, rows, and columns. 
This makes it easy to enforce data constraints, such as unique keys, and ensures data consistency. 
They are well tested and proven, and they have a long history of use in OLTP systems. 
This makes them a reliable choice for OLTP systems. 
However, SQL databases can be complex to set up and maintain and can be challenging to scale, particularly for large OLTP systems that require horizontal scalability and the rigid schema of SQL databases can make it difficult to accommodate changing requirements or new data types.</p>

<p>NoSQL databases on the other hand are designed for horizontal scalability, which makes them well suited for OLTP systems that need to scale to handle large amounts of data and users. 
In addition, they use a variety of data models which makes them more flexible than SQL databases. 
This allows NoSQL databases to better handle unstructured data and changing data requirements. 
However , NoSQL databases may not provide the same level of transactional consistency as SQL databases, which can result in data inconsistencies. 
Plus they can be complex to set up and maintain as well, even though this can be addressed since they are designed to work well in cloud environments, which makes them a good choice for OLTP systems that need to scale quickly and elastically.</p>

<h4 id="acid-vs-base">ACID vs BASE</h4>

<p>We kept mentioning <strong>transactional consistency</strong> and you might be wondering what is it?</p>

<p>A transaction is a sequence of operations performed (using one or more SQL statements) on a database as a single logical unit of work. 
For relational databases, transactions have the following four standard properties, usually referred to by the acronym <strong>ACID</strong>.</p>

<ul>
  <li><strong>Atomicity</strong> − ensures that all operations within the work unit are completed successfully. Otherwise, the transaction is aborted at the point of failure and all the previous operations are rolled back to their former state.</li>
  <li><strong>Consistency</strong> − ensures that the database properly changes states upon a successfully committed transaction.</li>
  <li><strong>Isolation</strong> − enables transactions to operate independently of and transparent to each other. Executing transactions concurrently has the same results as if the transactions were executed serially.</li>
  <li><strong>Durability</strong> − ensures that the result or effect of a committed transaction persists in case of a system failure.</li>
</ul>

<p><strong>BASE</strong> on the other hand is often used to describe the properties of NoSQL databases. It stands for:</p>
<ul>
  <li><strong>Basically available</strong> - the system guarantees availability.</li>
  <li><strong>Soft state</strong> - the state of the system may change over time, even without input.</li>
  <li><strong>Eventual consistency</strong> - the system will become consistent over a period of time, given that the system doesn’t receive input during that period.</li>
</ul>

<p>ACID databases prioritize consistency over availability—the whole transaction fails if an error occurs in any step within the transaction. In contrast, BASE databases prioritize availability over consistency. Instead of failing the transaction, users can access inconsistent data temporarily.</p>

<h3 id="olap-databases">OLAP Databases</h3>

<p>In this section we will discuss two important components that are used for advanced analysis and decision-making; <strong>data warehouses</strong> and <strong>data lakes</strong>.</p>

<h4 id="data-warehouse">Data warehouse</h4>

<p>A data warehouse is a centralized repository for storing and managing large amounts of data from various sources. 
Data warehouses are designed to support business intelligence (BI) and analytics applications, by providing a single source of data that can be queried, analyzed, and used to make informed decisions. 
The following are the key characteristics of a data warehouse:</p>

<ul>
  <li><em>Integration</em> - Data warehouses integrate data from multiple sources, such as transactional systems, log files, and external data sources, into a single, unified view.</li>
  <li><em>Scalability</em> - Data warehouses are designed to handle large amounts of data, which can grow over time.</li>
  <li><em>Data Modeling</em> - Data warehouses use a specific data model, such as the star or snowflake schema, to organize data and make it easier to query and analyze.</li>
  <li><em>Historical data</em> - Data warehouses store historical data, allowing users to analyze trends and changes over time.</li>
  <li><em>Performance optimization</em> - Data warehouses are optimized for fast querying and analysis, by using techniques such as indexing, materialized views, and aggregations.</li>
  <li><em>Data Cleansing</em> - Data warehouses often include data cleansing and normalization to ensure that data is consistent and accurate.</li>
  <li><em>Security and access control</em> - Data warehouses have robust security and access control features to ensure that sensitive data is protected and only authorized users have access to it.</li>
</ul>

<p>The explosion of big data, including the growth of structured, semi-structured, and unstructured data, made it increasingly difficult for traditional data warehouses to store and process all the data being generated. 
In addition, Traditional data warehouses required expensive hardware and software to store and process data. 
The cost of these solutions made it difficult for organizations to store all their data, which led to the adoption of data lakes as a more cost-effective alternative.</p>

<h4 id="data-lake">Data lake</h4>

<p>A data lake is a centralized repository that stores large amounts of raw, structured and unstructured data. The data is stored in its native format and can be accessed, processed, and analyzed later as needed. 
The following are the key characteristics of a data lake:</p>

<ul>
  <li><em>Flexibility</em> - Data lakes allow organizations to store a wide variety of data types and formats, including structured, semi-structured, and unstructured data, without having to worry about pre-defining schemas.</li>
  <li><em>Scalability</em> - Data lakes are designed to handle very large amounts of data, which can grow over time.</li>
  <li><em>Cost-effectiveness</em> - Data lakes are often implemented on low-cost, commodity hardware</li>
  <li><em>Raw data preservation</em> - Data lakes preserve raw data, allowing organizations to perform in-depth analysis and retain the original data for future use.</li>
  <li><em>Decentralized processing</em> - Data lakes can be used to distribute processing tasks across multiple nodes in a network, allowing for increased processing speed and scalability.</li>
  <li><em>Self-service analytics</em> - Data lakes allow business users and data scientists to perform their own data analysis, without having to rely on IT or data engineering teams.</li>
  <li><em>Integration with big data tools</em> - Data lakes can be integrated with big data tools, such as Apache Spark and Apache Flink, allowing organizations to perform complex data processing and analysis tasks.</li>
</ul>

<p>The following table summarizes the differences between data warehouse and data lake.</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th style="text-align: left">Data Warehouse</th>
      <th style="text-align: left">Data Lake</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Data</td>
      <td style="text-align: left">structured, processed</td>
      <td style="text-align: left">structured, semi structured, unstructured, raw</td>
    </tr>
    <tr>
      <td>Processing</td>
      <td style="text-align: left">schema-on-write</td>
      <td style="text-align: left">schema-on-read</td>
    </tr>
    <tr>
      <td>Storage</td>
      <td style="text-align: left">expensive for large data volumes</td>
      <td style="text-align: left">designed for low-cost storage</td>
    </tr>
    <tr>
      <td>Agility</td>
      <td style="text-align: left">less agile, fixed configuration</td>
      <td style="text-align: left">highly agile, configurable as needed</td>
    </tr>
    <tr>
      <td>Security</td>
      <td style="text-align: left">mature</td>
      <td style="text-align: left">maturing</td>
    </tr>
    <tr>
      <td>Users</td>
      <td style="text-align: left">business professionals</td>
      <td style="text-align: left">data scientists</td>
    </tr>
  </tbody>
</table>

<p style="text-align:center;">Table 2: Data Warehouse vs Data Lake</p>

<p>As organizations move data infrastructure to the cloud, the choice of data warehouse vs. data lake, or the need for complex integrations between the two, is less of an issue. 
It is becoming natural for organizations to have both, and move data flexibly from lakes to warehouses to enable business analysis.</p>

<p>Here is a list of some known cloud-based solutions from different cloud providers:</p>

<p>Cloud data warehousing solutions</p>
<ul>
  <li><em>Amazon Redshift</em> - a fully-managed, analytical data warehouse that can handle petabyte-scale data, and enable querying it in seconds.</li>
  <li><em>Google BigQuery</em> - an enterprise-grade cloud-native data warehouse, which runs fast interactive and ad-hoc queries on datasets of petabyte-scale.</li>
</ul>

<p>Cloud data lake solutions</p>
<ul>
  <li><em>Amazon S3</em> - an object storage platform built to store and retrieve any amount of data from any data source, and designed for 99.999999999% durability.</li>
  <li><em>Azure Blob Storage</em> - stores billions of objects in hot, cool, or archive tiers, depending on how often data is accessed. Data ranges from structured (converted to object form) to any unstructured format - images, videos, audio, documents.</li>
</ul>

<p>The data lake architecture was introduced as a solution to some challenges of data warehousing with the rise of big data offering the ability to store and process big data in a cost-effective and scalable manner. 
However, it had its own set of challenges, such as the lack of reliability and transactional consistency and the complex data quality problems making it difficult for GDPR compliance and to use for critical business decisions.</p>

<p>Can we get the best of both worlds without the complexity of managing both a data lake and a data warehouse or perhaps multiple ones?</p>

<h4 id="data-lakehouse">Data Lakehouse</h4>

<p>A data Lakehouse is a new, open architecture that combines the best elements of data lakes and data warehouses. 
Data Lakehouses are enabled by a new system design: implementing similar data structures and data management features to those in a data warehouse directly on top of low cost cloud storage in open formats.</p>

<figure>
  <img src="/assets/images/articles/12_data_warehouse_vs_data_lake_vs_data_lakehouse.png" alt="architecture diagrams comparing data warehouse, data lake and data lakehouse" />
  <figcaption>Figure 1: Data Warehouse vs Data Lake vs Data Lakehouse - <a href="https://www.databricks.com/glossary/data-lakehouse">Image Source</a></figcaption>
</figure>

<p>Some data management solutions such as <a href="https://delta.io/">Delta Lake</a>, which is an implementation of Data Lakehouse from Databricks, offer the ability to store and process big data in a reliable and consistent manner, while also providing the scalability and cost savings of a data lake.</p>

<p>The data lakehouse is a relatively new concept and is still evolving, but it has the potential to become an important technology for big data processing and analysis in the future.</p>

<p>With this we have reached the end of this post, I hope you enjoyed it!</p>

<h2 id="recap">Recap</h2>

<p>In this article, we went through some popular patterns such as ETL vs ELT and stream vs batch processing that are used in data ingestion and transformation and where they can be applied. 
Then we discussed the different types of data storage and some concrete implementations of them in the cloud and how they fit in an organization based on its requirements, data maturity and purpose.</p>

<p><em>Happy learning!</em></p>

<h2 id="resources">Resources</h2>

<p><a href="https://martinfowler.com/articles/data-mesh-principles.html">https://martinfowler.com/articles/data-mesh-principles.html</a></p>

<p><a href="https://www.jie-tao.com/delta-lake-step-by-step1/">https://www.jie-tao.com/delta-lake-step-by-step1/</a></p>

<p><a href="https://www.databricks.com/blog/2020/01/30/what-is-a-data-lakehouse.html">https://www.databricks.com/blog/2020/01/30/what-is-a-data-lakehouse.html</a></p>

<p><a href="https://delta.io/">https://delta.io/</a></p>

<p><a href="https://aws.amazon.com/compare/the-difference-between-acid-and-base-database/">https://aws.amazon.com/compare/the-difference-between-acid-and-base-database/</a></p>

  </div>

  <hr>
<br>
<div class="ml-embedded" data-form="T82iSQ"></div>

  <br>
<hr>
<br>
<div id="relatedPosts">
   <div class="post-header bg-">
      <h1 class="page-heading">Further Reading</h1>
   </div>
   
   
   
   
   
    
    
    
   
    
    <div>
      <h3><a href="/articles/2025/10/24/serverless-architecture-for-data-engineering.html">Serverless Architecture for Data Engineering</a></h3>
    </div>
    
    
   
   
    
    
    
   
    
    <div>
      <h3><a href="/articles/2025/10/10/apache-spark-101.html">101 Apache Spark Cheatsheet</a></h3>
    </div>
    
    
   
   
    
    
    
   
    
   
    
    
    
   
    
    <div>
      <h3><a href="/articles/2025/09/15/apache-kafka-101.html">101 Apache Kafka Cheatsheet</a></h3>
    </div>
    
    
   
   
    
    
    
   
    
    <div>
      <h3><a href="/articles/2025/09/08/apache-airflow-101.html">101 Apache Airflow Cheatsheet</a></h3>
    </div>
    
    
        
</div>

  
    
<hr>
<br>
<div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://firasesbai.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  

  <a class="u-url" href="/articles/2023/03/12/data-engineering-201-part-2.html" hidden></a>
</article>
      </div>
    </main><link rel="stylesheet" href="/assets/css/footer.css">
 
<footer class="site-footer h-card">
   <data class="u-url" href="/"></data>
   <div class="wrapper">
      <div class="footer-col-wrapper">
         <div class="footer-col footer-col-1" style="text-align: left;"><ul class="social-media-list"><li><a href="https://www.firasesbai.com/feed.xml"><svg class="svg-icon orange"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg><span> Subscribe</span></a></li><li><a href="https://www.linkedin.com/in/firas-esbai"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">firas-esbai</span></a></li><li><a href="https://github.com/firasesbai"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">firasesbai</span></a></li></ul></div>
         <div class="footer-col footer-col-2" style="text-align: right;">
            <ul class="legal-list" style="list-style-type: none; padding: 0;">
               <li><a href="/archive/">Archive</a></li>
               <li><a href="/privacy-policy/">Privacy Policy</a></li>
               <li><a href="/terms/">Terms and Conditions</a></li>
            </ul>
         </div>
      </div>
      <div style="text-align: center; margin-top: 10px;">
         
            <p class="p-name">Copyright &copy; 2025 Firas Esbai.</p>
            
      </div>
   </div>
</footer><!-- Cookie Consent Logic -->	
	<script src="https://cdn.jsdelivr.net/npm/cookieconsent@3/build/cookieconsent.min.js" data-cfasync="false"></script>
	<script src="/js/cookie-consent-script.js" type="text/javascript"> </script>

  </body>

</html>