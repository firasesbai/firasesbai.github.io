<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://www.firasesbai.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.firasesbai.com/" rel="alternate" type="text/html" /><updated>2025-01-03T18:35:17+00:00</updated><id>https://www.firasesbai.com/feed.xml</id><title type="html">Firas Esbai</title><subtitle>Firas Esbai's Lifelong Learning Journey.
</subtitle><author><name>Firas Esbai</name></author><entry><title type="html">Level Up Your SQL Skills As a Data Engineer</title><link href="https://www.firasesbai.com/articles/2024/12/30/level-up-sql-skills-data-engineer.html" rel="alternate" type="text/html" title="Level Up Your SQL Skills As a Data Engineer" /><published>2024-12-30T00:00:00+00:00</published><updated>2024-12-30T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2024/12/30/level-up-sql-skills-data-engineer</id><content type="html" xml:base="https://www.firasesbai.com/articles/2024/12/30/level-up-sql-skills-data-engineer.html">&lt;p&gt;&lt;em&gt;Mastering SQL and understanding what can be done with it is crucial in making you a better data engineer.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This article is your starting point to leveling up your SQL skills. We will start with a refresher and then move on to more advanced topics and optimizations techniques all packed with concrete examples and a final case study to wrap it all up.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#sql-overview&quot; id=&quot;markdown-toc-sql-overview&quot;&gt;SQL Overview&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sql-query-order-of-execution&quot; id=&quot;markdown-toc-sql-query-order-of-execution&quot;&gt;SQL Query Order of Execution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#advanced-sql&quot; id=&quot;markdown-toc-advanced-sql&quot;&gt;Advanced SQL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#subquery-vs-cte-vs-temp-table&quot; id=&quot;markdown-toc-subquery-vs-cte-vs-temp-table&quot;&gt;Subquery vs CTE vs Temp Table&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#what-is-a-subquery&quot; id=&quot;markdown-toc-what-is-a-subquery&quot;&gt;What is a Subquery?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#what-is-a-cte&quot; id=&quot;markdown-toc-what-is-a-cte&quot;&gt;What is a CTE?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#what-is-a-temp-table&quot; id=&quot;markdown-toc-what-is-a-temp-table&quot;&gt;What is a Temp Table?&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#window-functions&quot; id=&quot;markdown-toc-window-functions&quot;&gt;Window Functions&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#so-what-exactly-are-window-functions&quot; id=&quot;markdown-toc-so-what-exactly-are-window-functions&quot;&gt;So what exactly are Window functions?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#breakdown-of-window-functions&quot; id=&quot;markdown-toc-breakdown-of-window-functions&quot;&gt;Breakdown of Window functions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sql-query-optimization-techniques&quot; id=&quot;markdown-toc-sql-query-optimization-techniques&quot;&gt;SQL Query Optimization Techniques&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#case-study-nyc-citi-bike-trips&quot; id=&quot;markdown-toc-case-study-nyc-citi-bike-trips&quot;&gt;Case Study: NYC Citi Bike Trips&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;sql-overview&quot;&gt;SQL Overview&lt;/h2&gt;

&lt;p&gt;There are 5 components of the SQL language:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data Definition Language (DDL)&lt;/strong&gt;: Used to define the structure that holds the data. It includes commands like:
    &lt;ul&gt;
      &lt;li&gt;CREATE: Used to create objects in the database (e.g., tables).&lt;/li&gt;
      &lt;li&gt;ALTER: Used to modify the structure of an existing database object.&lt;/li&gt;
      &lt;li&gt;DROP: Used to delete objects from the database.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Manipulation Language (DML)&lt;/strong&gt;: deals with the manipulation of the data itself. Common DML commands include:
    &lt;ul&gt;
      &lt;li&gt;INSERT: Used to add new rows of data into a table.&lt;/li&gt;
      &lt;li&gt;UPDATE: Used to modify existing data within a table.&lt;/li&gt;
      &lt;li&gt;DELETE: Used to remove rows from a table.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Control Language (DCL)&lt;/strong&gt;: concerned with the rights, permissions, and other controls of the database system. It includes commands like:
    &lt;ul&gt;
      &lt;li&gt;GRANT: Gives users access privileges to database.&lt;/li&gt;
      &lt;li&gt;REVOKE: Takes back privileges granted with the GRANT command.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transaction Control Language (TCL)&lt;/strong&gt;: deals with transactions within a database. Transactions allow for control over groups of SQL statements. Common TCL commands include:
    &lt;ul&gt;
      &lt;li&gt;COMMIT: Saves changes made during the current transaction.&lt;/li&gt;
      &lt;li&gt;ROLLBACK: Restores the database to its original state since the last COMMIT.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Query Language (DQL)&lt;/strong&gt;: used to retrieve data from the database. The primary command in DQL is:
    &lt;ul&gt;
      &lt;li&gt;SELECT: Retrieves data from one or more tables.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These components together provide a comprehensive set of tools to interact with and manage databases using SQL.&lt;/p&gt;

&lt;h2 id=&quot;sql-query-order-of-execution&quot;&gt;SQL Query Order of Execution&lt;/h2&gt;

&lt;p&gt;For a given SQL query, the SQL engine will execute its clauses in a specific standard order in order to process your query and return the desired results.&lt;/p&gt;

&lt;p&gt;Understanding the order in which a SQL query is executed is important and will allow you to optimize your queries by minimizing the amount of data processed and improving query execution times. In addition, it will result in writing better and more efficient queries which consume less resources and lead to faster response times and less constraints on the database server.&lt;/p&gt;

&lt;p&gt;The following table summarizes the SQL query order of execution:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Order&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Clause&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Function&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;From/Join&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Determines table(s) from which data will be queried&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Where&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Filters data on rows&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Group By&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Checks if you have aggregations&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Having&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Filters data based on specified groups&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Select&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Selects which columns you want to see returned&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Order By&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Sorts the data returned&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Limit&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Limits the number of rows returned&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;Table 1: SQL query order of execution&lt;/p&gt;

&lt;h2 id=&quot;advanced-sql&quot;&gt;Advanced SQL&lt;/h2&gt;

&lt;h2 id=&quot;subquery-vs-cte-vs-temp-table&quot;&gt;Subquery vs CTE vs Temp Table&lt;/h2&gt;

&lt;h3 id=&quot;what-is-a-subquery&quot;&gt;What is a Subquery?&lt;/h3&gt;

&lt;p&gt;Subquery, also known as inner query, is a query nested inside another SQL query. Subqueries are enclosed within parentheses and can be placed in various parts of a SQL statement such as the SELECT, FROM, WHERE, or HAVING clauses.&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;   
&lt;span class=&quot;no&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;departments&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
   &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
   &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
   &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DECIMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
   &lt;span class=&quot;n&quot;&gt;department_id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;departments&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'HR'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Finance'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Marketing'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;VALUES&lt;/span&gt; 
   &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'John Doe'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
   &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Jane Smith'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
   &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Alice Johnson'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
   &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Bob Williams'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;55000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Suppose we want to retrieve all the employees that work in &lt;strong&gt;HR&lt;/strong&gt; department:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;   
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
	&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;departments&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'HR'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Subqueries are a powerful feature of SQL allowing for more complex and dynamic queries by enabling you to use the results of one query as a condition or value in another.&lt;/p&gt;

&lt;h3 id=&quot;what-is-a-cte&quot;&gt;What is a CTE?&lt;/h3&gt;

&lt;p&gt;CTE stands for Common Table Expression. It is a named temporary result set that exist only for the duration of the main query.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Basic Syntax:&lt;/em&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CTE&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cte_name&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CTE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;definition&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;here&lt;/span&gt;
	&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;column1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;column2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
	&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_name&lt;/span&gt;
	&lt;span class=&quot;no&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conditions&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CTE&lt;/span&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cte_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;CTEs are useful for improving the readability and maintainability of complex queries. In addition, when you need to use the same subquery result multiple times within a larger query, it avoids duplicating complex logic and can make queries more readable and easier to maintain.&lt;/p&gt;

&lt;h3 id=&quot;what-is-a-temp-table&quot;&gt;What is a Temp Table?&lt;/h3&gt;

&lt;p&gt;A temporary table in SQL is a table that exists temporarily on the database server.&lt;/p&gt;

&lt;p&gt;Unlike CTEs that exist only in the context of the query in which they are defined, Temp tables can be created and used just like regular database tables, but they are dropped automatically when the session ends or when explicitly dropped by the user.&lt;/p&gt;

&lt;p&gt;Temp Tables are useful for holding intermediate results that you want to reuse multiple times within a session and allow to break down complex tasks into smaller, more manageable tasks.&lt;/p&gt;

&lt;h2 id=&quot;window-functions&quot;&gt;Window Functions&lt;/h2&gt;

&lt;p&gt;SQL Window functions show up in pretty much every data engineering interview nowadays. Therefore, it is important to understand the key concepts related to this powerful feature.&lt;/p&gt;

&lt;h3 id=&quot;so-what-exactly-are-window-functions&quot;&gt;So what exactly are Window functions?&lt;/h3&gt;

&lt;p&gt;Window functions allow you to perform calculations across a set of table rows related to the current row. This is different from aggregate functions, which summarize data into a single output row for each group.&lt;/p&gt;

&lt;h3 id=&quot;breakdown-of-window-functions&quot;&gt;Breakdown of Window functions&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Partitioning&lt;/strong&gt;: Window functions are typically used with an &lt;strong&gt;OVER clause&lt;/strong&gt;, which defines the window of rows over which the function will operate. This clause can partition the result set into groups of rows based on one or more column values.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ordering&lt;/strong&gt;: Within each partition, you can specify an &lt;strong&gt;ORDER BY&lt;/strong&gt; clause to define the order in which the rows are processed by the window function.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Window Frame&lt;/strong&gt;: This defines the subset of rows within the partition to which the function is applied. The frame can be defined as rows preceding or following the current row, or between a range of rows.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are two main categories of window functions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Aggregate Window Functions:&lt;/strong&gt; These functions resemble regular aggregate functions (SUM, COUNT, AVG, etc.) but operate within the window instead of across the entire dataset. This allows you to calculate things like &lt;strong&gt;running totals&lt;/strong&gt; or &lt;strong&gt;moving averages&lt;/strong&gt;.&lt;/p&gt;

    &lt;p&gt;Commonly used SQL Aggregate Window Functions include:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;COUNT&lt;/strong&gt;() counts the number of rows in a specified column across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;SUM&lt;/strong&gt;() computes the sum of values within a specified column across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;AVG&lt;/strong&gt;() calculates the average of a selected group of values across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;MIN&lt;/strong&gt;() retrieves the lowest value from a particular column across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;MAX&lt;/strong&gt;() fetches the highest value from a specific column across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;FIRST_VALUE&lt;/strong&gt;() returns the first value in a designated column across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;LAST_VALUE&lt;/strong&gt;() provides the last value in a given column across a defined window.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ranking Window Functions:&lt;/strong&gt; These functions assign a rank or order to each row based on a specified value. Examples include ROW_NUMBER(), RANK(), and DENSE_RANK(). These are useful for identifying &lt;strong&gt;top performers&lt;/strong&gt;, assigning &lt;strong&gt;unique sequential identifiers&lt;/strong&gt;, or &lt;strong&gt;grouping data into buckets&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To better illustrate the syntax of the window function, let’s take the following example:&lt;/p&gt;

&lt;p&gt;Suppose we have a table &lt;strong&gt;employees&lt;/strong&gt;:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DECIMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;VALUES&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Alice'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'HR'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;50000.00&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Bob'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'HR'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Charlie'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Engineering'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'David'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Engineering'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Eve'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Engineering'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;90000.00&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We want to calculate the average salary for each departement:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_salary_department&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The result would be:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_salary_department&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;------------------------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Alice&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;50000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;55000.00&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Bob&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;55000.00&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Charlie&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;David&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Eve&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;90000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt;   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The window function calculates the average salary for each row in the result set, but it doesn’t change the number of rows returned. Each row retains its original data, but we also get a new column with the average salary for the department of that row.&lt;/p&gt;

&lt;p&gt;However, using a &lt;strong&gt;Group By&lt;/strong&gt;, the result set is reduced to one row per department, where each row represents a distinct department.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_salary_department&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_salary_department&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;------------------------------------&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;55000.00&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To better illustrate the difference between ROW_NUMBER(), RANK(), and DENSE_RANK(), we will update our employees table with the following values:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;   
&lt;span class=&quot;o&quot;&gt;-------------------------------------------&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Alice&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Bob&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Charlie&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;David&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Eve&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;75000.00&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Frank&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt;   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Ranking the employees within their departments based on their salaries results in the following queries:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;ROW_NUMBER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_number&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_number&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;-------------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Bob&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Frank&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Alice&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Charlie&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;David&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Eve&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;75000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Each Row has a unique number regardless of ties.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;RANK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;--------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Bob&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Frank&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Alice&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Charlie&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;David&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Eve&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;75000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;DENSE_RANK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dense_rank&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dense_rank&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;-------------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Bob&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Frank&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Alice&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Charlie&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;David&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Eve&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;75000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The difference between RANK and DENSE_RANK is the gaps between the ranking in case of ties. You can check this by looking at the row of Alice and Eve where their rank is 3 with RANK but 2 with DENSE_RANK.&lt;/p&gt;

&lt;h2 id=&quot;sql-query-optimization-techniques&quot;&gt;SQL Query Optimization Techniques&lt;/h2&gt;

&lt;p&gt;Since SQL is declarative, there are typically many alternative ways to execute a given query, with widely varying performance. When a query is submitted to the database, the query optimizer evaluates different possible plans or query execution plans which are sequences of steps used to access data. Once determined, the most efficient query is then returned.&lt;/p&gt;

&lt;p&gt;Many database systems provide tools to view the query plan, either graphically or in text format. This helps developers understand and optimize query performance.&lt;/p&gt;

&lt;p&gt;Regularly reviewing and analyzing query execution plans to understand how queries are executed and identify potential performance issues is very helpful. In addition, knowing and applying other optimization techinques can enahance the performance of your system. Here are some general tips for query optimization:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use column names instead of * in a SELECT statement. This reduces the amount of data transferred and processed.&lt;/li&gt;
  &lt;li&gt;Use the most appropriate and efficient data types for your columns to save space and improve performance.&lt;/li&gt;
  &lt;li&gt;Create indexes on columns that are frequently used in WHERE clauses, JOIN conditions, and as part of ORDER BY clauses for faster data retrievel.&lt;/li&gt;
  &lt;li&gt;Use appropriate join types(INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL JOIN) and ensure that join conditions are based on indexed columns.&lt;/li&gt;
  &lt;li&gt;Consider the order of joins: join smaller tables first to reduce the size of intermediate results.&lt;/li&gt;
  &lt;li&gt;Use INNER JOINs where possible as it’s usually faster than OUTER JOINs.&lt;/li&gt;
  &lt;li&gt;Use subqueries only when necessary and consider alternatives like JOINs or Common Table Expressions (CTEs) to simplify and optimize complex queries&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;case-study-nyc-citi-bike-trips&quot;&gt;Case Study: NYC Citi Bike Trips&lt;/h2&gt;

&lt;p&gt;In this section we will try to apply some of the learnings from previous sections to answer some questions about the Citi Bike Trips dataset using SQL.&lt;/p&gt;

&lt;p&gt;This dataset contains information about trips of the Citi Bike share program. It is hosted and available in Google BigQuery and included in the free tier processing. For more information, check &lt;a href=&quot;https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-citi-bike?project=propane-cooler-150809&quot;&gt;this link&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Each question is followed by the corresponding SQL query and its output. For better readability the output of some queries is limited to 3 rows.&lt;/p&gt;

&lt;p&gt;The answer and expected output are hidden. Try to answer the questions to test your understanding before revealing them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Which trips lasted longer than 30 minutes?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;end_station_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;bikeid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;usertype&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   
   &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_station_name&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bikeid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;usertype&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;------------------------------------------------------------------------------------&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;16930&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;South&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Whitehall&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;NYCBS&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Depot&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BAL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DYR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14826&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Subscriber&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;547&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Ave&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;NYCBS&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Depot&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BAL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DYR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;22094&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Subscriber&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;442403&lt;/span&gt;       &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;E&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Avenue&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;A&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;NYCBS&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Depot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DEL&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16592&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Customer&lt;/span&gt;   
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is the average trip duration for each user type (Subscriber and Customer)?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;usertype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;ROUND&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;average_trip_duration&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;usertype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   
   &lt;span class=&quot;n&quot;&gt;usertype&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;average_trip_duration&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;----------------------------------&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;Subscriber&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;806.38&lt;/span&gt;  
   &lt;span class=&quot;no&quot;&gt;Customer&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2145.51&lt;/span&gt; 
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How many trips were made each day?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;starttime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;COUNT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;-----------------------&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;2013&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;07&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;01&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16650&lt;/span&gt; 
   &lt;span class=&quot;mi&quot;&gt;2013&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;07&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;02&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;22745&lt;/span&gt; 
   &lt;span class=&quot;mi&quot;&gt;2013&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;07&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;03&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21864&lt;/span&gt; 
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Which start station has the highest number of trips?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;COUNT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;----------------------------------&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;Pershing&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Square&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;North&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;438077&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;E&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Broadway&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;423334&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Ave&lt;/span&gt;       &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;403795&lt;/span&gt; 
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Which stations had more than 1,000 trips starting from them?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;COUNT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;HAVING&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   
   &lt;span class=&quot;n&quot;&gt;start_duration_name&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; 
   &lt;span class=&quot;o&quot;&gt;----------------------------------&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;Liberty&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Broadway&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;149199&lt;/span&gt;     
   &lt;span class=&quot;no&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Ave&lt;/span&gt;       &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;118394&lt;/span&gt;     
   &lt;span class=&quot;no&quot;&gt;Henry&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Grand&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;105108&lt;/span&gt;     
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is the rolling average trip duration for each bike?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;bikeid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;starttime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bikeid&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starttime&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rolling_avg&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;bikeid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_date&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rolling_avg&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;------------------------------------------------&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;23076&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2015&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;04&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;468&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;505.2&lt;/span&gt;      
   &lt;span class=&quot;mi&quot;&gt;23076&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2015&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;04&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;332&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;869.8&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;23076&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2015&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;05&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;729&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;588.8&lt;/span&gt;
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What are the top 3 longest trips for each station?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ranked_trips&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;start_station_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;no&quot;&gt;ROW_NUMBER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_station_id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt;
      &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt;
   &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;start_station_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ranked_trips&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_station_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;start_station_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;-------------------------------&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;72&lt;/span&gt;               &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2006840&lt;/span&gt; 
   &lt;span class=&quot;mi&quot;&gt;72&lt;/span&gt;               &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;792782&lt;/span&gt;  
   &lt;span class=&quot;mi&quot;&gt;72&lt;/span&gt;               &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;594321&lt;/span&gt;  
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;In this article, we explored on a high level topics of different difficulty levels of the SQL language. Hopefully the examples and the case study helped in clarifying these concepts but this is only the tip of the iceberg. Writing clearer and more efficient SQL queries requires practice. The resources section contains valuable materials to support you further in your learning journey.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Query_plan&quot;&gt;https://en.wikipedia.org/wiki/Query_plan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://sqlzoo.net/wiki/SQL_Tutorial&quot;&gt;https://sqlzoo.net/wiki/SQL_Tutorial&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.windowfunctions.com/&quot;&gt;https://www.windowfunctions.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://datalemur.com/sql-tutorial&quot;&gt;https://datalemur.com/sql-tutorial&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://selectstarsql.com/&quot;&gt;https://selectstarsql.com/&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><summary type="html">Mastering SQL and understanding what can be done with it is crucial in making you a better data engineer.</summary></entry><entry><title type="html">System Desing Interview Blueprint</title><link href="https://www.firasesbai.com/articles/2024/12/08/system-design-interview-blueprint.html" rel="alternate" type="text/html" title="System Desing Interview Blueprint" /><published>2024-12-08T00:00:00+00:00</published><updated>2024-12-08T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2024/12/08/system-design-interview-blueprint</id><content type="html" xml:base="https://www.firasesbai.com/articles/2024/12/08/system-design-interview-blueprint.html">&lt;p&gt;&lt;em&gt;This article contains general guidelines and a reference framework to use when approaching system design interview.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;System design interview is a key component of the technical interview process that is no longer limited to big tech companies or traditional software engineering positions. Even though each company is different, a system design round is not uncommon for data engineering positions especially for senior and more experienced roles.&lt;/p&gt;

&lt;p&gt;The purpose of this step is to assess your ability to design large-scale, complex software systems from scratch focusing on your problem solving skills and communication and collaboration capabilities.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#general-concepts&quot; id=&quot;markdown-toc-general-concepts&quot;&gt;General Concepts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#workflow&quot; id=&quot;markdown-toc-workflow&quot;&gt;Workflow&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#step-1-design-scope&quot; id=&quot;markdown-toc-step-1-design-scope&quot;&gt;Step 1: Design Scope&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#general-questions&quot; id=&quot;markdown-toc-general-questions&quot;&gt;General questions&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#problem-specific-questions&quot; id=&quot;markdown-toc-problem-specific-questions&quot;&gt;Problem specific questions&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#non-functional-requirements&quot; id=&quot;markdown-toc-non-functional-requirements&quot;&gt;Non Functional Requirements&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#back-of-the-envelope-estimation&quot; id=&quot;markdown-toc-back-of-the-envelope-estimation&quot;&gt;Back of the envelope estimation&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#step-2-high-level-design&quot; id=&quot;markdown-toc-step-2-high-level-design&quot;&gt;Step 2: High Level Design&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#step-3-design-deep-dive&quot; id=&quot;markdown-toc-step-3-design-deep-dive&quot;&gt;Step 3: Design Deep Dive&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#step-4-wrap-up&quot; id=&quot;markdown-toc-step-4-wrap-up&quot;&gt;Step 4: Wrap up&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#common-system-design-use-cases&quot; id=&quot;markdown-toc-common-system-design-use-cases&quot;&gt;Common System Design Use Cases&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;general-concepts&quot;&gt;General Concepts&lt;/h2&gt;

&lt;p&gt;While there is no shortage of information or resources on the internet when it comes to system design interview preparation, following is a list of some concepts and topics that I personnaly found common and almost always used in every system and thus you should be familiar with before going to the interview:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ByteByteGoHq/system-design-101?tab=readme-ov-file#communication-protocols&quot;&gt;API Architecture Styles&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ByteByteGoHq/system-design-101?tab=readme-ov-file#how-do-we-design-effective-and-safe-apis&quot;&gt;API Design&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rate Limiter&lt;/strong&gt;: a rate limiter is used to control the rate of traffic requests sent by a client or a service. If the requests count hits the threshold defined by the rate limiter, all the following reuqests are blocked. The benefits of using a rate limiter include preventing resource starvation caused by Denial of Service (DoS) attack and reducing cost by requiring fewer servers and preventing these from being overloaded. 
Some popular rate limiting algorithms include:
    &lt;ul&gt;
      &lt;li&gt;Token bucket&lt;/li&gt;
      &lt;li&gt;Leaky bucket&lt;/li&gt;
      &lt;li&gt;Fixed window&lt;/li&gt;
      &lt;li&gt;Sliding window&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;For more information check out &lt;a href=&quot;https://www.geeksforgeeks.org/rate-limiting-algorithms-system-design/&quot;&gt;this link&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer?tab=readme-ov-file#load-balancer&quot;&gt;Load Balancer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.geeksforgeeks.org/consistent-hashing/&quot;&gt;Consistent hashing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer?tab=readme-ov-file#content-delivery-network&quot;&gt;Content Delivery Network (CDN)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Database choice&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/20_database_choice.png&quot; alt=&quot;comparison between types and characteristics of databases&quot; /&gt;
  &lt;figcaption&gt;Figure 1: Types of Databases - &lt;a href=&quot;https://blog.bytebytego.com/p/understanding-database-types&quot;&gt;Image Source&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt;: it improves load times and can reduce the load on your servers and databases. It is important to understand the different layers where caching can be applied, their advantages and disadvantages and strategies to update your cache. These would include:
    &lt;ul&gt;
      &lt;li&gt;Client caching&lt;/li&gt;
      &lt;li&gt;CDN caching&lt;/li&gt;
      &lt;li&gt;Web server caching&lt;/li&gt;
      &lt;li&gt;Database caching&lt;/li&gt;
      &lt;li&gt;Application caching&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;workflow&quot;&gt;Workflow&lt;/h2&gt;

&lt;h3 id=&quot;step-1-design-scope&quot;&gt;Step 1: Design Scope&lt;/h3&gt;

&lt;p&gt;Generally you will be tasked with designing a well known system or application that is used by hundreds if not millions of users with a broad and ambiguous statement. Obviously coming up with all the potential problems, edge cases and details around the ultimate solution is not a one session task. The system in question came to its current state after years of cumulative efforts from multiple engineering teams and designing something similar in the current context and scope is not a realistic expectation nor a feasible task. Therefore, a good starting point would be to define the scope of the design and what you want to achieve during the interview.&lt;/p&gt;

&lt;h4 id=&quot;general-questions&quot;&gt;General questions&lt;/h4&gt;

&lt;p&gt;Start by asking some general questions to better understand the requirements. Make sure to take notes of any assumptions and decisions made along the way.&lt;/p&gt;

&lt;p&gt;Following are some questions to consider:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What are the most important features?&lt;/li&gt;
  &lt;li&gt;Is this a mobile app, a web app or both?&lt;/li&gt;
  &lt;li&gt;How many Daily Active Users (DAU) does the product have?&lt;/li&gt;
  &lt;li&gt;Can we leverage some of the existing cloud infrastructure provided by Amazon, Google or Microsoft?&lt;/li&gt;
  &lt;li&gt;Is encryption required?&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;problem-specific-questions&quot;&gt;Problem specific questions&lt;/h4&gt;

&lt;p&gt;Building up on these, make sure to dive deeper in your conversation with your interviewer on more problem specific questions to clarify any ambiguities.&lt;/p&gt;

&lt;h4 id=&quot;non-functional-requirements&quot;&gt;Non Functional Requirements&lt;/h4&gt;

&lt;p&gt;After clarifying the requirements, it is important to understand the non functional aspects of your system which will guide you in your design choices since they are a crucial part of any large scale system.&lt;/p&gt;

&lt;p&gt;Some areas to consider would be:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reliability&lt;/li&gt;
  &lt;li&gt;Scalability&lt;/li&gt;
  &lt;li&gt;High Availability&lt;/li&gt;
  &lt;li&gt;Fault tolerance&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;back-of-the-envelope-estimation&quot;&gt;Back of the envelope estimation&lt;/h4&gt;

&lt;p&gt;A final part of defining your scope would involve doing back-of-the-envelope calculations. Weather your interviewer asks you to do it or not, these estimations help you assess which design will meet your requirements.&lt;/p&gt;

&lt;p&gt;These calculations will be based on the requirements and agreed upon assumptions form your previous questions and common performance numbers. You you should familiarize yourself with these numbers &lt;a href=&quot;https://github.com/donnemartin/system-design-primer?tab=readme-ov-file#appendix&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;step-2-high-level-design&quot;&gt;Step 2: High Level Design&lt;/h3&gt;

&lt;p&gt;After clarifying the design scope, now it is time to identify the key components of your system. These are the high level components that you are going to work with for the rest of the interview. As you progress, you will be adding more details to your design along the way so the point here is to really start at a high level even if it seems oversimplified. This will serve as a baseline as you work with the interviewer on identifying the right level of detail needed.&lt;/p&gt;

&lt;h3 id=&quot;step-3-design-deep-dive&quot;&gt;Step 3: Design Deep Dive&lt;/h3&gt;

&lt;p&gt;Based on your domain of expertise, choose the part you feel most comfortable with and start diving deeper on its key components. For example, when starting at the database layer you could discuss the factors to consider when selecting the appropriate database technology such as scalability, performance and data consistency and model. For someone else this could be the API layer where they can discuss the appropriate architecture style to choose and give an example of some API endpoints requests, parameters and responses.&lt;/p&gt;

&lt;p&gt;While covering different parts of the system, it is important to consider system optimizations and cost savings aspects to ensure your system handles the requirements previously identified in the most efficient way.&lt;/p&gt;

&lt;p&gt;Make sure to also discuss some scenarios and user journeys to demonstrate how your proposed system supports how the users would eventually interact with it.&lt;/p&gt;

&lt;h3 id=&quot;step-4-wrap-up&quot;&gt;Step 4: Wrap up&lt;/h3&gt;

&lt;p&gt;At this stage you should be approaching the end of the session. It could be useful to give the interviewer a recap of your design. Since there is always something to improve, use this opportunity to mention potential improvements in order to handle more scale or refinements you could do if you had more time especially if you had to do some tradeoffs at the beginning. Discussing things like monitoring and logging and error handling in case of failures of different components in your system are worth touching upon and would demonstrate your critical thinking.&lt;/p&gt;

&lt;h2 id=&quot;common-system-design-use-cases&quot;&gt;Common System Design Use Cases&lt;/h2&gt;

&lt;p&gt;Following is a list of common system design questions and real world applications each with a set of unique challenges, requirements and type of data.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;File storage and collaboration platform
    &lt;ul&gt;
      &lt;li&gt;Dropbox&lt;/li&gt;
      &lt;li&gt;Google Drive&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Messaging application
    &lt;ul&gt;
      &lt;li&gt;Slack&lt;/li&gt;
      &lt;li&gt;Facebook messenger&lt;/li&gt;
      &lt;li&gt;Whatsapp&lt;/li&gt;
      &lt;li&gt;WeChat&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Music streaming platform
    &lt;ul&gt;
      &lt;li&gt;Spotify&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;News feed system
    &lt;ul&gt;
      &lt;li&gt;Facebook news feed&lt;/li&gt;
      &lt;li&gt;Instagram feed&lt;/li&gt;
      &lt;li&gt;Twitter timeline&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ride sharing app
    &lt;ul&gt;
      &lt;li&gt;Uber&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Video streaming service
    &lt;ul&gt;
      &lt;li&gt;Netflix&lt;/li&gt;
      &lt;li&gt;Youtube&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Online Marketplace
    &lt;ul&gt;
      &lt;li&gt;Airbnb&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;E-commerce Platform
    &lt;ul&gt;
      &lt;li&gt;Amazon.com&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;This article presented a mental model with a logical set of steps to follow when approaching a system design interview enriched with pointers to an opinionated set of topics and concepts to review beforehand.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning and good luck on your system design interview!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.goodreads.com/en/book/show/54109255&quot;&gt;https://www.goodreads.com/en/book/show/54109255&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.goodreads.com/en/book/show/60631342&quot;&gt;https://www.goodreads.com/en/book/show/60631342&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ByteByteGoHq/system-design-101&quot;&gt;https://github.com/ByteByteGoHq/system-design-101&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer&quot;&gt;https://github.com/donnemartin/system-design-primer&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><summary type="html">This article contains general guidelines and a reference framework to use when approaching system design interview.</summary></entry><entry><title type="html">Evolution of Analytical Data Architectures: From Data Warehouses to Lakehouses</title><link href="https://www.firasesbai.com/articles/2024/11/17/evolution-analytical-data-architectures.html" rel="alternate" type="text/html" title="Evolution of Analytical Data Architectures: From Data Warehouses to Lakehouses" /><published>2024-11-17T00:00:00+00:00</published><updated>2024-11-17T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2024/11/17/evolution-analytical-data-architectures</id><content type="html" xml:base="https://www.firasesbai.com/articles/2024/11/17/evolution-analytical-data-architectures.html">&lt;p&gt;&lt;em&gt;In this article, we will go through a brief overview of the journey from the foundational data warehouses to the data lakes and up to the emerging concept of the data lakehouse.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The evolution of data management has been driven by the growing complexity and scale of modern data needs. Organizations have sought different solutions over the years for handling diverse data types while optimizing for cost efficiency.&lt;/p&gt;

&lt;p&gt;This article explores the key transitions from one analytical architecture to the other and the challenges that shaped each phase.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#data-warehouses&quot; id=&quot;markdown-toc-data-warehouses&quot;&gt;Data Warehouses&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-lakes&quot; id=&quot;markdown-toc-data-lakes&quot;&gt;Data Lakes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#two-tier-architecture-data-warehouse--data-lake&quot; id=&quot;markdown-toc-two-tier-architecture-data-warehouse--data-lake&quot;&gt;Two-Tier Architecture: Data Warehouse + Data Lake&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-lakehouses&quot; id=&quot;markdown-toc-data-lakehouses&quot;&gt;Data Lakehouses&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#what-is-a-table-format&quot; id=&quot;markdown-toc-what-is-a-table-format&quot;&gt;What is a Table Format?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#open-table-formats&quot; id=&quot;markdown-toc-open-table-formats&quot;&gt;Open Table Formats&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;data-warehouses&quot;&gt;Data Warehouses&lt;/h2&gt;

&lt;p&gt;The concept of data warehousing emerged in the late 1980s as a response to the growing need for businesses to make data-driven decisions. In fact, the proliferation of applications and the resulting disparate data across the organization resulted in a tedious manual process of querying and finding the right data with the correct version in order to avoid incorrect decisions.&lt;/p&gt;

&lt;p&gt;As a result, the &lt;em&gt;Data Warehouse&lt;/em&gt; was born.&lt;/p&gt;

&lt;p&gt;A data warehouse is a centralized repository for storing and managing large amounts of data from various sources.&lt;/p&gt;

&lt;p&gt;Data Warehouse is not the same as a database but rather typically built on top of data copied from other databases and addresses several limitations of traditional operational databases:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Centralization&lt;/strong&gt;: They provided a single source of truth for enterprise-wide data.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Historical analysis&lt;/strong&gt;: Unlike operational systems focused on current data, warehouses allowed for trend analysis over time.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Complex querying&lt;/strong&gt;: Designed for analytical processing, they could handle complex queries more efficiently than transaction-oriented databases.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data quality&lt;/strong&gt;: The ETL (Extract, Transform, Load) process helped in cleaning and standardizing data before loading it into the warehouse.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, as data types evolved and volumes grew exponentially, data warehouses faced mainly the following challenges:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: The increasing volume and velocity of data required expensive hardware and software to store and process data. The cost of these solutions made it difficult for organizations to store all their data.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Flexibility&lt;/strong&gt;: The rigid schema-on-write approach made it difficult to accommodate rapidly changing data requirements and the growth of semi-structured and unstructured data types.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These limitations set the stage for the next evolution in analytical data architecture: the &lt;strong&gt;Data Lake&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;data-lakes&quot;&gt;Data Lakes&lt;/h2&gt;

&lt;p&gt;As mentioned, the concept of a data lake emerged as a response to the limitations of traditional data warehouses, which were costly, proprietary, and unable to handle the diverse and voluminous data generated by modern businesses.&lt;/p&gt;

&lt;p&gt;Initially data lakes were almost exclusively implemented on &lt;strong&gt;&lt;em&gt;Hadoop&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Hadoop is an open-source platform that enables the storage and processing of large datasets across distributed computing environments. The original development of Hadoop goes back to 2003 when Google released two papers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Google File System (GFS)&lt;/em&gt;&lt;/strong&gt;: a way to store data across distributed machines&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Google MapReduce&lt;/em&gt;&lt;/strong&gt;: a programming model for distributed data processing on top of GFS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This research paved the way for Yahoo to bootstrap the Hadoop project. Later on, a shift towards modern data lakes appeared that leverages cloud platforms.&lt;/p&gt;

&lt;p&gt;Cloud platforms offer elasticity and cost efficiency especially with the need for data lakes to support a wider range of users and use cases including machine learning.&lt;/p&gt;

&lt;p&gt;While data lakes offer a lot of improvements over data warehouses including enabling organizations to scale their data storage in a more cost-effective way and flexibility with their schema on-read approach, it is also important to note that they also come with challenges.&lt;/p&gt;

&lt;p&gt;Following are some of the key challenges associated with data lakes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data Reliability&lt;/strong&gt;: Data lakes can suffer from reliability issues due to broken data pipelines and the need for continuous reprocessing of missing or corrupted data. This often occurs when write operations fail partially, requiring data engineers to clean up and reprocess the data, which can be time-consuming and resource-intensive.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Quality&lt;/strong&gt;: Ensuring high data quality is a significant challenge in data lakes, as they store raw, unprocessed data that may be inconsistent or incomplete. Poor data quality can negatively impact downstream analytics and decision-making processes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Governance&lt;/strong&gt;: Implementing effective data governance in data lakes is complex due to the variety and volume of data. Ensuring data integrity, security, and compliance with regulations such as GDPR and CCPA is challenging, especially when it comes to deleting or updating data.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Silos&lt;/strong&gt;: Without proper management, data lakes can become data swamps, where data is isolated and inaccessible, leading to the creation of data silos. This hinders collaboration and limits the organization’s ability to extract valuable insights from the data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In an attempt to address these challenges, a common approach organizations ended up deploying was the &lt;strong&gt;Two-Tier Architecture&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;two-tier-architecture-data-warehouse--data-lake&quot;&gt;Two-Tier Architecture: Data Warehouse + Data Lake&lt;/h2&gt;

&lt;p&gt;This architecture involves using a data lake as the first tier for data ingestion and storage, followed by a data warehouse as the second tier for structured analytics and reporting.&lt;/p&gt;

&lt;p&gt;This leverages the cost effective storage and flexibility of the data lake to store the large volumes of raw data. In addition, through ETL processes, data will be moved from the lake to the data warehouse where security, compliance, and optimized performance for analytical queries are ensured.&lt;/p&gt;

&lt;p&gt;This sounds like the perfect combination and the answer to all the previously mentioned challenges. In practice however this has several drawbacks. It results in higher costs because of the redundant data stored across both systems and the maintenance costs of both infrastructures. Also managing two separate systems can be quite complex for users.&lt;/p&gt;

&lt;p&gt;Luckily the evolution did not stop here and the data lakehouse architecture emerged to the rescue which aims to combine the best features of both data warehouses and data lakes but into a single, unified architecture.&lt;/p&gt;

&lt;h2 id=&quot;data-lakehouses&quot;&gt;Data Lakehouses&lt;/h2&gt;

&lt;p&gt;Data Lakehouses combine the best elements of both data lakes and data warehouses.&lt;/p&gt;

&lt;p&gt;They are enabled by a new system design: implementing similar data structures, data management features and ACID transactions to those in a data warehouse directly on top of low cost cloud storage in open file formats of the data lake for flexibility and scale.&lt;/p&gt;

&lt;p&gt;One of the key technology advancements that have enabled the data lakehouse architecture is a &lt;strong&gt;table format&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;what-is-a-table-format&quot;&gt;What is a Table Format?&lt;/h3&gt;

&lt;p&gt;Table format is a metadata layer that allows tools to interact with data lake storage like a traditional database. Since data in a data lake is usually stretched across several files, the metadata layer contains information about which files are part of different table versions to offer rich management features like ACID-compliant transactions.&lt;/p&gt;

&lt;p&gt;In addition, the metadata layers enable other features common in data lakehouses such as:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Schema evolution&lt;/strong&gt;: accommodate data that is changing over time by easily changing a table current’s schema&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Partition evolution&lt;/strong&gt;: allows us to update the partition scheme of a table without having to rewrite all the previous data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Time Travel&lt;/strong&gt;: query a table at previous states&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;open-table-formats&quot;&gt;Open Table Formats&lt;/h3&gt;

&lt;p&gt;Multiple projects have emerged as open source table format technologies to allow community development, drive standardization efforts and avoid vendor lock in. The term open table format gained prominence with the rise of the data lakehouse concept and become a way to collectively refer to these technologies.&lt;/p&gt;

&lt;p&gt;Among these are Apache Iceberg, Apache Hudi, and Databricks Delta Lake.&lt;/p&gt;

&lt;p&gt;The following table summarizes differences between these open table formats and how each has a different approach to supporting common features of data lakehouses.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Apache Iceberg&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Apache Hudi&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Delta Lake&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Origin&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Originated at Netflix and then become part of the Apache Software Foundation&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Originated at Uber and then become part of the Apache Software Foundation&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Developed by Databricks and is now an independent open-source sub-project of the Linux Foundation Projects&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Metadata Layer&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Catalogue&lt;/strong&gt;: maintain a list of existing Iceberg tables and keeps a reference to a table’s current metadata file known as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;metadata.json&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Timeline&lt;/strong&gt;: event log recording all table actions in an ordered manner, with events kept for a specified period.&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Transaction Log&lt;/strong&gt;: Log files similar to Git commits to capture files added and removed from the table since the last commit and Log checkpoints that summarize a group of log files so each individual log file doesn’t have to be read to construct the list of files in the dataset.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Schema Evolution&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;In-place table evolution: schema updates are metadata changes and no data files need to be rewritten to perform the update. Iceberg supports the following schema evolution changes: &lt;ul&gt;&lt;li&gt;&lt;i&gt;Add&lt;/i&gt; -- add a new column to the table or to a nested struct&lt;/li&gt;&lt;li&gt;&lt;i&gt;Drop&lt;/i&gt; -- remove an existing column from the table or a nested struct&lt;/li&gt;&lt;li&gt;&lt;i&gt;Rename&lt;/i&gt; -- rename an existing column or field in a nested struct&lt;/li&gt;&lt;li&gt;&lt;i&gt;Update&lt;/i&gt; -- widen the type of a column, struct field, map key, map value, or list element&lt;/li&gt;&lt;li&gt;&lt;i&gt;Reorder&lt;/i&gt; -- change the order of columns or fields in a nested struct&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Supports schema evolution on write out of the box and an experimental schema evolution on read feature. Schema evolution on write supports backward compatible scenarios such as adding a nullable field, promoting data types or handling missing columns.&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Schema evolution is disabled by default. This is referred to as schema enforcement. You can enable it by:&lt;ul&gt;&lt;li&gt;&lt;i&gt;mergeSchema&lt;/i&gt;: applies for a single write to a single table &lt;/li&gt;&lt;li&gt;&lt;i&gt;autoMerge&lt;/i&gt;: activates schema evolution for writes to any table&lt;/li&gt;&lt;/ul&gt; Delta lake supports the following types of schema changes: &lt;ul&gt;&lt;li&gt;Adding new columns (at arbitrary positions)&lt;/li&gt;&lt;li&gt;Reordering existing columns&lt;/li&gt;&lt;li&gt;Renaming existing columns&lt;/li&gt;&lt;/ul&gt; When attempting to write data with a new schema, Delta Lake compares the new schema with the existing schema stored in the transaction log. It checks if the schema change is compatible and allowed based on the current settings (e.g., if mergeSchema is enabled). If the change is allowed, Delta Lake creates a new transaction that includes:&lt;ul&gt;&lt;li&gt;An &quot;update metadata&quot; action to modify the table's schema&lt;/li&gt;&lt;li&gt;&quot;Add file&quot; actions for the new data files&lt;/li&gt;&lt;/ul&gt; If the transaction is successful, these changes are committed to the transaction log as a new entry. After the commit, the latest table state, including the new schema, is reflected in the next checkpoint file &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Partition Evolution&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Partition evolution is a metadata operation and does not eagerly rewrite files. When you evolve a partition spec, the old data written with an earlier spec remains unchanged. New data is written using the new spec in a new layout. Metadata for each of the partition versions is kept separately.&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Hudi considers partition evolution as anti-pattern and avoids such scheme&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Delta lake does not natively support partition evolution without rewriting the entire table&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Time Travel&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Every change to an Iceberg table creates a new snapshot. Queries can access the table’s list of snapshots to return results from older versions. Queries can be executed using: &lt;ul&gt;&lt;li&gt;specific snapshot id&lt;/li&gt;&lt;li&gt;timestamp when a snapshot was the current at that time&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;The internal timeline log used by Hudi enables time travel queries support using a point in time syntax with timestamps&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Delta lake will inspect the transaction log and figure out which files should be read for each given version. It also supports time travel by timestamp without having to figure out the exact version.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;Table 1: Open Table Formats Comparison&lt;/p&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;In this article, we covered the advantages and challenges of different data analytics architecture and how these led to the current development of the data lakehouse concept. In addition, we compared internal structures of open table formats to better understand their importance in enabling the data lakehouse architecture.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.databricks.com/blog/2021/05/19/evolution-to-the-data-lakehouse.html&quot;&gt;https://www.databricks.com/blog/2021/05/19/evolution-to-the-data-lakehouse.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.dremio.com/blog/exploring-the-architecture-of-apache-iceberg-delta-lake-and-apache-hudi/&quot;&gt;https://www.dremio.com/blog/exploring-the-architecture-of-apache-iceberg-delta-lake-and-apache-hudi/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.dremio.com/blog/comparison-of-data-lake-table-formats-apache-iceberg-apache-hudi-and-delta-lake/&quot;&gt;https://www.dremio.com/blog/comparison-of-data-lake-table-formats-apache-iceberg-apache-hudi-and-delta-lake/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.databricks.com/glossary/data-lakehouse&quot;&gt;https://www.databricks.com/glossary/data-lakehouse&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://hudi.apache.org/docs/hudi_stack&quot;&gt;https://hudi.apache.org/docs/hudi_stack&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://iceberg.apache.org/concepts/catalog/&quot;&gt;https://iceberg.apache.org/concepts/catalog/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.delta.io/latest/delta-intro.html&quot;&gt;https://docs.delta.io/latest/delta-intro.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://delta.io/blog/2023-02-08-delta-lake-schema-evolution/&quot;&gt;https://delta.io/blog/2023-02-08-delta-lake-schema-evolution/&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><category term="Data Architecture" /><summary type="html">In this article, we will go through a brief overview of the journey from the foundational data warehouses to the data lakes and up to the emerging concept of the data lakehouse.</summary></entry><entry><title type="html">Cloudflare Analytics vs Google Analytics</title><link href="https://www.firasesbai.com/articles/2024/08/11/cloudflare-vs-google-analytics.html" rel="alternate" type="text/html" title="Cloudflare Analytics vs Google Analytics" /><published>2024-08-11T00:00:00+00:00</published><updated>2024-08-11T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2024/08/11/cloudflare-vs-google-analytics</id><content type="html" xml:base="https://www.firasesbai.com/articles/2024/08/11/cloudflare-vs-google-analytics.html">&lt;p&gt;&lt;em&gt;In this article we will look into the reasons for discrepancies between the data reported by Cloudflare Analytics and Google Analytics and how to leverage both of them.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Tracking and analyzing web data is essential for keeping a holistic view on your site’s performance. This is especially useful for bloggers to track key metrics such as which articles and pages are most visited, where visitors are located and the percentage of visitors who leave after viewing only one page just to name a few.&lt;/p&gt;

&lt;p&gt;For monitoring this site’s performance, I have opted for integrating Google Analytics web service. In addition, I’m using cloudflare for managing a custom domain name. Cloudflare has implemented Analytics where users can also gain insights to their managed sites. These however show big discrepancies from the data present in Google Analytics. Understanding the reasons behind it is what we will try to accomplish in this blog post.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#data-collection-method&quot; id=&quot;markdown-toc-data-collection-method&quot;&gt;Data Collection Method&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#server-side-tracking&quot; id=&quot;markdown-toc-server-side-tracking&quot;&gt;Server-Side Tracking&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#client-side-tracking&quot; id=&quot;markdown-toc-client-side-tracking&quot;&gt;Client-Side Tracking&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#types-of-data-collected&quot; id=&quot;markdown-toc-types-of-data-collected&quot;&gt;Types of Data Collected&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#cloudflare&quot; id=&quot;markdown-toc-cloudflare&quot;&gt;Cloudflare&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#google-analytics&quot; id=&quot;markdown-toc-google-analytics&quot;&gt;Google Analytics&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recommendation&quot; id=&quot;markdown-toc-recommendation&quot;&gt;Recommendation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;data-collection-method&quot;&gt;Data Collection Method&lt;/h2&gt;

&lt;p&gt;Understanding the different methods used by each tool to collect data will reveal the main reason for discrepancies in their reports.&lt;/p&gt;

&lt;h3 id=&quot;server-side-tracking&quot;&gt;Server-Side Tracking&lt;/h3&gt;

&lt;p&gt;Cloudflare uses DNS and server-side data to track visits. This means it collects data on every request made to your website’s server. This includes all HTTP/HTTPS requests, regardless of whether they are made by human users, bots, or automated scripts. Therefore, every unique IP address for a request is identified as a visit.&lt;/p&gt;

&lt;p&gt;For this reason, Cloudflare Analytics probably will show higher unique visitors than Google Analytics unique pageviews because when a bot or API is consuming partial content from your site without loading the full page it counts as a unique visitor in Cloudflare but not as a pageview.&lt;/p&gt;

&lt;h3 id=&quot;client-side-tracking&quot;&gt;Client-Side Tracking&lt;/h3&gt;

&lt;p&gt;Google Analytics uses a JavaScript tag embedded in web pages to collect data. When a user loads a page, the script sends data back to Google Analytics. Even though Google Analytics filters out known bot traffic, it can miss traffic from users who block Javascript, use privacy-focused browsers or have ad blockers that prevent Google Analytics from loading.&lt;/p&gt;

&lt;p&gt;For this reason, Cloudflare Analytics probably will show higher number of visitors than Google Analytics.&lt;/p&gt;

&lt;h2 id=&quot;types-of-data-collected&quot;&gt;Types of Data Collected&lt;/h2&gt;

&lt;p&gt;Knowing the reason behind the data of both Cloudflare and Google Analytics was only the beginning. In this section, we will look into the type of data collected by them and its purpose.&lt;/p&gt;

&lt;h3 id=&quot;cloudflare&quot;&gt;Cloudflare&lt;/h3&gt;

&lt;p&gt;Cloudflare often provides high-level technical data. It tracks every request made to your server which gives a comprehensive view of all incoming traffic and how many requests each resource on your website receives. In addition, Cloudflare provides data to help maintain the security and efficiency of your website such as blocked threats or DDoS attacks and cache hits/misses and load times.&lt;/p&gt;

&lt;h3 id=&quot;google-analytics&quot;&gt;Google Analytics&lt;/h3&gt;

&lt;p&gt;Google Analytics excels in tracking how users interact with your website. It provides detailed metrics on page views, sessions, bounce rates, and conversion rates. Also, it tracks where your visitors come from, whether through organic search, paid ads, social media, or referrals. This will help you understand your users’ behavior and engagement and their journey through your website.&lt;/p&gt;

&lt;h2 id=&quot;recommendation&quot;&gt;Recommendation&lt;/h2&gt;

&lt;p&gt;Leveraging data from both Cloudflare and Google Analytics offers a powerful combination of insights that will allow you to maximise your understanding of your website traffic along with detailed insights into user behavior and improve the performance and security.&lt;/p&gt;

&lt;p&gt;One way to achieve this would be using &lt;a href=&quot;https://lookerstudio.google.com/overview&quot;&gt;Looker Studio&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Looker Studio is an online free tool by Google that will allow you to easily access data from multiple sources through its built-in connectors and visualise it through interactive reports and dashboards.&lt;/p&gt;

&lt;p&gt;If you are using Google Analytics then getting your data into Looker Studio is just a few clicks away. However, for Cloudflare data it is a bit more than that.&lt;/p&gt;

&lt;p&gt;Cloudflare web analytics is free and does not require an Enterprise plan but getting data into Looker Studio in an automated fashion would require a Cloudflare Enterprise account with Cloudflare Logs enabled. For more information, check this &lt;a href=&quot;https://developers.cloudflare.com/analytics/analytics-integrations/looker/&quot;&gt;link&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;An alternative workaround to visualize your Cloudflare data in Looker Studio can be achieved by exporting the collected data into Google Sheets first and then use the latter as a new data source in Looker Studio.&lt;/p&gt;

&lt;p&gt;The data export step can be done either manually or using a script that sends requests to Cloudflare’s API. Choosing one option over the other is up to you depending on your requirements and needs for up-to-date dashboards and how often you will review them.&lt;/p&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;In this article we covered the reasons behind the difference of data gathered by Cloudflare Analytics and data coming from Google Analytics. We also saw how to use Looker Studio as a central reporting solution for combining both data sources for a comprehensive website analytics.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://developers.cloudflare.com/analytics/faq/about-analytics/#4lt2VoRUorCudxN1xzxpOt&quot;&gt;https://developers.cloudflare.com/analytics/faq/about-analytics/#4lt2VoRUorCudxN1xzxpOt&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Blogging" /><summary type="html">In this article we will look into the reasons for discrepancies between the data reported by Cloudflare Analytics and Google Analytics and how to leverage both of them.</summary></entry><entry><title type="html">Data Warehouse Modeling Techniques</title><link href="https://www.firasesbai.com/articles/2024/08/11/data-warehouse-modeling-techniques.html" rel="alternate" type="text/html" title="Data Warehouse Modeling Techniques" /><published>2024-08-11T00:00:00+00:00</published><updated>2024-08-11T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2024/08/11/data-warehouse-modeling-techniques</id><content type="html" xml:base="https://www.firasesbai.com/articles/2024/08/11/data-warehouse-modeling-techniques.html">&lt;p&gt;&lt;em&gt;In this article we will go over the big three approaches for modeling analytical data.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We will go through some definitions around data modeling and database design approaches as well as the differences between a data warehouse and a data mart, how they are used in business intelligence and data analytics and the modeling techniques applied with them.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-a-data-warehouse&quot; id=&quot;markdown-toc-what-is-a-data-warehouse&quot;&gt;What is a Data Warehouse?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-warehouse-vs-data-mart&quot; id=&quot;markdown-toc-data-warehouse-vs-data-mart&quot;&gt;Data Warehouse vs Data Mart&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-data-modeling&quot; id=&quot;markdown-toc-what-is-data-modeling&quot;&gt;What is Data Modeling?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#normalization-vs-denormalization&quot; id=&quot;markdown-toc-normalization-vs-denormalization&quot;&gt;Normalization vs Denormalization&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#normalization&quot; id=&quot;markdown-toc-normalization&quot;&gt;Normalization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#denormalization&quot; id=&quot;markdown-toc-denormalization&quot;&gt;Denormalization&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-warehouse-modeling-techniques&quot; id=&quot;markdown-toc-data-warehouse-modeling-techniques&quot;&gt;Data Warehouse Modeling Techniques&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#modeling-techniques-implementation-on-databricks-lakehouse-platform&quot; id=&quot;markdown-toc-modeling-techniques-implementation-on-databricks-lakehouse-platform&quot;&gt;Modeling Techniques Implementation on Databricks Lakehouse Platform&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;what-is-a-data-warehouse&quot;&gt;What is a Data Warehouse?&lt;/h2&gt;

&lt;p&gt;Data Warehouse is not the same as a database but rather typically built on top of other databases. It aggregates data from dozens of data sources such as operational systems or external systems and the data is actually copied rather than moved.&lt;/p&gt;

&lt;p&gt;Building a Data Warehouse serves the purpose of having a one stop shop: all your data in a single location which will enable you to make data driven decisions through trend analysis and business intelligence.&lt;/p&gt;

&lt;h2 id=&quot;data-warehouse-vs-data-mart&quot;&gt;Data Warehouse vs Data Mart&lt;/h2&gt;

&lt;p&gt;Unlike the data warehouse which is a centralized data repository that provides a holistic view on the organization’s data, data mart is a specialized and focused subset of a data warehouse. It supports specific analytical needs and is generally easier and quicker to design and implement compared to a data warehouse.&lt;/p&gt;

&lt;h2 id=&quot;what-is-data-modeling&quot;&gt;What is Data Modeling?&lt;/h2&gt;

&lt;p&gt;Data Modeling is the process of creating a visual representation of a system’s data to represent it in an easy way for reusability, flexibility, and scalability. 
The output is usually a collection of living documents that evolve along with changes to business needs and serve the purpose of facilitating communication among stakeholders and the foundation for later database implementation and analysis.&lt;/p&gt;

&lt;p&gt;The process of crafting data models involves 3 steps:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Conceptual&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Analysis and design phase to understand the key business entities and attributes and capture their interactions as per the business processes and rules within the organization.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Logical&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Technology agnostic model that adds more details and relations between entities for how the conceptual model will be implemented.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Physical&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Defines how the logical model will be implemented using the system and technology in question to ensure that the writes and reads can be performed efficiently. It gives details about:
        &lt;ul&gt;
          &lt;li&gt;Data field types as represented in the Database Management System (DBMS)&lt;/li&gt;
          &lt;li&gt;Data relationships as represented in the DBMS&lt;/li&gt;
          &lt;li&gt;Additional details, such as performance tuning&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To better illustrate these steps, let’s consider an &lt;strong&gt;Auto Dealership&lt;/strong&gt; as an example and model the potential system’s data. For instance, the diagram below highlights the different data entities and their relationships of the business on a conceptual level:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/19_conceptual_model_auto_dealership.png&quot; alt=&quot;conceptual data model of an auto dealership&quot; /&gt;
  &lt;figcaption&gt;Figure 1: Conceptual data model of an auto dealership&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Adding more details to the identified entities will result in the following logical diagram:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/19_logical_model_auto_dealership.png&quot; alt=&quot;logical data model of an auto dealership&quot; /&gt;
  &lt;figcaption&gt;Figure 2: Logical data model of an auto dealership &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Finally, the physical model will depend on the chosen database technology and will involve considerations such as how easy it is to manage it and will it be able to handle the load if the data volume scales.&lt;/p&gt;

&lt;h2 id=&quot;normalization-vs-denormalization&quot;&gt;Normalization vs Denormalization&lt;/h2&gt;

&lt;p&gt;Normalization and Denormalization are two opposing approaches to database design.&lt;/p&gt;

&lt;h3 id=&quot;normalization&quot;&gt;Normalization&lt;/h3&gt;

&lt;p&gt;In normalization, the focus is on reducing data redundancy and non-consistency and improving data integrity. This is achieved by organizing data into separate related tables in accordance with normal forms.&lt;/p&gt;

&lt;p&gt;There are several normal forms each building upon the previous one and the main normalization norms are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;First normal form (1NF)&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Each column is unique and has a single value. The table has a unique primary key.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Second normal form (2NF)&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;The requirements of 1NF, plus &lt;em&gt;partial dependencies&lt;/em&gt; are removed.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Third normal form (3NF)&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;The requirements of 2NF, plus each table contains only relevant Fields related to its primary key and has no &lt;em&gt;transitive dependencies&lt;/em&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A &lt;em&gt;partial dependency&lt;/em&gt; occurs when a subset of fields in a composite key can be used to determine a non-key column of the table.&lt;/p&gt;

&lt;p&gt;For example, considering the following table:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;StudentID&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;CourseID&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;StudentName&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;CourseName&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;InstructorName&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;101&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;CS101&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;John&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Database&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Dr. Smith&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;CS102&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Emma&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Networking&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Dr. Johnson&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;CS102&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;John&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Networking&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Dr. Johnson&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;Table 1: Partial Dependency Example&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The primary key is the combination of (StudentId, CourseID)&lt;/li&gt;
  &lt;li&gt;StudentName depends only on StudentID&lt;/li&gt;
  &lt;li&gt;CourseName depends only on CourseID&lt;/li&gt;
  &lt;li&gt;Here, we have two partial dependencies:
    &lt;ul&gt;
      &lt;li&gt;StudentID → StudentName&lt;/li&gt;
      &lt;li&gt;CourseID → CourseName&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A &lt;em&gt;transitive dependency&lt;/em&gt; occurs when a non-key field depends on another non-key field.&lt;/p&gt;

&lt;p&gt;For example, considering the following table:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;EmployeeID&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;EmployeeName&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;DepartmentID&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;DepartmentName&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;E01&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Alice&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;D1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Sales&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;E02&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Bob&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;D2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Marketing&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;E03&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Charlie&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;D1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Sales&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;Table 2: Transitive Dependency Example&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The primary key is EmployeeID&lt;/li&gt;
  &lt;li&gt;EmployeeName depends on EmployeeID&lt;/li&gt;
  &lt;li&gt;DepartmentID depends on EmployeeID&lt;/li&gt;
  &lt;li&gt;DepartmentName depends on DepartmentID&lt;/li&gt;
  &lt;li&gt;Here, we have a transitive dependency:
    &lt;ul&gt;
      &lt;li&gt;EmployeeID → DepartmentID → DepartmentName&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most practical database designs typically aim for 3NF as it generally provides a good balance between data integrity and performance.&lt;/p&gt;

&lt;p&gt;In general, normalization is best suited for systems with frequent insert, update, and delete operations, like transactional databases. What about denormalization?&lt;/p&gt;

&lt;h3 id=&quot;denormalization&quot;&gt;Denormalization&lt;/h3&gt;

&lt;p&gt;Denormalization on the other hand focuses on improving query performance, especially for read-heavy workloads, by combining related data from multiple tables increasing data redundancy and storage requirements and decreasing the number of tables in the database.&lt;/p&gt;

&lt;p&gt;Denormalization is ideal for reporting systems and data warehouses where complex joins are expensive.&lt;/p&gt;

&lt;p&gt;The choice between normalization and denormalization depends on specific application needs:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Use normalization when data integrity and consistency are crucial, and when the database undergoes frequent updates.&lt;/li&gt;
  &lt;li&gt;Opt for denormalization when query performance is a priority, especially for read-intensive applications or when complex joins significantly slow down data retrieval.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-warehouse-modeling-techniques&quot;&gt;Data Warehouse Modeling Techniques&lt;/h2&gt;

&lt;p&gt;The three big approaches for modeling analytical data are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Inmon&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Top-down approach&lt;/li&gt;
      &lt;li&gt;Advocates for creating a centralized, integrated &lt;em&gt;Enterprise Data Warehouse&lt;/em&gt; (EDW)&lt;/li&gt;
      &lt;li&gt;Uses a normalized structure (3NF) for the core warehouse where data is organized by subject reflecting the overall business structure&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Data Marts&lt;/em&gt; are created from the EDW as needed for analytical needs&lt;/li&gt;
      &lt;li&gt;The popular option for modeling the data mart is a &lt;strong&gt;Star Schema&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Rules how to build data warehouse, store and organise data (Bill Inmon, 1990):
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;Integrated&lt;/strong&gt; = other data sources&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Subject oriented&lt;/strong&gt; = reorganise the data per subject&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Time variant&lt;/strong&gt; = data warehouse contains historical data&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Non volatile&lt;/strong&gt; = data warehouse remains stable between refreshes
Continuing with the auto dealership example, an example of a star schema of the EDW is shown below:&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/19_star_schema_auto_dealership.png&quot; alt=&quot;star schema of an auto dealership&quot; /&gt;
  &lt;figcaption&gt;Figure 3: Star schema of an auto dealership &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Kimball&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Bottom up approach&lt;/li&gt;
      &lt;li&gt;Focuses on building data marts that address specific business processes making the data mart the data warehouse itself&lt;/li&gt;
      &lt;li&gt;Uses a &lt;strong&gt;Star or Snowflake Schema&lt;/strong&gt; for the design of the data marts&lt;/li&gt;
      &lt;li&gt;Data is modulated with two general types of tables: &lt;strong&gt;Facts&lt;/strong&gt; and &lt;strong&gt;Dimensions&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;A &lt;strong&gt;slowly changing dimension (SCD)&lt;/strong&gt; is necessary to track changes in dimensions&lt;/li&gt;
      &lt;li&gt;SCD three most common ones:
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;Type 1&lt;/strong&gt;
            &lt;ul&gt;
              &lt;li&gt;Overwrite existing dimension records. This is super simple and means you have no access to the deleted historical dimension records&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Type 2&lt;/strong&gt;
            &lt;ul&gt;
              &lt;li&gt;Keep a full history of dimension records. When a record changes, that specific record is flagged as changed, and a new dimension record is created that reflects the current status of the attributes&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Type 3&lt;/strong&gt;
            &lt;ul&gt;
              &lt;li&gt;A type 3 SCD is similar to a type 2 SCD, but instead of creating a new Row, a change in a type 3 SCD creates a new field
Applying the dimensional modeling approach to our example will result, as shown below, in a &lt;em&gt;Sales&lt;/em&gt; fact table representing sales transactions with numeric measures (facts) and several dimension tables that provide the context for the facts with descriptive attributes.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/19_dimensional_model_auto_dealership.png&quot; alt=&quot;dimensional model of an auto dealership&quot; /&gt;
  &lt;figcaption&gt;Figure 4: Dimensional model of an auto dealership &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data Vault&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Data Vaults organize data into three different types: &lt;strong&gt;hubs&lt;/strong&gt;, &lt;strong&gt;links&lt;/strong&gt;, and &lt;strong&gt;satellites&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Hubs represent core business entities. The primary key of Hub tables is usually derived by a combination of business concept ID, load date, and other metadata information&lt;/li&gt;
          &lt;li&gt;Links represent relationships between hubs. It has only the join keys. It is like a Factless Fact table in the dimensional model. No attributes - just join keys&lt;/li&gt;
          &lt;li&gt;Satellites store attributes about hubs or links. They have descriptive information on core business entities. They are similar to a normalized version of a Dimension table&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Data Vault is a “write-optimized” modeling style&lt;/li&gt;
      &lt;li&gt;Great fit for data lakes and lakehouse approach&lt;/li&gt;
      &lt;li&gt;Supports agile development approaches:
        &lt;ul&gt;
          &lt;li&gt;It can be easily extended without massive refactoring like the dimensional models&lt;/li&gt;
          &lt;li&gt;Additional hubs can be easily added to links and additional satellites can be added to a Hub with minimal changes&lt;/li&gt;
          &lt;li&gt;Existing ETL jobs need significantly less refactoring when the data model changes&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;modeling-techniques-implementation-on-databricks-lakehouse-platform&quot;&gt;Modeling Techniques Implementation on Databricks Lakehouse Platform&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;data Lakehouse&lt;/strong&gt; is a new, open architecture that combines the best elements of data lakes and data warehouses. The Databricks Lakehouse is a large-scale enterprise-level platform that can host many use cases and data products. Therefore, it can support many different data modeling styles for different purposes and both normalized Data Vault (write-optimized) and denormalized dimensional models (read-optimized) data modeling styles have their place.&lt;/p&gt;

&lt;p&gt;The application of both techniques can be especially recognized through the lenses of the &lt;strong&gt;Medallion Architecture&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The medallion architecture is a data design pattern used to logically organize data in a lakehouse, with the goal of incrementally and progressively improving the structure and quality of data as it flows through each layer of the architecture (from Bronze ⇒ Silver ⇒ Gold layer tables).&lt;/p&gt;

&lt;p&gt;The following diagram summarizes the mapping of different layers, their purpose, and applied modeling techniques in each:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/19_data_lakehouse_architecture.png&quot; alt=&quot;medallion architecture with used modeling techniques in each stage&quot; /&gt;
  &lt;figcaption&gt;Figure 5: Data lakehouse architecture and modeling techniques - &lt;a href=&quot;https://www.databricks.com/blog/2022/06/24/data-warehousing-modeling-techniques-and-their-implementation-on-the-databricks-lakehouse-platform.html&quot;&gt;Image Source&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;First data is landed in the Bronze layer in raw format using the same models of source systems in order to get converted to delta lake format. Next it flows into the Silver layer where it gets aggregated using more normalized model. Finally, the gold layer is meant for read-optimized presentation layer using denormalized models.&lt;/p&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;In this article we covered the three main data warehouse modeling techniques and relevant design concepts and how they are applied in some form of combination taking the example of Databricks lakehouse platform.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.snowflake.com/guides/difference-between-data-warehouse-and-data-mart/&quot;&gt;https://www.snowflake.com/guides/difference-between-data-warehouse-and-data-mart/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.databricks.com/glossary/medallion-architecture&quot;&gt;https://www.databricks.com/glossary/medallion-architecture&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.databricks.com/blog/2022/06/24/prescriptive-guidance-for-implementing-a-data-vault-model-on-the-databricks-lakehouse-platform.html&quot;&gt;https://www.databricks.com/blog/2022/06/24/prescriptive-guidance-for-implementing-a-data-vault-model-on-the-databricks-lakehouse-platform.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/what-is/data-modeling/&quot;&gt;https://aws.amazon.com/what-is/data-modeling/&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><category term="Data Architecture" /><summary type="html">In this article we will go over the big three approaches for modeling analytical data.</summary></entry><entry><title type="html">Preparation Guide for Google Cloud Professional Data Engineer Certification</title><link href="https://www.firasesbai.com/articles/2023/11/19/gcp-data-engineer-certification.html" rel="alternate" type="text/html" title="Preparation Guide for Google Cloud Professional Data Engineer Certification" /><published>2023-11-19T00:00:00+00:00</published><updated>2023-11-19T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2023/11/19/gcp-data-engineer-certification</id><content type="html" xml:base="https://www.firasesbai.com/articles/2023/11/19/gcp-data-engineer-certification.html">&lt;p&gt;&lt;em&gt;This article contains a collection of notes, mind maps and resources to support you while preparing for the google cloud professional data engineer certification.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Disclaimer&lt;/em&gt;&lt;/strong&gt;: The new Professional Data Engineer exam will be live starting November 13. The new version reflects updates to Google Cloud’s data storing, data sharing, and data governance and has less emphasis on operationalizing machine learning models. 
That being said, I believe most of the content is still relevant and can serve as a guide to assist you as you begin your preparation.&lt;/p&gt;

&lt;p&gt;So brace yourselves, this is gonna be a rather long post filled with too many images extracted from different parts of the mind maps I used for my preparation in order to make them easy to read and follow.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#google-cloud&quot; id=&quot;markdown-toc-google-cloud&quot;&gt;Google Cloud&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#infrastructure&quot; id=&quot;markdown-toc-infrastructure&quot;&gt;Infrastructure&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#vpc-networks&quot; id=&quot;markdown-toc-vpc-networks&quot;&gt;VPC Networks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#data-transfer-services&quot; id=&quot;markdown-toc-data-transfer-services&quot;&gt;Data Transfer Services&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#resource-manager&quot; id=&quot;markdown-toc-resource-manager&quot;&gt;Resource Manager&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#security&quot; id=&quot;markdown-toc-security&quot;&gt;Security&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#compute&quot; id=&quot;markdown-toc-compute&quot;&gt;Compute&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#storage&quot; id=&quot;markdown-toc-storage&quot;&gt;Storage&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#ingestion-and-processing&quot; id=&quot;markdown-toc-ingestion-and-processing&quot;&gt;Ingestion and Processing&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#data-pipelines-management&quot; id=&quot;markdown-toc-data-pipelines-management&quot;&gt;Data Pipelines Management&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#data-governance&quot; id=&quot;markdown-toc-data-governance&quot;&gt;Data Governance&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#analytics&quot; id=&quot;markdown-toc-analytics&quot;&gt;Analytics&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#machine-learning&quot; id=&quot;markdown-toc-machine-learning&quot;&gt;Machine Learning&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ingestion-and-pocessing&quot; id=&quot;markdown-toc-ingestion-and-pocessing&quot;&gt;Ingestion and Pocessing&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#pubsub&quot; id=&quot;markdown-toc-pubsub&quot;&gt;Pub/Sub&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dataproc&quot; id=&quot;markdown-toc-dataproc&quot;&gt;Dataproc&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dataflow&quot; id=&quot;markdown-toc-dataflow&quot;&gt;Dataflow&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#storage-1&quot; id=&quot;markdown-toc-storage-1&quot;&gt;Storage&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#cloud-storage&quot; id=&quot;markdown-toc-cloud-storage&quot;&gt;Cloud Storage&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cloud-sql&quot; id=&quot;markdown-toc-cloud-sql&quot;&gt;Cloud SQL&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#query-insights&quot; id=&quot;markdown-toc-query-insights&quot;&gt;Query Insights&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cloud-spanner&quot; id=&quot;markdown-toc-cloud-spanner&quot;&gt;Cloud Spanner&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#firestore&quot; id=&quot;markdown-toc-firestore&quot;&gt;Firestore&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#datastore&quot; id=&quot;markdown-toc-datastore&quot;&gt;Datastore&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#memorystore&quot; id=&quot;markdown-toc-memorystore&quot;&gt;Memorystore&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bigtable&quot; id=&quot;markdown-toc-bigtable&quot;&gt;Bigtable&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bigquery&quot; id=&quot;markdown-toc-bigquery&quot;&gt;BigQuery&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;script src=&quot;/js/visualizations/mind-map.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;/js/visualizations/create-chart.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;google-cloud&quot;&gt;Google Cloud&lt;/h2&gt;

&lt;p&gt;Before we dive into the characteristics of Google Cloud services that will enable professional data engineers to design, build and operationalize data processing systems, let’s start with a 10,000-foot view on different topics that may be included in the exam presented in the below interactive mindmap:&lt;/p&gt;

&lt;div id=&quot;mindmap-container&quot;&gt;&lt;/div&gt;
&lt;script&gt;
    createChart(&quot;mindmap-container&quot;, &quot;/assets/data/2023-11-19-gcp-data-engineer-certification/google-cloud.json&quot;, &quot;mindmap&quot;, {
      width: 800,
      height: 600,
      nodeColor: &quot;#fefae0&quot;,
      nodeBorderColor: &quot;#333&quot;,
      linkColor: &quot;#aaa&quot;,
      linkWidth: 2,
      textFontSize: &quot;14px&quot;,
      textColor: &quot;#444&quot;
    });
&lt;/script&gt;

&lt;figure&gt;
   &lt;figcaption&gt;Figure 1: 10,000 View on Google Cloud Professional Data Engineer Exam Topics&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In the coming sections, we will cover each topic from the mindmap separately.&lt;/p&gt;

&lt;h3 id=&quot;infrastructure&quot;&gt;Infrastructure&lt;/h3&gt;

&lt;p&gt;Google Cloud services are available in different locations divided into &lt;strong&gt;Regions&lt;/strong&gt;.
Regions contain multiple &lt;strong&gt;Zones&lt;/strong&gt; where the resources are deployed and are isolated from one another so that failures in one zone do not affect other zones in a region. 
Most regions have at least three zones and can have more. All regions have at least two zones.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_regions.png&quot; alt=&quot;world map of google cloud region locations&quot; /&gt;
  &lt;figcaption&gt;Figure 2: Google Cloud Regions - &lt;a href=&quot;https://cloud.google.com/about/locations#lightbox-regions-map&quot;&gt;Image Source&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Google data centers are connected with Google’s own high-speed network. Google is the only cloud provider that owns all the fiber connecting its data center together. A huge amount of the world’s internet traffic goes through Google’s network.&lt;/p&gt;

&lt;p&gt;In addition to the data centers, there are points of presence all over the world. They allow access to Google’s network where all messages are encrypted, secure and very fast.&lt;/p&gt;

&lt;p&gt;In addition to the POPs, Google runs a global caching system or CDN that consists of hundreds of more nodes. You can easily take advantage of this CDN to cache your content, thus increasing your application performance and decreasing your networking cost.&lt;/p&gt;

&lt;h3 id=&quot;vpc-networks&quot;&gt;VPC Networks&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_vpc_networks.png&quot; alt=&quot;mindmap of topics related to VPC networks&quot; /&gt;
  &lt;figcaption&gt;Figure 3: Google Cloud Platform VPC Networks&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;data-transfer-services&quot;&gt;Data Transfer Services&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_data_transfer_services.png&quot; alt=&quot;mindmap of topics related to data transfer services&quot; /&gt;
  &lt;figcaption&gt;Figure 4: Google Cloud Platform Data Transfer Services&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;resource-manager&quot;&gt;Resource Manager&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_resource_manager.png&quot; alt=&quot;mindmap of topics related to resource manager&quot; /&gt;
  &lt;figcaption&gt;Figure 5: Google Cloud Platform Resource Manager&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;security&quot;&gt;Security&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_security.png&quot; alt=&quot;mindmap of topics related to security&quot; /&gt;
  &lt;figcaption&gt;Figure 6: Security in Google Cloud Platform&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;compute&quot;&gt;Compute&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_compute.png&quot; alt=&quot;mindmap of topics related to compute&quot; /&gt;
  &lt;figcaption&gt;Figure 7: Google Cloud Platform Compute&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;storage&quot;&gt;Storage&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_storage.png&quot; alt=&quot;mindmap of topics related to storage&quot; /&gt;
  &lt;figcaption&gt;Figure 8: Google Cloud Platform Storage&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;ingestion-and-processing&quot;&gt;Ingestion and Processing&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_ingestion_and_processing.png&quot; alt=&quot;mindmap of topics related to ingestion and processing&quot; /&gt;
  &lt;figcaption&gt;Figure 9: Ingestion and Processing in Google Cloud Platform&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;data-pipelines-management&quot;&gt;Data Pipelines Management&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_data_pipelines_management.png&quot; alt=&quot;mindmap of topics related to data pipelines management&quot; /&gt;
  &lt;figcaption&gt;Figure 10: Data Pipelines Management in Google Cloud Platform Data&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;data-governance&quot;&gt;Data Governance&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_data_governance.png&quot; alt=&quot;mindmap of topics related to data governance&quot; /&gt;
  &lt;figcaption&gt;Figure 11: Data Governance in Google Cloud Platform&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;analytics&quot;&gt;Analytics&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_analytics.png&quot; alt=&quot;mindmap of topics related to analytics&quot; /&gt;
  &lt;figcaption&gt;Figure 12: Analytics in Google Cloud Platform&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_machine_learning.png&quot; alt=&quot;mindmap of topics related to machine learning&quot; /&gt;
  &lt;figcaption&gt;Figure 13: Machine Learning in Google Cloud Platform&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;ingestion-and-pocessing&quot;&gt;Ingestion and Pocessing&lt;/h2&gt;

&lt;p&gt;As a professional data engineer, designing data processing systems requires building and operationalizing data pipelines by choosing the appropriate services to integrate new data sources and processing the data in batch or streaming fashion. In this section, we deep dive into services that will allow you to ingest data in real time and build data processing systems whether you are migrating on premises workloads or starting from scratch.&lt;/p&gt;

&lt;div id=&quot;mindmap-container-ingestion-and-processing&quot;&gt;&lt;/div&gt;
&lt;script&gt;
    createChart(&quot;mindmap-container-ingestion-and-processing&quot;, &quot;/assets/data/2023-11-19-gcp-data-engineer-certification/ingestion-and-processing.json&quot;, &quot;mindmap&quot;, {
      width: 800,
      height: 600,
      nodeColor: &quot;#fefae0&quot;,
      nodeBorderColor: &quot;#333&quot;,
      linkColor: &quot;#aaa&quot;,
      linkWidth: 2,
      textFontSize: &quot;14px&quot;,
      textColor: &quot;#444&quot;
    });
&lt;/script&gt;

&lt;figure&gt;
   &lt;figcaption&gt;Figure 14: Ingestion and Processing Topics&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;pubsub&quot;&gt;Pub/Sub&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_pub_sub.png&quot; alt=&quot;mindmap of topics related to pub sub&quot; /&gt;
  &lt;figcaption&gt;Figure 15: Pub/Sub&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;dataproc&quot;&gt;Dataproc&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_dataproc.png&quot; alt=&quot;mindmap of topics related to dataproc part 1&quot; /&gt;
  &lt;figcaption&gt;Figure 16: Dataproc Part 1/2&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_dataproc_2.png&quot; alt=&quot;mindmap of topics related to dataproc part 2&quot; /&gt;
  &lt;figcaption&gt;Figure 17: Dataproc Part 2/2&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;dataflow&quot;&gt;Dataflow&lt;/h3&gt;

&lt;p&gt;It allows you to execute your Apache Beans pipelines on Google Cloud.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A managed service that provides the resources necessary to create pipelines
    &lt;ul&gt;
      &lt;li&gt;Defines &lt;em&gt;HOW&lt;/em&gt; to run the pipeline:
        &lt;ul&gt;
          &lt;li&gt;Optimizes the graph by fusing transforms for example for best execution path&lt;/li&gt;
          &lt;li&gt;Breaks jobs into units of work&lt;/li&gt;
          &lt;li&gt;Schedules them to various workers&lt;/li&gt;
          &lt;li&gt;Optimization is always ongoing
            &lt;ul&gt;
              &lt;li&gt;Units of work are continually rebalanced mid job which provides fault tolerance&lt;/li&gt;
              &lt;li&gt;autoscaling mid job&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Resources –both compute and storage– are deployed on demand and on a per job basis&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The Apache Beam SDK, which provides the programming environment to make the creation of streaming and batch pipelines easier
    &lt;ul&gt;
      &lt;li&gt;Defines &lt;em&gt;WHAT&lt;/em&gt; has to be done&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_dataflow.png&quot; alt=&quot;mindmap of topics related to dataproc part 1&quot; /&gt;
  &lt;figcaption&gt;Figure 18: Datflow Part 1/3&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_dataflow_2.png&quot; alt=&quot;mindmap of topics related to dataproc part 2&quot; /&gt;
  &lt;figcaption&gt;Figure 19: Datflow Part 2/3&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_dataflow_3.png&quot; alt=&quot;mindmap of topics related to dataproc part 3&quot; /&gt;
  &lt;figcaption&gt;Figure 20: Datflow Part 3/3&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;storage-1&quot;&gt;Storage&lt;/h2&gt;

&lt;p&gt;One of a data engineer’s most important skills is choosing the right storage technology, which involves knowing how to use managed services and having a solid grasp of storage performance and pricing. To further optimize your data processing and cut expenses, consider data modeling, schema design, and data life cycle management. In this section we will delve into the many storage options provided by Google Cloud.&lt;/p&gt;

&lt;div id=&quot;mindmap-container-storage&quot;&gt;&lt;/div&gt;
&lt;script&gt;
    createChart(&quot;mindmap-container-storage&quot;, &quot;/assets/data/2023-11-19-gcp-data-engineer-certification/storage.json&quot;, &quot;mindmap&quot;, {
      width: 800,
      height: 600,
      nodeColor: &quot;#fefae0&quot;,
      nodeBorderColor: &quot;#333&quot;,
      linkColor: &quot;#aaa&quot;,
      linkWidth: 2,
      textFontSize: &quot;14px&quot;,
      textColor: &quot;#444&quot;
    });
&lt;/script&gt;

&lt;figure&gt;
   &lt;figcaption&gt;Figure 21: Storage Topics&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;cloud-storage&quot;&gt;Cloud Storage&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_cloud_storage.png&quot; alt=&quot;mindmap of topics related to cloud storage part 1&quot; /&gt;
  &lt;figcaption&gt;Figure 22: Cloud Storage Part 1/2&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_cloud_storage_2.png&quot; alt=&quot;mindmap of topics related to cloud storage part 2&quot; /&gt;
  &lt;figcaption&gt;Figure 23: Cloud Storage Part 2/2&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Google Cloud provides 3 ways to manage the KEK encryption key:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Google Managed Encryption Keys - GMEK: automatic encryption using Cloud KMS (Key Management Service)&lt;/li&gt;
  &lt;li&gt;Customer Managed Encryption Keys - CMEK: you control the creation and existance of the KEK key in KMS&lt;/li&gt;
  &lt;li&gt;Customer Supplied Encryption Keys - CSEK: you provide the KEK key&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cloud-sql&quot;&gt;Cloud SQL&lt;/h3&gt;

&lt;p&gt;Cloud SQL is a fully managed relational database service for:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;MySQL&lt;/li&gt;
  &lt;li&gt;PostgreSQL&lt;/li&gt;
  &lt;li&gt;Microsoft SQL&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_cloud_sql.png&quot; alt=&quot;mindmap of topics related to cloud slq&quot; /&gt;
  &lt;figcaption&gt;Figure 24: Cloud SQL&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;query-insights&quot;&gt;Query Insights&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_insights.png&quot; alt=&quot;mindmap of topics related to query insights&quot; /&gt;
  &lt;figcaption&gt;Figure 25: Query Insights&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;cloud-spanner&quot;&gt;Cloud Spanner&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_cloud_spanner.png&quot; alt=&quot;mindmap of topics related to cloud spanner&quot; /&gt;
  &lt;figcaption&gt;Figure 26: Cloud Spanner&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;firestore&quot;&gt;Firestore&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_firestore.png&quot; alt=&quot;mindmap of topics related to firestore&quot; /&gt;
  &lt;figcaption&gt;Figure 27: Firestore&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;datastore&quot;&gt;Datastore&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_datastore.png&quot; alt=&quot;mindmap of topics related to datastore&quot; /&gt;
  &lt;figcaption&gt;Figure 28: Datastore&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;memorystore&quot;&gt;Memorystore&lt;/h3&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_memorystore.png&quot; alt=&quot;mindmap of topics related to memorystore&quot; /&gt;
  &lt;figcaption&gt;Figure 29: Memorystore&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;bigtable&quot;&gt;Bigtable&lt;/h3&gt;

&lt;p&gt;Bigtable is a fully managed NoSQL database service. It is suitable for:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Storing &amp;gt; 1TB&lt;/li&gt;
  &lt;li&gt;High Throughput&lt;/li&gt;
  &lt;li&gt;Low latency random data access&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigtable.png&quot; alt=&quot;mindmap of topics related to bigtable&quot; /&gt;
  &lt;figcaption&gt;Figure 30: Bigtable&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;bigquery&quot;&gt;BigQuery&lt;/h2&gt;

&lt;div id=&quot;mindmap-container-bigquery&quot;&gt;&lt;/div&gt;
&lt;script&gt;
    createChart(&quot;mindmap-container-bigquery&quot;, &quot;/assets/data/2023-11-19-gcp-data-engineer-certification/bigquery.json&quot;, &quot;mindmap&quot;, {
      width: 800,
      height: 600,
      nodeColor: &quot;#fefae0&quot;,
      nodeBorderColor: &quot;#333&quot;,
      linkColor: &quot;#aaa&quot;,
      linkWidth: 2,
      textFontSize: &quot;14px&quot;,
      textColor: &quot;#444&quot;
    });
&lt;/script&gt;

&lt;figure&gt;
   &lt;figcaption&gt;Figure 31: BigQuery Topics&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The last section is solely dedicated to BigQuery. BigQuery is a serverless and cost-effective data warehouse. It is deeply integrated with the GCP’s analytical and data processing offering, allowing customers to build an enterprise ready cloud native data warehouse. BigQuery is part of Google Cloud’s comprehensive data analytics platform that covers the analytics value chain from Ingest, process and store to advanced analytics and collaboration.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery.png&quot; alt=&quot;mindmap of topics related to bigquery part 1&quot; /&gt;
  &lt;figcaption&gt;Figure 32: BigQuery Part 1/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery_2.png&quot; alt=&quot;mindmap of topics related to bigquery part 2&quot; /&gt;
  &lt;figcaption&gt;Figure 33: BigQuery Part 2/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery_3.png&quot; alt=&quot;mindmap of topics related to bigquery part 3&quot; /&gt;
  &lt;figcaption&gt;Figure 34: BigQuery Part 3/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery_4.png&quot; alt=&quot;mindmap of topics related to bigquery part 4&quot; /&gt;
  &lt;figcaption&gt;Figure 35: BigQuery Part 4/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery_5.png&quot; alt=&quot;mindmap of topics related to bigquery part 5&quot; /&gt;
  &lt;figcaption&gt;Figure 36: BigQuery Part 5/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery_6.png&quot; alt=&quot;mindmap of topics related to bigquery part 6&quot; /&gt;
  &lt;figcaption&gt;Figure 37: BigQuery Part 6/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery_7.png&quot; alt=&quot;mindmap of topics related to bigquery part 7&quot; /&gt;
  &lt;figcaption&gt;Figure 38: BigQuery Part 7/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery_8.png&quot; alt=&quot;mindmap of topics related to bigquery part 8&quot; /&gt;
  &lt;figcaption&gt;Figure 39: BigQuery Part 8/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery_9.png&quot; alt=&quot;mindmap of topics related to bigquery part 9&quot; /&gt;
  &lt;figcaption&gt;Figure 40: BigQuery Part 9/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery_10.png&quot; alt=&quot;mindmap of topics related to bigquery part 10&quot; /&gt;
  &lt;figcaption&gt;Figure 41: BigQuery Part 10/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery_11.png&quot; alt=&quot;mindmap of topics related to bigquery part 11&quot; /&gt;
  &lt;figcaption&gt;Figure 42: BigQuery Part 11/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/18_gcp_bigquery_12.png&quot; alt=&quot;mindmap of topics related to bigquery part 12&quot; /&gt;
  &lt;figcaption&gt;Figure 43: BigQuery Part 12/12&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;Developer Cheat Sheet:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://googlecloudcheatsheet.withgoogle.com/&quot;&gt;https://googlecloudcheatsheet.withgoogle.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Cloud Girl:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/priyankavergadia/GCPSketchnote&quot;&gt;https://github.com/priyankavergadia/GCPSketchnote&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Google Cloud Product list:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://cloud.google.com/terms/services&quot;&gt;https://cloud.google.com/terms/services&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;21 products explained under 2 minutes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://cloud.google.com/blog/topics/inside-google-cloud/21-google-cloud-tools-each-explained-under-2-minutes&quot;&gt;https://cloud.google.com/blog/topics/inside-google-cloud/21-google-cloud-tools-each-explained-under-2-minutes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GCP Data Engineer Study Guide:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/xg1990/GCP-Data-Engineer-Study-Guide/blob/master/GCP%20Data%20Engineer.pdf&quot;&gt;https://github.com/xg1990/GCP-Data-Engineer-Study-Guide/blob/master/GCP%20Data%20Engineer.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Data Engineering Cheat Sheet on GCP:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ml874/Data-Engineering-on-GCP-Cheatsheet/blob/master/data_engineering_on_GCP.pdf&quot;&gt;https://github.com/ml874/Data-Engineering-on-GCP-Cheatsheet/blob/master/data_engineering_on_GCP.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Schema design best practices for Bigtable:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://cloud.google.com/bigtable/docs/schema-design&quot;&gt;https://cloud.google.com/bigtable/docs/schema-design&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Optimize query computation for BigQuery:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://cloud.google.com/bigquery/docs/best-practices-performance-compute&quot;&gt;https://cloud.google.com/bigquery/docs/best-practices-performance-compute&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Cloud Computing" /><summary type="html">This article contains a collection of notes, mind maps and resources to support you while preparing for the google cloud professional data engineer certification.</summary></entry><entry><title type="html">Learning How to Learn</title><link href="https://www.firasesbai.com/notes/2023/10/21/learning-how-to-learn.html" rel="alternate" type="text/html" title="Learning How to Learn" /><published>2023-10-21T00:00:00+00:00</published><updated>2023-10-21T00:00:00+00:00</updated><id>https://www.firasesbai.com/notes/2023/10/21/learning-how-to-learn</id><content type="html" xml:base="https://www.firasesbai.com/notes/2023/10/21/learning-how-to-learn.html">&lt;p&gt;&lt;em&gt;Notes from the Learning How to Learn Book By Barbara Oakley.&lt;/em&gt;&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/17_learning_how_to_learn.png&quot; alt=&quot;mindmap containing important topics from the learning how to learn book&quot; /&gt;
  &lt;figcaption&gt;Figure 1: Learning How to Learn Mindmap&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#summary&quot; id=&quot;markdown-toc-summary&quot;&gt;Summary&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#main-takeaways&quot; id=&quot;markdown-toc-main-takeaways&quot;&gt;Main Takeaways&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1-what-is-learning&quot; id=&quot;markdown-toc-1-what-is-learning&quot;&gt;1/ What is learning?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2-memory&quot; id=&quot;markdown-toc-2-memory&quot;&gt;2/ Memory&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#working-memory&quot; id=&quot;markdown-toc-working-memory&quot;&gt;Working Memory&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#long-term-memory&quot; id=&quot;markdown-toc-long-term-memory&quot;&gt;Long Term Memory&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3-how-to-improve-your-memory&quot; id=&quot;markdown-toc-3-how-to-improve-your-memory&quot;&gt;3/ How to improve your memory&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#4-chunking&quot; id=&quot;markdown-toc-4-chunking&quot;&gt;4/ Chunking&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#what-is-a-chunk&quot; id=&quot;markdown-toc-what-is-a-chunk&quot;&gt;What is a Chunk?&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#how-to-form-a-chunk&quot; id=&quot;markdown-toc-how-to-form-a-chunk&quot;&gt;How to form a chunk?&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#the-value-of-a-library-of-chunks&quot; id=&quot;markdown-toc-the-value-of-a-library-of-chunks&quot;&gt;The value of a Library of Chunks&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#interleaving&quot; id=&quot;markdown-toc-interleaving&quot;&gt;Interleaving&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#5-procrastination&quot; id=&quot;markdown-toc-5-procrastination&quot;&gt;5/ Procrastination&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#what-is-a-habit&quot; id=&quot;markdown-toc-what-is-a-habit&quot;&gt;What is a habit?&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#harnessing-your-zombies&quot; id=&quot;markdown-toc-harnessing-your-zombies&quot;&gt;Harnessing your zombies&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#6-juggling-life-and-learning&quot; id=&quot;markdown-toc-6-juggling-life-and-learning&quot;&gt;6/ Juggling Life and Learning&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In a world that’s constantly evolving, the ability to learn efficiently and effectively is a skill that can unlock doors to personal and professional growth. Whether you’re a student striving for academic excellence, a professional seeking to stay competitive in your career, or simply someone who wants to enhance their ability to acquire new knowledge, the &lt;strong&gt;&lt;a href=&quot;https://barbaraoakley.com/books/learning-how-to-learn/&quot;&gt;Learn How to Learn book&lt;/a&gt;&lt;/strong&gt; is a valuable resource that can empower you to do just that.&lt;/p&gt;

&lt;p&gt;This book has garnered attention from learners of all backgrounds. It delves into the science behind learning and equips you with proven strategies to enhance your learning abilities. As we explore the key takeaways from this book, you’ll discover how to overcome common obstacles, develop effective study habits, and harness the power of your brain to grasp new concepts with confidence.&lt;/p&gt;

&lt;h2 id=&quot;main-takeaways&quot;&gt;Main Takeaways&lt;/h2&gt;

&lt;h3 id=&quot;1-what-is-learning&quot;&gt;1/ What is learning?&lt;/h3&gt;

&lt;p&gt;There are two different modes of thinking:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Focused&lt;/strong&gt;: concentrate intently on something you’re trying to learn or to understand&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Diffuse&lt;/strong&gt;: relaxed thinking style related to a set of neural resting states&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When you’re learning something new, especially something that’s a bit challenging, your mind needs to be able to go back and forth between the two different learning modes. Study something hard by focusing intently. Then take a break or at least change your focus to something different for a while. During this time of seeming relaxation, your brain’s diffuse mode has a chance to work away in the background and help you out with your conceptual understanding.&lt;/p&gt;

&lt;p&gt;Salvador Dali and Thomas Edison are two well-known innovators who leveraged interleaving between these phases. They would hold onto objects while falling asleep in their chairs. They would think of a problem and once they lost consciousness the object they held would fall to the floor and wake them up. Many of their imaginative ideas came from this state.&lt;/p&gt;

&lt;h3 id=&quot;2-memory&quot;&gt;2/ Memory&lt;/h3&gt;

&lt;h4 id=&quot;working-memory&quot;&gt;Working Memory&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The part of memory that has to do with what you’re immediately and consciously processing in your mind. It is centred out of the prefrontal cortex. There are also connections to other parts of your brain so you can access long-term memories.&lt;/li&gt;
  &lt;li&gt;Working memory holds only about &lt;strong&gt;four items&lt;/strong&gt; at a time.&lt;/li&gt;
  &lt;li&gt;You often need to keep repeating what you’re trying to work with so it stays in your working memory; for example repeat a phone number to yourself until you have a chance to write it down. You may find yourself shutting your eyes to keep any other items from intruding into the limited slots of your working memory as you concentrate.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;long-term-memory&quot;&gt;Long Term Memory&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Wide storage warehouse distributed over the brain.&lt;/li&gt;
  &lt;li&gt;It is immense and has so many items that they can bury each other.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To move information into long-term memory, it often takes time and practice. To help with this process use a technique called &lt;strong&gt;Spaced Repetition&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Research has shown that when you first try to put an item of information in long-term memory, you need to revisit it at least a few times to increase the chances that you’ll be able to find it later when you might need it.&lt;/p&gt;

&lt;p&gt;You might be surprised to learn that just plain being awake creates toxic products in your brain.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sleep&lt;/strong&gt; is your brain’s way of keeping itself healthy. When you sleep, your brain cells shrink. This causes an increase in the space between your brain cells. Fluid can flow past these cells and wash the toxins out.&lt;/p&gt;

&lt;p&gt;Sleep is also an important part of the memory and learning process. It seems that during sleep, your brain tidies up ideas and concepts you’re thinking about and learning. It erases the less important parts of memory and simultaneously strengthens areas that you need or want to remember. During sleep, your brain also rehearses some of the tougher parts of whatever you’re trying to learn, going over and over neural patterns to deepen and strengthen them.&lt;br /&gt;
Sleep has also been shown to make a remarkable difference in your ability to figure out difficult problems and to understand what you’re trying to learn.&lt;/p&gt;

&lt;h3 id=&quot;3-how-to-improve-your-memory&quot;&gt;3/ How to improve your memory&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Recall&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Simply looking away and seeing what you can recall from the material you’ve just read is a more productive approach than simply rereading. Using recall, mental retrieval of the key ideas, rather than passive rereading, will make your study time more focused and effective. The only time rereading text seems to be effective, is if you let time pass between the rereading, so that it becomes more of an exercise in spaced repetition.&lt;/li&gt;
      &lt;li&gt;Another tip is recalling material when you are outside your usual place of study can also help you strengthen your grasp of the material. You don’t realize it, but when you are learning something new you can often take in subliminal cues for the room and the space around you at the time you were originally learning the material.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mnemonics&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Let’s say you want to remember four plants that help ward off vampires; garlic, rose, hawthorn, and mustard. The first letters abbreviate to GRHM. so all you need to do to remember is to use the image of Graham cracker.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Highlighting and Underlining&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;It must be done very carefully. Otherwise it can not only be ineffective, but also misleading. If you do mark up the text, try to look for main ideas before making any marks. And try to keep your underlining or highlighting to a minimum. On the other hand, words or notes in a margin that synthesizes key concepts are a very good idea.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Visual/Spatial Memory&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Our mind is built for visual/spatial memory. For example, if you were asked to look around a house you never visited before, you’d soon have a sense of the general furniture layout. We can tap into this memory by associating strange and funny images to memorize a concept. We can use spaced repetition to commit this relationship to long term memory. The more senses you use the easier it is to commit to memory.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Memory Palace Technique&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Is a particularly powerful way of grouping things you want to remember. It involves calling to mind a familiar place like the layout of your house and using it as a visual notepad where you can deposit the concept images that you want to remember. You would imagine yourself walking through a place you know well, coupled with shockingly memorable images of what you want to remember.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Memory tricks allow people to expand their working memory with easy access to long term memory. What’s more, the memory process itself becomes an exercise in creativity. The more you memorize using these innovative techniques, the more creative you become.&lt;/p&gt;

&lt;h3 id=&quot;4-chunking&quot;&gt;4/ Chunking&lt;/h3&gt;

&lt;h4 id=&quot;what-is-a-chunk&quot;&gt;What is a Chunk?&lt;/h4&gt;

&lt;p&gt;Chunking is the mental leap that helps you unite bits of information together through meaning. The new logical whole makes the chunk easier to remember, and also makes it easier to fit the chunk into the larger picture of what you’re learning.&lt;/p&gt;

&lt;p&gt;Once you chunk an idea, a concept, or an action, you don’t need to remember all the little underlying details. You’ve got the main idea, the chunk, and that’s enough.&lt;/p&gt;

&lt;h4 id=&quot;how-to-form-a-chunk&quot;&gt;How to form a chunk?&lt;/h4&gt;

&lt;p&gt;The best chunks are the ones that are so well ingrained that you don’t even have to consciously think about connecting the neural patterns together. That actually is the point of making complex ideas, movements or reactions into a single chunk.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Focus your undivided attention on the information you want to chunk (limited short term memory)&lt;/li&gt;
  &lt;li&gt;Understand the basic idea of what you want to chunk.
    &lt;ul&gt;
      &lt;li&gt;It helps hold the underlying memory traces together&lt;/li&gt;
      &lt;li&gt;It creates broad encompassing traces that can link to other memory traces&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Practice and repetition with context
    &lt;ul&gt;
      &lt;li&gt;Context means going beyond the initial problem and seeing more broadly&lt;/li&gt;
      &lt;li&gt;Helps you see how your new formed chunks fit in the bigger picture&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It is as if you have an attention octopus that slips its tentacles through those four slots of working memory when necessary to help you make connections to information that you might have in various parts of your brain.&lt;/p&gt;

&lt;h4 id=&quot;the-value-of-a-library-of-chunks&quot;&gt;The value of a Library of Chunks&lt;/h4&gt;

&lt;p&gt;Basically what people do to enhance their knowledge and gain expertise, is to gradually build the number of chunks in their mind, valuable bits of information they can piece together in new and creative ways.&lt;/p&gt;

&lt;p&gt;Chunks can also help you understand new concepts. This is because when you grasp one chunk, you’ll find that that chunk can be related in surprising ways to similar chunks, not only in that field but also in very different fields. This idea is called transfer.&lt;/p&gt;

&lt;p&gt;If you have a library of concepts and solutions internalized as chunked patterns, you can think of it as a collection or a library of neural patterns. When you’re trying to figure something out, if you have a good library of these chunks, you can more easily skip to the right solution by, metaphorically speaking, listening to whispers from your diffuse mode. Your diffuse mode can help you connect two or more chunks together in new ways to solve novel problems. Another way to think of it is this, as you build each chunk it is filling in a part of your larger knowledge picture, but if you don’t practice with your growing chunks, they can remain faint and it’s harder to put together the big picture of what you’re trying to learn.&lt;/p&gt;

&lt;p&gt;There are two ways to figure something out or to solve problems. First, through sequential step-by-step reasoning and second, through a more holistic intuition. Sequential thinking where each small step leads deliberately towards a solution, involves the focused mode. Intuition on the other hand often seems to require this creative diffuse mode linking of several seemingly different focused mode thoughts. Most difficult problems and concepts are grasped through intuition, because these new ideas make a leap away from what you’re familiar with. Keep in mind that the diffuse modes, semi-random way of making connections means that the solutions it provides should be very carefully verified using the focused mode. Intuitive insights aren’t always correct.&lt;/p&gt;

&lt;h4 id=&quot;interleaving&quot;&gt;Interleaving&lt;/h4&gt;

&lt;p&gt;Mastering a new subject means learning not only the basic chunks, but also learning how to select and use different chunks. The best way to learn is by practicing jumping back and forth between problems or situations that require different techniques or strategies. 
Interleaving is extraordinarily important. Although practice and repetition is important in helping build solid neural patterns to draw on, it’s interleaving that starts building flexibility and creativity.&lt;/p&gt;

&lt;h3 id=&quot;5-procrastination&quot;&gt;5/ Procrastination&lt;/h3&gt;

&lt;p&gt;Procrastination is the act of unnecessarily and voluntarily delaying or postponing something despite knowing that there will be negative consequences for doing so.&lt;/p&gt;

&lt;p&gt;Procrastination is an easy habit to develop because of the reward. It shares features with addiction. It offers temporary excitement and relief from sometimes boring reality.&lt;/p&gt;

&lt;h4 id=&quot;what-is-a-habit&quot;&gt;What is a habit?&lt;/h4&gt;

&lt;p&gt;Habit is an energy saver for us. It allows us to free our mind for other types of activities. You go into this habitual zombie far more often than you might think, that’s the point of habit. You don’t have to think in a focused manner about what you are doing while you are performing the habit, it saves energy. 
Habits can be good and bad, they can be brief like absently brushing back your hair or they can be long for example when you take a walk or watch television for a few hours after you get home from work.&lt;/p&gt;

&lt;p&gt;You can think of habits as having 4 parts:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;The cue&lt;/strong&gt;: this is the trigger that launches you into zombie mode&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The routine&lt;/strong&gt;: what we do in reaction to that cue. This is your zombie mode. Zombie responses can be useful, harmless or sometimes harmful.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The reward&lt;/strong&gt;: every habit develops and continues because it rewards us. It gives us an immediate little feeling of pleasure.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The belief&lt;/strong&gt;: habits have power because your belief in them. To change a habit you need to change your underlying belief.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you find yourself avoiding certain tasks because they make you feel uncomfortable, you should know there’s another helpful way to re-frame things and that’s to learn to focus on process not product. Process means the flow of time and the habits and actions associated with that flow of time. As in, I’m going to spend 20 minutes working. Product is an outcome, for example, a homework assignment that you need to finish. To prevent procrastination you want to avoid concentrating on the product. Instead your attention should be on building processes. 
The essential idea here is that the zombie habitual part of your brain likes processes because it can march mindlessly along.&lt;/p&gt;

&lt;h4 id=&quot;harnessing-your-zombies&quot;&gt;Harnessing your zombies&lt;/h4&gt;

&lt;p&gt;The trick to overriding a habit is to look to change your reaction to a cue. The only place you need to apply will power is to change your reaction to the cue. To understand that, it helps to go back through the four components of habit and we analyze them from the perspective of procrastination:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Cue
    &lt;ul&gt;
      &lt;li&gt;It usually falls into one of the following categories: location, time, how you feel and reactions, either to other people or to something that just happened. Do you look something up on the web and then find yourself web surfing? The issue with procrastination is that, because it’s an automatic habit, you’re often unaware that you’ve begun to procrastinate. You can prevent the most damaging cues by shutting off your cell phone or keeping away from the internet and other distractions for brief periods of time, as when you’re doing a pomodoro.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Routine
    &lt;ul&gt;
      &lt;li&gt;The key to rewiring is to have a plan. Developing a new ritual can be helpful. Some students make it a habit to leave their phone in their car when they head for class which removes a potent distraction.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The reward
    &lt;ul&gt;
      &lt;li&gt;It helps to add a new reward if you want to overcome your previous cravings. Only once your brain starts expecting that reward, will the important rewiring take place that will allow you to create new habits.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The belief
    &lt;ul&gt;
      &lt;li&gt;The most important part of changing your procrastination habit is the belief that you can do it.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;6-juggling-life-and-learning&quot;&gt;6/ Juggling Life and Learning&lt;/h3&gt;

&lt;p&gt;A good way for you to keep perspective about what you’re trying to learn and accomplish is to once a week write a brief weekly list of key tasks in a planner journal. Then each day on another page of your planner, write a list of the tasks that you can reasonably work on or accomplish (The list should be short, 6 items for example where some are process oriented and others product oriented). Try to write this daily task list the evening before. Why? Research has shown that this helps your subconscious to grapple with the tasks on the list, so you can figure out how to accomplish them. Writing the list before you go to sleep enlists your zombies to help you accomplish the items on the list the next day. If you don’t write your tasks down on a list, they lurk at the edge of the four or so slots in your working memory, taking up valuable mental real estate. But once you make a task list, it frees working memory for problem-solving.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thanks for reading, I hope you enjoyed it!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://barbaraoakley.com/books/learning-how-to-learn/&quot;&gt;https://barbaraoakley.com/books/learning-how-to-learn/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.brainfacts.org/&quot;&gt;https://www.brainfacts.org/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Procrastination&quot;&gt;https://en.wikipedia.org/wiki/Procrastination&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="notes" /><category term="General" /><summary type="html">Notes from the Learning How to Learn Book By Barbara Oakley.</summary></entry><entry><title type="html">Data Processing Architectures: Lambda vs Kappa</title><link href="https://www.firasesbai.com/articles/2023/09/24/data-processing-architectures-lambda-vs-kappa.html" rel="alternate" type="text/html" title="Data Processing Architectures: Lambda vs Kappa" /><published>2023-09-24T00:00:00+00:00</published><updated>2023-09-24T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2023/09/24/data-processing-architectures-lambda-vs-kappa</id><content type="html" xml:base="https://www.firasesbai.com/articles/2023/09/24/data-processing-architectures-lambda-vs-kappa.html">&lt;p&gt;&lt;em&gt;In this article we will explore two popular data processing architectures: Lambda and Kappa. We will take a look at their components, key differences and how to choose between them.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In our data-driven era, the ability to harness the power of data has become a pivotal competitive advantage for businesses and organizations across industries. The vast volumes of information generated daily present both opportunities and challenges. How do we efficiently process, analyze, and derive insights from this deluge of data in real-time, without drowning in complexity?&lt;/p&gt;

&lt;p&gt;This is where data processing architectures come into play, offering structured approaches to these challenges. In this blog post, we will explore two prominent contenders in the realm of data processing: the &lt;strong&gt;Lambda&lt;/strong&gt; and &lt;strong&gt;Kappa&lt;/strong&gt; architectures.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#lambda-architecture&quot; id=&quot;markdown-toc-lambda-architecture&quot;&gt;Lambda Architecture&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#advantages-and-disadvantages&quot; id=&quot;markdown-toc-advantages-and-disadvantages&quot;&gt;Advantages and Disadvantages&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#kappa-architecture&quot; id=&quot;markdown-toc-kappa-architecture&quot;&gt;Kappa Architecture&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#advantages-and-disadvantages-1&quot; id=&quot;markdown-toc-advantages-and-disadvantages-1&quot;&gt;Advantages and Disadvantages&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#choosing-the-right-architecture&quot; id=&quot;markdown-toc-choosing-the-right-architecture&quot;&gt;Choosing the Right Architecture&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;lambda-architecture&quot;&gt;Lambda Architecture&lt;/h2&gt;

&lt;p&gt;Lambda architecture was introduced by &lt;em&gt;Nathan Marz&lt;/em&gt; to address the challenges of data processing in a scalable and fault-tolerant manner.
The architecture takes an event stream and forks/duplicates it into two relatively independent layers called the &lt;strong&gt;Batch Layer&lt;/strong&gt; and the &lt;strong&gt;Speed Layer&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Batch layer&lt;/strong&gt; takes incoming data, combines it with historical data, and recomputes the results by iterating over the entire dataset thus allowing the system to give the most accurate results. However, the results are achieved at the expense of high latency due to the long computation time.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Speed Layer&lt;/strong&gt; on the other hand is used to provide a low-latency, near-real-time result. It performs incremental updates on data that was not processed in the last batch of the Batch Layer.&lt;/p&gt;

&lt;p&gt;The results from both systems constitute the &lt;strong&gt;Serving Layer&lt;/strong&gt;. It is responsible for serving queryable, up-to-date results to users or applications. In this layer, the query aims at merging and analyzing data from both the Batch Layer view and the incremental flow view from the Speed Layer.&lt;/p&gt;

&lt;p&gt;There are two variations on this: a &lt;strong&gt;unified serving layer&lt;/strong&gt; with one database for both outputs or &lt;strong&gt;separate serving layers&lt;/strong&gt; with two different databases, one optimized for real time and the other optimized for batch updates.&lt;/p&gt;

&lt;p&gt;The following diagram shows the lambda architecture at a high level:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/16_lambda_architecture.png&quot; alt=&quot;diagram showing high level components of lambda architecture&quot; /&gt;
  &lt;figcaption&gt;Figure 1: High Level Lambda Architecture&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;advantages-and-disadvantages&quot;&gt;Advantages and Disadvantages&lt;/h3&gt;

&lt;p&gt;One of the key challenges in streaming is the reprocessing of the data. This can be due to code changes because your application evolves and you need to update the business logic or because you found a bug and you need to fix it. In either way, you will need to recompute your output to see the effect of these changes. The batch layer in the lambda architecture addresses this challenge by having a complete history of immutable data. In addition, the usage of two separate systems for processing data makes the lambda architecture flexible, easily scalable and fault tolerant. For instance, it can be used for a variety of use cases, including real-time analytics using the stream processing system and machine learning where models can leverage the large volume of data through the batch layer to generate more accurate results. If one system fails, say the batch processing system, the other can continue to operate providing real time insights into the data. Lastly, both systems can be scaled independently by either adding more nodes to the cluster or adding more streams.&lt;/p&gt;

&lt;p&gt;However, managing two separate processing systems is very complex. We need to provision and manage the infrastructure for two distributed systems including monitoring and logging which increases the cost and operations efforts of storage, compute and networking. Also, we need to align the business logic across streaming and batch codebases resulting in writing the same logic in two places with, most likely, different languages. This leads to difficult debugging and a challenge in validating data quality and making sure that the algorithms in each layer are matching.&lt;/p&gt;

&lt;p&gt;So, what’s different in Kappa architecture?&lt;/p&gt;

&lt;h2 id=&quot;kappa-architecture&quot;&gt;Kappa Architecture&lt;/h2&gt;

&lt;p&gt;The Kappa architecture was introduced by &lt;em&gt;Jay Kreps&lt;/em&gt;, co-founder and CEO at Confluent, a company built around the open source messaging system Apache Kafka, as a response to some of the challenges and complexities associated with the Lambda Architecture. 
The Kappa Architecture primarily focuses on stream processing simplifying the complexity of maintaining two systems with a single technology stack, referred to as &lt;strong&gt;Stream Processing Layer&lt;/strong&gt; in the diagram below, that can perform both real-time and batch processing:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/16_kappa_architecture.png&quot; alt=&quot;diagram showing high level components of kappa architecture&quot; /&gt;
  &lt;figcaption&gt;Figure 2: High Level Kappa Architecture&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;advantages-and-disadvantages-1&quot;&gt;Advantages and Disadvantages&lt;/h3&gt;

&lt;p&gt;The shift to a single stream processing system to handle both real-time and batch processing makes the Kappa architecture simpler, more efficient and cost effective than the lambda architecture. Having a single source of truth to all the data reduces both the burden of maintaining two separate systems and two codebases as well as the underlying costs. People can now develop, test, debug, and operate their systems on top of a single processing framework such as Apache Kafka.&lt;/p&gt;

&lt;p&gt;Stream processing is considered a paradigm shift from the traditional batch data processing. Therefore, it goes without saying that the Kappa architecture presents some challenges and limitations. In fact, processing out of order data or intricate joins combining many streams causes difficulties when transforming data in a streaming method. On top of that, data reprocessing which is now running using a single codebase, on the same framework, and with the same input data, still comes with some tradeoffs. As Jay Kreps detailed in his 
&lt;a href=&quot;https://www.oreilly.com/radar/questioning-the-lambda-architecture/&quot;&gt;original post&lt;/a&gt;, we can leverage Apache Kafka retention period (30 days for example) and take the retained data as an input to a second instance of the streaming process that will produce a new output table with the reprocessed data. However, this approach depends heavily on the configured retention period value and is limited in cases where we need to fix the algorithm or deploy a change like adding a new field that goes beyond the span of the retention period.&lt;/p&gt;

&lt;h2 id=&quot;choosing-the-right-architecture&quot;&gt;Choosing the Right Architecture&lt;/h2&gt;

&lt;p&gt;So when should we use one architecture or the other? As is often the case, it depends on some peculiarities of the implemented application.&lt;/p&gt;

&lt;p&gt;A very simple case is when the algorithms used for real-time and historical data are identical and implementable on streaming. It is then clearly very advantageous to use the same codebase to process historical and real-time data, and hence use the Kappa Architecture.
If the algorithms used to process historical data and real-time data are not always identical. Here, the choice between Lambda and Kappa becomes a tradeoff between the performance benefits of batch processing over a simpler codebase.&lt;/p&gt;

&lt;p&gt;Some examples of use cases where Kappa architecture is a good fit include fraud detection to detect fraudulent transactions in real time, process data from IoT devices in real time or recommendation engines used to to provide personalized recommendations to users in real time.&lt;/p&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;Lambda and Kappa are two popular data processing architectures that can be used to handle huge data. The ideal architecture relies on the individual needs for a given use case. We have discussed some benefits as well as drawbacks and limitations of each design to assist you in making your decision. Real-time insights are more important for businesses that want to become data-driven, which has increased the popularity of event streaming architecture. Batch processing will not go away, therefore it is essential to view the two architectures as complementing solutions rather than one being a cure for all ills.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.kai-waehner.de/blog/2021/09/23/real-time-kappa-architecture-mainstream-replacing-batch-lambda/&quot;&gt;https://www.kai-waehner.de/blog/2021/09/23/real-time-kappa-architecture-mainstream-replacing-batch-lambda/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.oreilly.com/radar/questioning-the-lambda-architecture/&quot;&gt;https://www.oreilly.com/radar/questioning-the-lambda-architecture/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html&quot;&gt;http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><category term="Data Architecture" /><summary type="html">In this article we will explore two popular data processing architectures: Lambda and Kappa. We will take a look at their components, key differences and how to choose between them.</summary></entry><entry><title type="html">Understanding Modern Data Stack</title><link href="https://www.firasesbai.com/articles/2023/09/10/understanding-modern-data-stack.html" rel="alternate" type="text/html" title="Understanding Modern Data Stack" /><published>2023-09-10T00:00:00+00:00</published><updated>2023-09-10T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2023/09/10/understanding-modern-data-stack</id><content type="html" xml:base="https://www.firasesbai.com/articles/2023/09/10/understanding-modern-data-stack.html">&lt;p&gt;&lt;em&gt;In this article we will explore the modern data stack, a brief history that led to its adoption and a brief walkthrough of its components and objectives.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The modern data stack is designed to empower organizations to harness the full potential of their data assets, make data-driven decisions, and stay competitive in today’s data-centric business landscape. It represents a shift towards more agile, integrated, and scalable data management practices.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#a-brief-history&quot; id=&quot;markdown-toc-a-brief-history&quot;&gt;A Brief History&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-the-modern-data-stack&quot; id=&quot;markdown-toc-what-is-the-modern-data-stack&quot;&gt;What is the Modern Data Stack?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#objectives-of-the-modern-data-stack&quot; id=&quot;markdown-toc-objectives-of-the-modern-data-stack&quot;&gt;Objectives of the Modern Data Stack&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#components-of-the-modern-data-stack&quot; id=&quot;markdown-toc-components-of-the-modern-data-stack&quot;&gt;Components of the Modern Data Stack&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;a-brief-history&quot;&gt;A Brief History&lt;/h2&gt;

&lt;p&gt;The modern data stack as we currently know it is a very recent development in data. In fact the rise of the cloud data warehouse triggered by the release of Amazon Redshift in late 2012 is considered one of the key developments that led to the adoption of the modern data stack. Redshift was one of the early cloud-based data warehousing solutions that offered a highly scalable and cost-effective platform for storing and analyzing large datasets. Its introduction marked a shift away from traditional on-premises data warehousing and towards cloud-based solutions. All of the other solutions in the market today like Google BigQuery and Snowflake followed the revolution set by Amazon.&lt;/p&gt;

&lt;p&gt;Consequently this shift led to the move from &lt;em&gt;Extract Transform Load (ETL)&lt;/em&gt; to &lt;em&gt;Extract Load Transform (ELT)&lt;/em&gt; pipelines. As storage becomes cheaper and more accessible, there is no need to deal with data transformations before saving it in the traditional data warehouse. Organizations just dump their data in its raw format and only apply the transformations later when needed.&lt;/p&gt;

&lt;p&gt;The rise of the cloud data warehouse has not only contributed to the transition from ETL to ELT but also the widespread adoption of BI tools. These self serve solutions democratize data usage allowing more and more personas to access it and make data-driven business decisions.‍&lt;/p&gt;

&lt;h2 id=&quot;what-is-the-modern-data-stack&quot;&gt;What is the Modern Data Stack?&lt;/h2&gt;

&lt;p&gt;The modern data stack is a collection of tools and technologies used together to support the data flow starting from ingestion and integration of different data sources up to analysis in order to extract insights and help create data driven decisions. The particularity resides in the plug and play nature of its components and the overall ease of use without much infrastructure and data platform management overhead so that data is accessible for everyone to turn it into knowledge.&lt;/p&gt;

&lt;h2 id=&quot;objectives-of-the-modern-data-stack&quot;&gt;Objectives of the Modern Data Stack&lt;/h2&gt;

&lt;p&gt;The objectives of the modern data stack revolve around building a data infrastructure that enables organizations to efficiently and effectively manage their data, derive valuable insights, and make data-driven decisions.&lt;/p&gt;

&lt;p&gt;Here are the primary objectives of implementing a modern data stack:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Accommodate Growing Data - The modern data stack should be able to handle increasing data volumes, whether structured or unstructured, as organizations collect more data from various sources.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Flexibility and Agility&lt;/strong&gt;: Easily Adapt to Changing Needs - It should be flexible enough to adapt to changing business requirements, data sources, and processing methods without the need for a complete overhaul.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Integration&lt;/strong&gt;: Seamlessly Connect Data Sources: The stack should provide tools and processes for integrating data from diverse sources, including databases, applications, APIs, and more.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cost-Efficiency&lt;/strong&gt;: Optimize Resource Usage by minimising unnecessary resource usage by efficiently managing data storage and processing to control costs.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Interoperability&lt;/strong&gt;: Ensure Compatibility - Ensure that the various components of the stack can interoperate smoothly with each other and with external systems or tools.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cloud-Ready&lt;/strong&gt;: Leverage Cloud Infrastructure - Be compatible with cloud-based infrastructure to take advantage of scalability, cost-effectiveness, and the latest data services provided by cloud providers.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Performance and Reliability&lt;/strong&gt;: Maintain High Performance - Deliver reliable and high-performance data processing to support critical business operations.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Adaptability to Emerging Technologies&lt;/strong&gt;: Be Open to Innovation - Keep an eye on emerging technologies and trends, allowing for easy integration with new tools or platforms that may enhance the stack’s capabilities.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;components-of-the-modern-data-stack&quot;&gt;Components of the Modern Data Stack&lt;/h2&gt;

&lt;p&gt;In a previous blog post about the &lt;a href=&quot;https://www.firasesbai.com/articles/2023/03/01/data-engineering-101.html&quot;&gt;fundamentals of data engineering&lt;/a&gt; we tried to identify a common data flow that identifies the different stages including ingestion, storage, transformation, data management/governance, visualization and exploration  which are  involved in making data easily accessible.&lt;/p&gt;

&lt;p&gt;The components of the modern data stack can be perfectly mapped to the same diagram from the mentioned article, at least at a high level first, as shown below:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/15_modern_data_stack_example.png&quot; alt=&quot;diagram with boxes containing logos of tools and representing stages through which data flows&quot; /&gt;
  &lt;figcaption&gt;Figure 1: Example of Componentes of Modern Data Stack in Standard Data Flow&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Note that the specific tools are changing and evolving rapidly but they usually include some of the ones we chose as an example in the diagram. In addition, some vendor technologies fit beyond a single stage as presented in the diagram and offer more capabilities such as data governance and/or machine learning.&lt;/p&gt;

&lt;p&gt;However, this only captures the stack at a high level. In fact, there is no one-size-fits-all approach when it comes to selecting the best tools and technologies to deal with your data. Every organization has a different level of data maturity, different data teams, different structures, processes, and so on.&lt;/p&gt;

&lt;p&gt;Therefore, the stack can be enriched with a &lt;strong&gt;workflow  orchestration tool&lt;/strong&gt; such as &lt;a href=&quot;https://airflow.apache.org/&quot;&gt;Apache Airflow&lt;/a&gt; or &lt;a href=&quot;https://dagster.io/&quot;&gt;Dagster&lt;/a&gt; needed to schedule your transformation in an automated fashion depending on your required frequency.&lt;/p&gt;

&lt;p&gt;Also &lt;strong&gt;data observability&lt;/strong&gt; has become a key part of the modern data stack. It ensures data reliability by monitoring data quality and identifying potential data issues throughout the stack. Explaining this concept is beyond the scope of this article but we will have a dedicated blog post about. Some of the tools worth mentioning here include &lt;a href=&quot;https://www.montecarlodata.com/&quot;&gt;Monte Carlo&lt;/a&gt; and &lt;a href=&quot;https://www.datadoghq.com/&quot;&gt;Datadog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;In this article, we explored the concept of the modern data stack and its significance in the contemporary data landscape. We provided an overview of its main components and how they correlate to our standard data flow established in a previous article.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://preset.io/blog/modern-data-stack/&quot;&gt;https://preset.io/blog/modern-data-stack/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://preset.io/blog/reshaping-data-engineering/&quot;&gt;https://preset.io/blog/reshaping-data-engineering/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.getdbt.com/blog/future-of-the-modern-data-stack/&quot;&gt;https://www.getdbt.com/blog/future-of-the-modern-data-stack/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://a16z.com/2020/10/15/emerging-architectures-for-modern-data-infrastructure-2020/&quot;&gt;https://a16z.com/2020/10/15/emerging-architectures-for-modern-data-infrastructure-2020/&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><category term="Data Architecture" /><category term="Cloud Computing" /><summary type="html">In this article we will explore the modern data stack, a brief history that led to its adoption and a brief walkthrough of its components and objectives.</summary></entry><entry><title type="html">Turning Your Jekyll Blog into a Progressive Web App (PWA) on GitHub Pages: A Step-by-Step Guide</title><link href="https://www.firasesbai.com/articles/2023/08/21/turning-your-jekyll-blog-into-a-progressive-web-app-on-github-pages.html" rel="alternate" type="text/html" title="Turning Your Jekyll Blog into a Progressive Web App (PWA) on GitHub Pages: A Step-by-Step Guide" /><published>2023-08-21T00:00:00+00:00</published><updated>2023-08-21T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2023/08/21/turning-your-jekyll-blog-into-a-progressive-web-app-on-github-pages</id><content type="html" xml:base="https://www.firasesbai.com/articles/2023/08/21/turning-your-jekyll-blog-into-a-progressive-web-app-on-github-pages.html">&lt;p&gt;&lt;em&gt;In this guide, we’ll explore how to transform your Jekyll-based blog into a Progressive Web App, unlocking features such as offline access, fast loading, and a seamless user experience.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Progressive Web Apps (PWAs) represent a significant advancement in web application development, offering users a seamless and engaging experience that combines the best aspects of both web and native mobile applications. 
By transforming your Jekyll-based blog into a PWA, you’ll enhance user engagement, improve performance, and enable key features such as offline access.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#what-are-progressive-web-apps&quot; id=&quot;markdown-toc-what-are-progressive-web-apps&quot;&gt;What are Progressive Web Apps?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#key-attributes-of-pwas&quot; id=&quot;markdown-toc-key-attributes-of-pwas&quot;&gt;Key Attributes of PWAs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#successful-pwa-examples&quot; id=&quot;markdown-toc-successful-pwa-examples&quot;&gt;Successful PWA Examples&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#technical-features-of-pwas&quot; id=&quot;markdown-toc-technical-features-of-pwas&quot;&gt;Technical features of PWAs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#creating-a-manifest-file&quot; id=&quot;markdown-toc-creating-a-manifest-file&quot;&gt;Creating a Manifest File&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#implementing-service-workers&quot; id=&quot;markdown-toc-implementing-service-workers&quot;&gt;Implementing Service Workers&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#deploying-service-workers&quot; id=&quot;markdown-toc-deploying-service-workers&quot;&gt;Deploying Service Workers&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;what-are-progressive-web-apps&quot;&gt;What are Progressive Web Apps?&lt;/h2&gt;

&lt;p&gt;Platform-specific apps are developed for a specific operating system (OS) and/or class of devices, like an iOS or Android device. They are usually installed on the user’s device using the vendor’s app store. Websites on the other hand, can only be accessed by the user opening the browser and navigating to the site, and is highly dependent on network connectivity.&lt;/p&gt;

&lt;p&gt;So how does this relate to PWAs?&lt;/p&gt;

&lt;p&gt;Progressive web apps combine the best features of traditional websites and platform-specific apps. At their core, PWAs are web applications that take advantage of modern web technologies to deliver a reliable, fast, and immersive experience to users. Unlike traditional websites, PWAs can be installed on users’ devices, giving them a direct pathway to your content, even without a traditional app store. PWAs can be accessed through web browsers, but they offer the responsiveness and fluidity that users typically expect from native mobile applications.&lt;/p&gt;

&lt;h2 id=&quot;key-attributes-of-pwas&quot;&gt;Key Attributes of PWAs&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Offline Access&lt;/strong&gt;: One of the most significant advantages of PWAs is their ability to work offline or in low-network conditions. Users can still access content and navigate within the app, even when they’re not connected to the internet. This offline capability ensures that your content remains accessible, enhancing user satisfaction.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fast Loading&lt;/strong&gt;: PWAs are designed to load quickly, providing an almost instant experience to users. This is achieved through techniques like efficient caching, optimized assets, and lazy loading of content. Fast loading times lead to lower bounce rates and higher user retention.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Responsive Design&lt;/strong&gt;: PWAs are responsive by default, adapting to various screen sizes and orientations. This responsiveness ensures a consistent and visually appealing experience across devices, including smartphones, tablets, and desktops.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Engagement and Retention&lt;/strong&gt;: PWAs can be “installed” on users’ home screens or app drawers, creating a sense of ownership and encouraging repeated visits. This increased engagement can lead to higher retention rates, as users have easy access to your PWA.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;successful-pwa-examples&quot;&gt;Successful PWA Examples&lt;/h2&gt;

&lt;p&gt;Numerous companies have embraced PWAs to enhance user experience and drive business growth. For example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Pinterest&lt;/strong&gt;: Pinterest’s PWA increased user engagement, with faster load times leading to a 60% increase in user engagement and a 44% increase in user-generated ad revenue.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Alibaba&lt;/strong&gt;: Alibaba.com’s PWA achieved a 76% increase in conversions across browsers, with 14% more monthly active users on iOS and a 30% increase in mobile users.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more details, check the links in the resources section.&lt;/p&gt;

&lt;h2 id=&quot;technical-features-of-pwas&quot;&gt;Technical features of PWAs&lt;/h2&gt;

&lt;p&gt;Because PWAs are websites, they have the same basic features as any other website: at least one HTML page, which very probably loads some CSS and JavaScript.&lt;/p&gt;

&lt;p&gt;Beyond that, a PWA has some additional features:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A &lt;strong&gt;web app manifest file&lt;/strong&gt;, which, at a minimum, provides information that the browser needs to install the PWA, such as the app name and icon.&lt;/li&gt;
  &lt;li&gt;A &lt;strong&gt;service worker&lt;/strong&gt;, which, at a minimum, provides a basic offline experience.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Having this in mind, a blog is nothing more than static HTML, CSS, and Javascript files. This makes it a prime candidate for adding PWA features which is the focus of the rest of this blog post.&lt;/p&gt;

&lt;p&gt;We will be adding these features to a blog built using Jekyll, a free and open source static site generator, and hosted on Github Pages. For more in depth guides on how I started my journey building this blog, you can check my 4 Parts series starting from &lt;a href=&quot;https://www.firasesbai.com/articles/2021/10/07/how-i-started-this-blog.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;creating-a-manifest-file&quot;&gt;Creating a Manifest File&lt;/h2&gt;

&lt;p&gt;The Web App Manifest is a JSON document that provides application metadata such as its name, icon, and other details, which browsers can use when adding the PWA to the home screen.&lt;/p&gt;

&lt;p&gt;If you have previously generated a favicon to your blog using &lt;a href=&quot;https://realfavicongenerator.net/&quot;&gt;https://realfavicongenerator.net/&lt;/a&gt; or similar, you should already have a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site.webmanifest&lt;/code&gt; file that might be complete or miss a few properties. Otherwise, you can just use the following link &lt;a href=&quot;https://app-manifest.firebaseapp.com/&quot;&gt;https://app-manifest.firebaseapp.com/&lt;/a&gt; for reference or to generate its content.&lt;/p&gt;

&lt;p&gt;In either cases, the next step would be to add a reference to the manifest file under the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;default.html&lt;/code&gt; file in the head section as follow:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;link&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;manifest&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;href&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/assets/favicon/site.webmanifest&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The location of your manifest file might differ and you should update it accordingly. In my case, the manifest file is placed under assets along with the icons and favicon.&lt;/p&gt;

&lt;h2 id=&quot;implementing-service-workers&quot;&gt;Implementing Service Workers&lt;/h2&gt;

&lt;p&gt;A service worker is a powerful web technology that acts as a scriptable network proxy between a web application (such as a website) and the browser. It runs in the background, separate from the main web page, and allows you to intercept and control network requests and responses, enabling advanced features like offline access, caching, and push notifications in web applications.&lt;/p&gt;

&lt;p&gt;We will be using &lt;a href=&quot;https://developer.chrome.com/docs/workbox/&quot;&gt;Workbox&lt;/a&gt; which is a set of Javascript modules created by Google that simplifies and addresses a specific aspect of service worker development.&lt;/p&gt;

&lt;p&gt;1- Download and install the latest version of Node.js from the &lt;a href=&quot;https://nodejs.org/&quot;&gt;official website&lt;/a&gt;, and npm will be installed automatically as part of the Node.js package.&lt;/p&gt;

&lt;p&gt;2- Install Workbox CLI by running the following command:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;  &lt;span class=&quot;n&quot;&gt;npm&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workbox&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cli&lt;/span&gt; 
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;3- Use the Workbox Wizard to create a service worker by executing the following command inside the directory of your blog:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;  &lt;span class=&quot;n&quot;&gt;workbox&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wizard&lt;/span&gt; 
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The Workbox CLI wizard will guide you through setting up the service worker by choosing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_site&lt;/code&gt; directory as the root of your app and selecting the type of files the service worker should pre-cache.&lt;/p&gt;

&lt;p&gt;At the end of this step, you should have a file named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;workbox-config.js&lt;/code&gt; created at the root of the project.&lt;/p&gt;

&lt;p&gt;4- Use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;workbox-confiog.js&lt;/code&gt; file to generate the service worker by executing the following command:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;  &lt;span class=&quot;n&quot;&gt;workbox&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateSW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workbox&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;js&lt;/span&gt;
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;A new file named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sw.js&lt;/code&gt; inside the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_site&lt;/code&gt; folder will be generated.&lt;/p&gt;

&lt;p&gt;5- Create a new javascript file used to register your service worker. Place this file under &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/js/service-worker.js&lt;/code&gt; in your Jekyll project’s root directory.&lt;/p&gt;

&lt;p&gt;The content of this file is the following:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;    &lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Only&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trigger&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workers&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;are&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;supported&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'serviceWorker'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;navigator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Wait&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;until&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loaded&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;before&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;registering&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;addEventListener&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'load'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Register&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;worker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'s scope.
        navigator.serviceWorker.register('&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;js&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;', { scope: '&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;' })
            // Output success/failure of registration.
            .then(() =&amp;gt; console.log('&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Service&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Worker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;registered&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scope&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'))
            .catch(() =&amp;gt; console.error('&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Service&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Worker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;registration&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failed&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In order to register the service worker and enable its functionality, you’ll need to include this code snippet to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;default.html&lt;/code&gt; file, which is a layout file included in all your pages, as follow:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;     
    &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text/javascript&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/js/service-worker.js&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/script&amp;gt;
  
  &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;At this point if your development server is already running, you can navigate to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://localhost:4000&lt;/code&gt; and use developer tools to verify that:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;By checking the Offline box under &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Application -&amp;gt; Manifest -&amp;gt; Service worker&lt;/code&gt; you can still access your site.&lt;/li&gt;
  &lt;li&gt;Under &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Application -&amp;gt; Cache Storage&lt;/code&gt; new entry have been created&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The newly created cache entry indicates that the predetermined assets in the workbox-config file are added to the cache during the service worker installation. This is called &lt;strong&gt;precaching&lt;/strong&gt; and is commonly used to ensure that essential resources are available offline and to improve the initial loading performance of your application.&lt;/p&gt;

&lt;p&gt;For more details on some precaching considerations you can check this &lt;a href=&quot;https://developer.chrome.com/docs/workbox/precaching-dos-and-donts/&quot;&gt;article&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another type of caching is &lt;strong&gt;runtime caching&lt;/strong&gt;. It  involves caching resources dynamically during the runtime of your web application, i.e., when users interact with the application. Unlike precaching, runtime caching allows you to define caching strategies for specific URLs or URL patterns based on different criteria such as network requests, HTTP methods, and more.&lt;/p&gt;

&lt;p&gt;There some common runtime caching strategies that are out of the scope of this blog post. For more details you can refer to the &lt;a href=&quot;https://developer.chrome.com/docs/workbox/modules/workbox-strategies/&quot;&gt;workbox documentation&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;deploying-service-workers&quot;&gt;Deploying Service Workers&lt;/h2&gt;

&lt;p&gt;Knowing that Jekyll regenerates the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_site&lt;/code&gt; folder with each change you make to your files, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sw.js&lt;/code&gt; will be lost and we have to regenerate it each time. Since our site is hosted on Github Pages, we can leverage &lt;strong&gt;Github Actions&lt;/strong&gt; to automate the execution of these commands as part of the pipeline building and deploying your site.&lt;/p&gt;

&lt;p&gt;An example of a Github Actions workflow can be found &lt;a href=&quot;https://github.com/firasesbai/firasesbai.github.io/blob/master/.github/workflows/github-pages.yml&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;Congratulations! You’ve successfully transformed your Jekyll blog into a powerful Progressive Web App. By implementing service workers and a manifest file, you’ve unlocked offline access and responsive design, making your content accessible to users even when they’re offline. Remember, this is just the beginning and there’s a wealth of additional features and optimizations you can explore to further enhance your PWA.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps/Guides/What_is_a_progressive_web_app&quot;&gt;https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps/Guides/What_is_a_progressive_web_app&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://web.dev/what-are-pwas/&quot;&gt;https://web.dev/what-are-pwas/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/dev-channel/a-pinterest-progressive-web-app-performance-case-study-3bd6ed2e6154&quot;&gt;https://medium.com/dev-channel/a-pinterest-progressive-web-app-performance-case-study-3bd6ed2e6154&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://web.dev/alibaba/&quot;&gt;https://web.dev/alibaba/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://fredrickb.com/2019/07/25/turning-jekyll-site-into-a-progressive-web-app/&quot;&gt;https://fredrickb.com/2019/07/25/turning-jekyll-site-into-a-progressive-web-app/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://sevic.dev/caching-service-worker-workbox/&quot;&gt;https://sevic.dev/caching-service-worker-workbox/&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Blogging" /><summary type="html">In this guide, we’ll explore how to transform your Jekyll-based blog into a Progressive Web App, unlocking features such as offline access, fast loading, and a seamless user experience.</summary></entry></feed>