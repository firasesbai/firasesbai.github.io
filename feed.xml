<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://www.firasesbai.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.firasesbai.com/" rel="alternate" type="text/html" /><updated>2025-09-17T19:22:38+00:00</updated><id>https://www.firasesbai.com/feed.xml</id><title type="html">Firas Esbai</title><subtitle>The Blog and Portfolio of Firas Esbai.
</subtitle><author><name>Firas Esbai</name></author><entry><title type="html">101 Apache Kafka Cheatsheet</title><link href="https://www.firasesbai.com/articles/2025/09/15/apache-kafka-101.html" rel="alternate" type="text/html" title="101 Apache Kafka Cheatsheet" /><published>2025-09-15T00:00:00+00:00</published><updated>2025-09-15T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2025/09/15/apache-kafka-101</id><content type="html" xml:base="https://www.firasesbai.com/articles/2025/09/15/apache-kafka-101.html">&lt;p&gt;&lt;em&gt;101 Apache Kafka Cheatsheet&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-apache-kafka&quot; id=&quot;markdown-toc-what-is-apache-kafka&quot;&gt;What is Apache Kafka?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#core-concepts&quot; id=&quot;markdown-toc-core-concepts&quot;&gt;Core Concepts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#key-features&quot; id=&quot;markdown-toc-key-features&quot;&gt;Key Features&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#message-delivery-semantics&quot; id=&quot;markdown-toc-message-delivery-semantics&quot;&gt;Message delivery semantics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#use-cases&quot; id=&quot;markdown-toc-use-cases&quot;&gt;Use Cases&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;what-is-apache-kafka&quot;&gt;What is Apache Kafka?&lt;/h2&gt;

&lt;p&gt;Apache Kafka is an open-source distributed event streaming platform. It consists of highly scalable and fault tolerant &lt;strong&gt;servers&lt;/strong&gt; enabling real-time data ingestion and processing between &lt;strong&gt;clients&lt;/strong&gt; that are decoupled (source and target) and can scale independently.&lt;/p&gt;

&lt;h2 id=&quot;core-concepts&quot;&gt;Core Concepts&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Cluster&lt;/strong&gt;: A group of Kafka broker servers that work together to manage and distribute data.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Broker&lt;/strong&gt;: A Kafka server that stores data and serves client requests (producers and consumers). Multiple brokers form a cluster.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Topic&lt;/strong&gt;: A named stream of records to which producers send data and from which consumers read. Topics are split into partitions.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Partition&lt;/strong&gt;: Each topic is divided into partitions, which are ordered, immutable sequences of messages. Partitions enable parallelism and scalability.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Producer&lt;/strong&gt;: An application or service that sends (publishes) records to Kafka topics.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Message Key&lt;/strong&gt;: producers can choose to send a key with records then messages for that key will always go to the same partition.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Consumer&lt;/strong&gt;: An application or service that reads (subscribes to) records from Kafka topics.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Consumer Group&lt;/strong&gt;: A group of consumers that work together to consume data from a topic, ensuring each message is processed only once by the group.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ZooKeeper&lt;/strong&gt;: Used for managing and coordinating Kafka brokers (leader election, metadata, etc.). 
Note: Newer Kafka versions are moving toward removing ZooKeeper dependency.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Offset&lt;/strong&gt;: A unique identifier for each message within a partition, used by consumers to keep track of read messages.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Replication&lt;/strong&gt;: Each partition can be replicated across multiple brokers to ensure durability and high availability.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/24_apache_kafka_architecture.png&quot; alt=&quot;Example Kafka Topic &amp;amp; Producers &quot; /&gt;
  &lt;figcaption&gt;Figure 1: Example Kafka Topic &amp;amp; Producers - &lt;a href=&quot;https://kafka.apache.org/documentation/#gettingStarted&quot;&gt;Image Source&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;key-features&quot;&gt;Key Features&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;High Throughput&lt;/strong&gt;: Capable of handling millions of messages per second.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Low Latency&lt;/strong&gt;: Designed for real-time streaming and processing.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Scales horizontally by adding brokers and partitions.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fault Tolerance&lt;/strong&gt;: Data is replicated across brokers; if one fails, another can take over.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Durability&lt;/strong&gt;: Messages are persisted on disk and replicated.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Decoupling&lt;/strong&gt;: Producers and consumers are independent, enabling flexible architectures.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Multiple APIs&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;Admin API&lt;/em&gt;: manage and inspect topics, brokers, and other Kafka objects.&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Producer API&lt;/em&gt;: Publish data to topics.&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Consumer API&lt;/em&gt;: Subscribe to and process data from topics.&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Streams API&lt;/em&gt;: Build stream processing applications.&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Connect API&lt;/em&gt;: Integrate with external systems (databases, file systems, etc.)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;message-delivery-semantics&quot;&gt;Message delivery semantics&lt;/h2&gt;

&lt;p&gt;Apache Kafka provides three primary message delivery semantics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;At-most-once&lt;/strong&gt;: Messages are delivered zero or one time. Some messages may be lost, but never delivered more than once.
Typical usage in applicaitons with high-throughput, low latency requirements and risk of data loss.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;At-least-once&lt;/strong&gt;: Messages are delivered one or more times. No message is lost, but duplicates may occur. 
Typical usage in data pipelines where no data loss is acceptable, and duplicates can be handled.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Exactly-once&lt;/strong&gt;: Each message is delivered once and only once. No data loss or duplicate delivery.
Ensures no message loss or duplication, but with increased latency and configuration overhead
Typical usage in Financial transactions and critical data flows.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How kafka achieves these semantics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;At-most-once:
    &lt;ul&gt;
      &lt;li&gt;Producer sends messages without waiting for acknowledgment (acks=0).&lt;/li&gt;
      &lt;li&gt;If a failure occurs before delivery, messages may be lost.&lt;/li&gt;
      &lt;li&gt;Consumer commits its offset before processing messages. If it crashes after committing but before processing, messages are lost.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;At-least-once:
    &lt;ul&gt;
      &lt;li&gt;Producer waits for acknowledgment (acks=1 or acks=all).&lt;/li&gt;
      &lt;li&gt;If acknowledgment is not received, the producer retries, which can result in duplicate messages.&lt;/li&gt;
      &lt;li&gt;Consumers must be idempotent to handle possible duplicates&lt;/li&gt;
      &lt;li&gt;Consumer commits offset after processing. If it crashes before committing, messages may be processed again after recovery (duplicates possible).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Exactly-once:
    &lt;ul&gt;
      &lt;li&gt;Producer uses idempotence and transactions; each message is written once even if retried.&lt;/li&gt;
      &lt;li&gt;Consumers and producers must be properly configured for transactional processing. Offset commits and output are part of the same transaction, ensuring atomicity.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;use-cases&quot;&gt;Use Cases&lt;/h2&gt;

&lt;p&gt;Some of the popular use cases for Apache Kafka include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Messaging&lt;/strong&gt;: replacement to traditional message broker for decoupling data processing between producers and consumers.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Website activity tracking&lt;/strong&gt;: this is the original use case where a user’s site activity like page views, clicks and searches events are published to central topics 
and available for consumption from real time analytics and insights applications.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Metrics&lt;/strong&gt;: similarly apache kafka is used in aggregating statistics from distributed applications to produce centralized feeds of operational data.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Log aggregation&lt;/strong&gt;: used as a replacement for log aggregation solutions giving cleaner abstraction of log or event data as a stream of messages.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><summary type="html">101 Apache Kafka Cheatsheet</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" /><media:content medium="image" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">101 Apache Airflow Cheatsheet</title><link href="https://www.firasesbai.com/articles/2025/09/08/apache-airflow-101.html" rel="alternate" type="text/html" title="101 Apache Airflow Cheatsheet" /><published>2025-09-08T00:00:00+00:00</published><updated>2025-09-08T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2025/09/08/apache-airflow-101</id><content type="html" xml:base="https://www.firasesbai.com/articles/2025/09/08/apache-airflow-101.html">&lt;p&gt;&lt;em&gt;101 Apache Airflow Cheatsheet.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-apache-airflow&quot; id=&quot;markdown-toc-what-is-apache-airflow&quot;&gt;What is Apache Airflow?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#core-concepts&quot; id=&quot;markdown-toc-core-concepts&quot;&gt;Core Concepts&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#directed-acyclic-graphs-dags&quot; id=&quot;markdown-toc-directed-acyclic-graphs-dags&quot;&gt;Directed Acyclic Graphs (DAGs)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dag-run&quot; id=&quot;markdown-toc-dag-run&quot;&gt;DAG Run&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#tasks&quot; id=&quot;markdown-toc-tasks&quot;&gt;Tasks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#task-instances&quot; id=&quot;markdown-toc-task-instances&quot;&gt;Task Instances&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#variables&quot; id=&quot;markdown-toc-variables&quot;&gt;Variables&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#architecture-components&quot; id=&quot;markdown-toc-architecture-components&quot;&gt;Architecture Components&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#architecture-components-1&quot; id=&quot;markdown-toc-architecture-components-1&quot;&gt;Architecture Components&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;what-is-apache-airflow&quot;&gt;What is Apache Airflow?&lt;/h2&gt;

&lt;p&gt;Apache Airflow is an open-source workflow management platform designed to programmatically author, schedule, and monitor complex data pipelines.&lt;/p&gt;

&lt;h2 id=&quot;core-concepts&quot;&gt;Core Concepts&lt;/h2&gt;

&lt;h3 id=&quot;directed-acyclic-graphs-dags&quot;&gt;Directed Acyclic Graphs (DAGs)&lt;/h3&gt;

&lt;p&gt;The fundamental structure in Airflow, representing a collection of tasks with defined dependencies. Each DAG is defined in Python code and dictates the order of task execution based on their relationships. A DAG is a graph structure where tasks are represented as nodes, and the dependencies between these tasks are represented as directed edges. The “directed” aspect indicates that tasks have a specific order of execution, while “acyclic” means there are no loops or cycles, preventing infinite execution paths.&lt;/p&gt;

&lt;h3 id=&quot;dag-run&quot;&gt;DAG Run&lt;/h3&gt;

&lt;p&gt;A DAG Run is an object representing an instantiation of the DAG in time. Any time the DAG is executed, a DAG Run is created and all tasks inside it are executed. The status of the DAG Run depends on the tasks states. Each DAG Run is run separately from one another, meaning that you can have many runs of a DAG at the same time.&lt;/p&gt;

&lt;h3 id=&quot;tasks&quot;&gt;Tasks&lt;/h3&gt;

&lt;p&gt;Task is the  individual units of work within a DAG. Each task represents a single operation, such as data extraction, transformation, or loading (ETL). The relationships between tasks are established using dependency definitions. This can be done through:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Bitwise Operators: Using » to set downstream dependencies and « for upstream dependencies.&lt;/li&gt;
  &lt;li&gt;Methods: Using set_upstream() and set_downstream() methods to explicitly define task relationships.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are three common types of task:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Operators&lt;/strong&gt;, conceptually a template for predefined tasks that you can string together quickly to build most parts of your DAGs.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sensors&lt;/strong&gt;, a special subclass of Operators which are entirely about waiting for an external event to happen.&lt;/li&gt;
  &lt;li&gt;A &lt;strong&gt;TaskFlow-decorated&lt;/strong&gt; @task, which is a custom Python function packaged up as a Task.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To pass data between tasks you have three options:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;XComs&lt;/strong&gt; (“Cross-communications”), a system where you can have tasks push and pull small bits of metadata identified by a &lt;strong&gt;key&lt;/strong&gt; as well as the &lt;strong&gt;task_id&lt;/strong&gt; and &lt;strong&gt;dag_id&lt;/strong&gt; it came from.&lt;/li&gt;
  &lt;li&gt;Uploading and downloading large files from a storage service (either one you run, or part of a public cloud)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TaskFlow API&lt;/strong&gt; automatically passes data between tasks via implicit XComs&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;task-instances&quot;&gt;Task Instances&lt;/h3&gt;

&lt;p&gt;Much in the same way that a DAG is instantiated into a DAG Run each time it runs, task instances are specific executions of tasks at particular times, which can vary based on the DAG’s scheduling.&lt;/p&gt;

&lt;h3 id=&quot;variables&quot;&gt;Variables&lt;/h3&gt;

&lt;p&gt;Variables are Airflow’s runtime configuration concept - a general key/value store that is global and can be queried from your tasks, and easily set via Airflow’s user interface, or bulk-uploaded as a JSON file.
Variables are &lt;strong&gt;global&lt;/strong&gt;, and should only be used for overall configuration that covers the entire installation; to pass data from one Task/Operator to another, you should use XComs instead.&lt;/p&gt;

&lt;h2 id=&quot;architecture-components&quot;&gt;Architecture Components&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/23_apache_airflow_architecture.png&quot; alt=&quot;Apache Airflow Architecture Components&quot; /&gt;
  &lt;figcaption&gt;Figure 1: Apache Airflow Architecture Components - &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/2.1.2/concepts/overview.html&quot;&gt;Image Source&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Scheduler&lt;/strong&gt;: The component responsible for scheduling tasks and determining when they should run. It checks the DAG directory for tasks that need to be executed.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Executor&lt;/strong&gt;: This defines how and where tasks are executed. Various executors are available.  In the default Airflow installation, this runs everything inside the scheduler, but most production-suitable executors actually push task execution out to workers.
Most executors will generally also introduce other components to let them talk to their workers - like a &lt;strong&gt;task queue&lt;/strong&gt; - but you can still think of the executor and its workers as a single logical component&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Web Server&lt;/strong&gt;: Provides a user interface for monitoring and managing workflows, allowing users to inspect DAGs and task statuses.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;A folder of DAG files&lt;/strong&gt;, read by the scheduler and executor (and any workers the executor has)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Metadata Database&lt;/strong&gt;: Stores all metadata related to DAGs and tasks, typically using PostgreSQL or MySQL.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;architecture-components-1&quot;&gt;Architecture Components&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Task Management&lt;/strong&gt;: Airflow manages task dependencies automatically, ensuring that tasks execute in the correct order.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scheduling&lt;/strong&gt;: Airflow provides advanced scheduling capabilities, allowing workflows to run on defined schedules or trigger based on external events.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Extensibility&lt;/strong&gt;: Users can create custom operators and plugins to extend Airflow’s functionality, integrating with various data sources and services.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Error Handling and Retries&lt;/strong&gt;: Built-in mechanisms allow tasks to be retried automatically upon failure, enhancing workflow reliability.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Airflow can handle thousands of concurrent tasks across multiple workers, making it suitable for large-scale data operations.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rich Command Line Interface (CLI)&lt;/strong&gt;: The CLI provides utilities for managing DAGs and executing tasks directly from the command line.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Integration with Other Tools&lt;/strong&gt;: Airflow supports integration with various cloud services and data tools, including AWS, Google Cloud Platform, and many others.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><summary type="html">101 Apache Airflow Cheatsheet.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" /><media:content medium="image" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Blogging Tools</title><link href="https://www.firasesbai.com/articles/2025/08/18/blogging-tools.html" rel="alternate" type="text/html" title="Blogging Tools" /><published>2025-08-18T00:00:00+00:00</published><updated>2025-08-18T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2025/08/18/blogging-tools</id><content type="html" xml:base="https://www.firasesbai.com/articles/2025/08/18/blogging-tools.html">&lt;p&gt;&lt;em&gt;A curated list of tools that I’m using for writing and building this site.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In this article, I have curated a list of resources and tools that help me manage everything from hosting and analytics to writing and working on this site. Finding the right tool can make a huge difference in terms of efficiency. While there are countless options out there, this is what works best for me.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#writing-and-planning&quot; id=&quot;markdown-toc-writing-and-planning&quot;&gt;Writing and Planning&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#trello&quot; id=&quot;markdown-toc-trello&quot;&gt;Trello&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#obsidian&quot; id=&quot;markdown-toc-obsidian&quot;&gt;Obsidian&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#domain-and-hosting&quot; id=&quot;markdown-toc-domain-and-hosting&quot;&gt;Domain and Hosting&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#cloudflare&quot; id=&quot;markdown-toc-cloudflare&quot;&gt;Cloudflare&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#github-pages&quot; id=&quot;markdown-toc-github-pages&quot;&gt;Github Pages&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#analytics-and-tracking&quot; id=&quot;markdown-toc-analytics-and-tracking&quot;&gt;Analytics and Tracking&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#google-analytics-4-ga4&quot; id=&quot;markdown-toc-google-analytics-4-ga4&quot;&gt;Google Analytics 4 (GA4)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#google-search-console&quot; id=&quot;markdown-toc-google-search-console&quot;&gt;Google Search Console&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#looker&quot; id=&quot;markdown-toc-looker&quot;&gt;Looker&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#seo&quot; id=&quot;markdown-toc-seo&quot;&gt;SEO&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#ahrefs&quot; id=&quot;markdown-toc-ahrefs&quot;&gt;Ahrefs&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#screaming-frog&quot; id=&quot;markdown-toc-screaming-frog&quot;&gt;Screaming Frog&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#google-chrome-lighthouse&quot; id=&quot;markdown-toc-google-chrome-lighthouse&quot;&gt;Google Chrome Lighthouse&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#add-ons&quot; id=&quot;markdown-toc-add-ons&quot;&gt;Add-ons&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#email-marketing&quot; id=&quot;markdown-toc-email-marketing&quot;&gt;Email Marketing&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#comments&quot; id=&quot;markdown-toc-comments&quot;&gt;Comments&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#contact-form&quot; id=&quot;markdown-toc-contact-form&quot;&gt;Contact Form&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#speed-optimization&quot; id=&quot;markdown-toc-speed-optimization&quot;&gt;Speed Optimization&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#cloudflare-1&quot; id=&quot;markdown-toc-cloudflare-1&quot;&gt;Cloudflare&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#tinypng&quot; id=&quot;markdown-toc-tinypng&quot;&gt;TinyPNG&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#google-pagespeed-insights&quot; id=&quot;markdown-toc-google-pagespeed-insights&quot;&gt;Google Pagespeed Insights&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;writing-and-planning&quot;&gt;Writing and Planning&lt;/h2&gt;

&lt;h3 id=&quot;trello&quot;&gt;Trello&lt;/h3&gt;

&lt;p&gt;Trello is a visual project management tool. I use it to organise the content workflow and capture ideas for potential articles. I keep it simple with just 3 lists representing the stages of the writing process: To Do, Doing, and Done. Each card within represents a blog post or some fixes or improvements to the site itself. To distinguish between them I use specific labels. This visual approach allows me to easily see what needs to be done and ensure I’m on track.&lt;/p&gt;

&lt;h3 id=&quot;obsidian&quot;&gt;Obsidian&lt;/h3&gt;

&lt;p&gt;Obsidian is a markdown based note taking app. In this context, i use it for kicking off drafts, creating notes for each blog post and capturing relevant research. It allows for linking notes together and creating interconnected central knowledge base where you can easily jump between related notes to brainstorm and rediscover information.&lt;/p&gt;

&lt;h2 id=&quot;domain-and-hosting&quot;&gt;Domain and Hosting&lt;/h2&gt;

&lt;h3 id=&quot;cloudflare&quot;&gt;Cloudflare&lt;/h3&gt;

&lt;p&gt;While often thought of for performance and security (which I’ll touch on later), Cloudflare also handles my DNS. It provides a fast and robust way to manage my domain’s records. For more details, you can check &lt;a href=&quot;https://www.firasesbai.com/articles/2025/01/19/google-domains-cloudflare-migration.html&quot;&gt;the following article&lt;/a&gt; where I outline how I migrated from Google Domains to Cloudflare.&lt;/p&gt;

&lt;h3 id=&quot;github-pages&quot;&gt;Github Pages&lt;/h3&gt;

&lt;p&gt;This is where the site physically lives. It’s a free solution for hosting static websites like this one directly from a GitHub repository, and it integrates seamlessly with custom domains via Cloudflare.&lt;/p&gt;

&lt;h2 id=&quot;analytics-and-tracking&quot;&gt;Analytics and Tracking&lt;/h2&gt;

&lt;h3 id=&quot;google-analytics-4-ga4&quot;&gt;Google Analytics 4 (GA4)&lt;/h3&gt;

&lt;p&gt;GA4 helps me understand traffic sources, user behavior, content performance, and conversions. It’s the primary source for overall site metrics.&lt;/p&gt;

&lt;h3 id=&quot;google-search-console&quot;&gt;Google Search Console&lt;/h3&gt;

&lt;p&gt;This is essential for understanding how my site performs in Google Search. It shows me search queries, indexing status, technical errors, and sitemaps.&lt;/p&gt;

&lt;h3 id=&quot;looker&quot;&gt;Looker&lt;/h3&gt;

&lt;p&gt;I use Looker to create custom dashboards pulling data from GA4, Cloudflare Analytics, Search Console and Google Forms. This allows me to visualize key metrics in a centralised view without switching between tools and overcoming data discrepancies as indicated in &lt;a href=&quot;https://www.firasesbai.com/articles/2024/08/11/cloudflare-vs-google-analytics.html&quot;&gt;this article&lt;/a&gt; where I cover the difference between Cloudflare Analytics and Google Analytics.&lt;/p&gt;

&lt;h2 id=&quot;seo&quot;&gt;SEO&lt;/h2&gt;

&lt;h3 id=&quot;ahrefs&quot;&gt;Ahrefs&lt;/h3&gt;
&lt;p&gt;I mainly use Ahrefs Webmaster Tools which gives you free access to a bundle of 3 tools if you can verify the ownership of your website. You can achieve this by connecting Google Search Console as the recommended approach. 
    - Web Analytics: You can setup web analytics for your site as an alternative to Google Analytics to get real time metrics about your visitors.
    - Site Audit: Scans your website for known technical and most common SEO issues such as broken links, duplicate content and missing metadata description. You can setup scheduled crawls of your site and get an email with an overview containing a health score of the site, number of issues grouped by severity and newly identified issues since the last crawl. This will allow you to proactively identify and fix issues to improve your site’s performance.
    - Site Explorer: Helps you gain insights into your site’s organic search performance&lt;/p&gt;

&lt;h3 id=&quot;screaming-frog&quot;&gt;Screaming Frog&lt;/h3&gt;

&lt;p&gt;Screaming Frog is a desktop based website crawler with a free version limited to 500 URLs which is more than enough for a small blog. It acts as a search engine spider by crawling your site’s URLs and extracting data to give you a comprehensive technical audit. By finding and fixing issues like broken links, you ensure a better user experience and help search engines properly crawl and index your site.&lt;/p&gt;

&lt;h3 id=&quot;google-chrome-lighthouse&quot;&gt;Google Chrome Lighthouse&lt;/h3&gt;

&lt;p&gt;As part of the Chrome browser’s developer tools, Lighthouse provides a detailed report on the performance, accessibility, best practices and SEO of any web page. It is very handy for a quick and easy way to check the health of individual pages on the site locally before publishing them.&lt;/p&gt;

&lt;h2 id=&quot;add-ons&quot;&gt;Add-ons&lt;/h2&gt;

&lt;h3 id=&quot;email-marketing&quot;&gt;Email Marketing&lt;/h3&gt;

&lt;p&gt;Building an email list is vital for direct communication with my audience. I’ve explored tools like &lt;strong&gt;ConvertKit&lt;/strong&gt; and &lt;strong&gt;Mailerlite&lt;/strong&gt;, both offering features to build and manage subscriber lists, create landing pages, and send broadcasts or sequences. I have settled for Mailerlite as the free plan was more interesting especially for starting out with small number of subscribers.&lt;/p&gt;

&lt;h3 id=&quot;comments&quot;&gt;Comments&lt;/h3&gt;

&lt;p&gt;I use &lt;strong&gt;Disqus&lt;/strong&gt; for managing comments on the blog posts. Originally I started out using Github API where I create an issue for each blog post and the comments section will redirect the users to commenting on the created issue. The list of all the comments is then fetched from the API. This was easy to setup initially but had limits as it requires the users to have a Github account and to be logged in. In addition, the overhead of maintaining the different issues made it easy to switch to Disqus as it provides a robust commenting system with moderation tools.&lt;/p&gt;

&lt;h3 id=&quot;contact-form&quot;&gt;Contact Form&lt;/h3&gt;

&lt;p&gt;I use an embedded &lt;strong&gt;Google Forms&lt;/strong&gt; in my contact page to enable visitors of my site to reach out and handle their requests and inquiries.&lt;/p&gt;

&lt;h2 id=&quot;speed-optimization&quot;&gt;Speed Optimization&lt;/h2&gt;

&lt;h3 id=&quot;cloudflare-1&quot;&gt;Cloudflare&lt;/h3&gt;

&lt;p&gt;As mentioned earlier, using Cloudflare comes with the additional bonus of faster and more responsive website. This is achieved through its role as a Content Delivery Network (CDN). A CDN is a network of servers located all over the world. When a visitor comes to my blog, Cloudflare automatically serves the static content (like images, CSS, and JavaScript files) from the server closest to them. This dramatically reduces the physical distance the data has to travel, which in turn cuts down on page load times.&lt;/p&gt;

&lt;h3 id=&quot;tinypng&quot;&gt;TinyPNG&lt;/h3&gt;

&lt;p&gt;Images are often the biggest culprit for slow page load times. TinyPNG is a free online tool that uses smart lossy compression techniques to reduce the file size of my images without a noticeable loss in quality.&lt;/p&gt;

&lt;h3 id=&quot;google-pagespeed-insights&quot;&gt;Google Pagespeed Insights&lt;/h3&gt;

&lt;p&gt;While using Google Chrome Lighthouse before publishing a post is useful for seeing how the introduced changes affect the performance, it is still run under controlled, simulated conditions such as throttled netweok speed on a specific device. This is where Pagespeed Insights comes in handy by complementing that with data on how real world visitors have experienced your site. It provides a holistic view of performance for both mobile and desktop with a list of actionable recommendations. This is a more accurate representation of how your site performs for your actual audience, across various devices and network conditions.&lt;/p&gt;

&lt;p&gt;If you have any remarks or suggestions for me, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;This is not an exhaustive list but rather a work in progress. Each tool serves a specific purpose in streamlining the process from writing to managing the site’s performance. While the exact setup may evolve, the goal remains the same: keep things simple and effective.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Blogging" /><summary type="html">A curated list of tools that I’m using for writing and building this site.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" /><media:content medium="image" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Introducing My Data Engineering Tech Radar</title><link href="https://www.firasesbai.com/articles/2025/08/10/data-engineering-tech-radar.html" rel="alternate" type="text/html" title="Introducing My Data Engineering Tech Radar" /><published>2025-08-10T00:00:00+00:00</published><updated>2025-08-10T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2025/08/10/data-engineering-tech-radar</id><content type="html" xml:base="https://www.firasesbai.com/articles/2025/08/10/data-engineering-tech-radar.html">&lt;p&gt;&lt;em&gt;Launching a Data Engineering Tech Radar.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The world of data engineering is constantly changing. New tools emerge every week, architectural patterns fall in and out of favor, and the hype cycle churns endlessly. I’m sure we all at some point have come across variations of landscapes or state of data engineering diagrams packed with unreadable logos. Be assured, this is not one of those.&lt;/p&gt;

&lt;p&gt;Keeping up feels like a full-time job already and we are usually looking to find something to help us cut through the noise and answer the following: How do you decide which technologies are genuinely worth your time?&lt;/p&gt;

&lt;p&gt;To help, first myself, answer that question, I created this &lt;strong&gt;&lt;a href=&quot;https://www.firasesbai.com/data-tech-radar/&quot; target=&quot;_blank&quot;&gt;Data Engineering Tech Radar&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Inspired by the pioneering &lt;a href=&quot;https://www.thoughtworks.com/en-de/radar&quot;&gt;ThoughtWorks Tech Radar&lt;/a&gt;, this is my curated, opinionated, and practical guide to the data ecosystem. It’s a snapshot of my perspective on the tools, platforms, languages, and techniques that I have personally used or seen other teams adopt them in production. It is also a way to capture and keep track of what actually matters in our field right now and not feel overwhelmed.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#why-a-tech-radar&quot; id=&quot;markdown-toc-why-a-tech-radar&quot;&gt;Why a Tech Radar?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-it-works-quadrants-and-rings&quot; id=&quot;markdown-toc-how-it-works-quadrants-and-rings&quot;&gt;How It Works: Quadrants and Rings&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#the-quadrants&quot; id=&quot;markdown-toc-the-quadrants&quot;&gt;The Quadrants&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-rings&quot; id=&quot;markdown-toc-the-rings&quot;&gt;The Rings&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#this-is-just-the-beginning&quot; id=&quot;markdown-toc-this-is-just-the-beginning&quot;&gt;This Is Just the Beginning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;why-a-tech-radar&quot;&gt;Why a Tech Radar?&lt;/h2&gt;

&lt;p&gt;My motivation for creating this radar is threefold:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;To Navigate Complexity:&lt;/strong&gt; The goal isn’t to list every tool, but to provide a filter. This radar helps separate the signal from the noise by offering a structured opinion on what’s production-ready, what’s promising, and what you might want to proceed with caution on.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;To Share Real-World Experience:&lt;/strong&gt; Tutorials can show you &lt;em&gt;how&lt;/em&gt; a tool works, but they rarely tell you &lt;em&gt;if&lt;/em&gt; you should use it. This radar is built on hands-on experience, reflecting what has worked well in practice and the lessons learned along the way.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;To Track a Moving Target:&lt;/strong&gt; The data landscape is not static, and neither is this radar. It’s a living document that I will update periodically to reflect new developments and evolving opinions, serving as a log of how our industry changes over time.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;how-it-works-quadrants-and-rings&quot;&gt;How It Works: Quadrants and Rings&lt;/h2&gt;

&lt;p&gt;To make sense of everything, the radar is broken down into four quadrants and four rings.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/22_data_tech_radar.png&quot; alt=&quot;Data Tech Radar&quot; /&gt;
  &lt;figcaption&gt;Figure 1: Data Tech Radar&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;the-quadrants&quot;&gt;The Quadrants&lt;/h3&gt;

&lt;p&gt;The quadrants categorize items by their functional area in the data lifecycle.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Languages &amp;amp; Frameworks:&lt;/strong&gt; This quadrant covers the foundational skills, languages and frameworks.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transformation &amp;amp; Orchestration:&lt;/strong&gt; Tools and practices for data transformation, ETL processes, and workflow orchestration.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Platforms &amp;amp; Storage&lt;/strong&gt;: Technologies for data storage, databases, and data warehousing solutions.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Analytics:&lt;/strong&gt; Tools and platforms for data analysis, visualization, and business intelligence.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-rings&quot;&gt;The Rings&lt;/h3&gt;

&lt;p&gt;The rings represent my opinion on a technology’s maturity and my recommendation for its adoption.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Adopt:&lt;/strong&gt; Technologies that are well-established and I have used or seen other teams adopt them in production and they’ve proven their value.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Trial:&lt;/strong&gt; Emerging technologies that show promise and I have started exploring them or using on non-critical projects.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Assess:&lt;/strong&gt; Technologies that caught my eye and are used or recommended by other teams that I think are worth exploring.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hold:&lt;/strong&gt; Technologies to proceed with caution on and I would not recommended for new projects.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;this-is-just-the-beginning&quot;&gt;This Is Just the Beginning&lt;/h2&gt;

&lt;p&gt;This is just the initial release and it might not have all the tools I have under the radar but this radar is a starting point, a snapshot in time, and it should be treated as such. My opinions will change as I learn, and new tools will emerge that demand a spot. I plan to revisit and update the radar periodically to keep it relevant.&lt;/p&gt;

&lt;p&gt;But most importantly, this is meant to be a conversation starter.&lt;/p&gt;

&lt;p&gt;What did I get right? What do you completely disagree with? What hidden gems are missing from the “Assess” ring? I’d love to hear your thoughts.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Check out the full &lt;a href=&quot;https://www.firasesbai.com/data-tech-radar/&quot; target=&quot;_blank&quot;&gt;Data Engineering Tech Radar&lt;/a&gt; and let me know what you think.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><summary type="html">Launching a Data Engineering Tech Radar.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.firasesbai.com/assets/images/articles/22_data_tech_radar.png" /><media:content medium="image" url="https://www.firasesbai.com/assets/images/articles/22_data_tech_radar.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Data Engineering Capabilities and Personas</title><link href="https://www.firasesbai.com/articles/2025/05/25/data-engineering-capabilities-and-personas.html" rel="alternate" type="text/html" title="Data Engineering Capabilities and Personas" /><published>2025-05-25T00:00:00+00:00</published><updated>2025-05-25T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2025/05/25/data-engineering-capabilities-and-personas</id><content type="html" xml:base="https://www.firasesbai.com/articles/2025/05/25/data-engineering-capabilities-and-personas.html">&lt;p&gt;&lt;em&gt;In this article, we will look at key data engineering capabilities at the intersection of several archetypes and personas.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;https://www.firasesbai.com/articles/2023/03/01/data-engineering-101.html&quot;&gt;a previous article&lt;/a&gt;, we looked into the role of a data engineer and the general responsibilities associated with it. However, the field of data engineering has changed dramatically over the last decade. This led to the emergence of different constellations of data teams. Depending on the company size and maturity level, more specialized personas appeared requiring certain set of capabilities. In today’s article, we will breakdown these types and the expected capabilities.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#software-engineering-at-heart&quot; id=&quot;markdown-toc-software-engineering-at-heart&quot;&gt;Software Engineering at Heart&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-platform-engineering&quot; id=&quot;markdown-toc-data-platform-engineering&quot;&gt;Data Platform Engineering&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#analytics-engineering&quot; id=&quot;markdown-toc-analytics-engineering&quot;&gt;Analytics Engineering&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;software-engineering-at-heart&quot;&gt;Software Engineering at Heart&lt;/h2&gt;

&lt;p&gt;There is a lot of debate and people comparing the role of data engineer with traditional software engineering. Some would argue that a data engineer is just a specialized software engineer while others would question the complexity and required technical skills in data engineering. One thing we can take out from this though is that the lines between the roles are blurring.&lt;/p&gt;

&lt;p&gt;A data engineer should be able to build, maintain and test the software architecture for managing different complexities of data. This includes understanding the principles, patterns and practices of writing clean code that is easy to evolve, test and get into production. A solid understanding of distributed systems and microservices architecture through the lenses of Application Programming Interfaces (APIs) in order to implement a secure, scalable and performant solution.&lt;/p&gt;

&lt;h2 id=&quot;data-platform-engineering&quot;&gt;Data Platform Engineering&lt;/h2&gt;

&lt;p&gt;Another area data teams focus on is the design and operation of the infrastructure required to run different types of data workloads. This includes knowing the tradeoffs between on-premises and cloud infrastructure as well as related tools and practices such as infrastructure as code, monitoring, performance testing and optimization.&lt;/p&gt;

&lt;p&gt;The purpose of building a data platform is to cover the end to end data lifecycle and related aspects including:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Data pipelines:
    &lt;ul&gt;
      &lt;li&gt;Ability to build, deploy, and orchestrate data pipelines and the different technology options to implement them. Examples include Extract-Transform-Load (ETL), Extract-Load-Transform (ELT), Change Data Capture (CDC), and batch vs. streaming pipelines.&lt;/li&gt;
      &lt;li&gt;Building data pipelines is not just about moving data from one system to another. It involves continuously evaluating, monitoring and improving the quality of your data over time. Common data quality aspects include completeness, timeliness, accuracy, integrity, and consistency.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data Modeling:
    &lt;ul&gt;
      &lt;li&gt;Ability to model data in different types of databases according to the data architecture and business needs. This includes RDBMS, data warehouses, key-value stores, document stores, graph databases, distributed file systems and columnar data stores.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data Storage:
    &lt;ul&gt;
      &lt;li&gt;Ability to understand and choose different platforms and technology options to store data. This includes different types of databases, data lake, data warehouse, and data serialization formats.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data Governance:
    &lt;ul&gt;
      &lt;li&gt;Data governance includes a company-wide principles, practices and organizational structures. It involves the ability to understand, design, and apply security controls around the sharing and using of data across the enterprise. Encompassing aspects around authorization, encryption, information security, compliance and regulatory needs. In addition, familiarity with the elements of data privacy and ethics such as bias, are crucial in order to detect and mitigate the anticipated threats, vulnerabilities and unintended consequences that can arise when using data.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;analytics-engineering&quot;&gt;Analytics Engineering&lt;/h2&gt;

&lt;p&gt;One more area to cover is analytics engineering where data engineering teams focus on extracting insights and knowledge from the processed data at the end of the data lifecycle. In addition to understanding multidimensional modeling and data warehousing technologies, it involves the ability to derive insights and actionable knowledge delivering clear reports, dashboards and KPIs containing compelling and effective visualizations to inform stakeholders and to support business decision-making.&lt;/p&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;Let me know what other teams should we include?&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;In this article, we discussed core capabilities required across different personas and team structures. Understanding these constellations helps organizations build effective teams and deliver value.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><summary type="html">In this article, we will look at key data engineering capabilities at the intersection of several archetypes and personas.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" /><media:content medium="image" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Data Encoding and Formats</title><link href="https://www.firasesbai.com/articles/2025/05/18/data-encoding-and-formats.html" rel="alternate" type="text/html" title="Data Encoding and Formats" /><published>2025-05-18T00:00:00+00:00</published><updated>2025-05-18T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2025/05/18/data-encoding-and-formats</id><content type="html" xml:base="https://www.firasesbai.com/articles/2025/05/18/data-encoding-and-formats.html">&lt;p&gt;&lt;em&gt;In this article, we will explore the importance of data encoding and how to choose the right data format, weather it is simple CSVs or binary formats like Avro and Parquet, in order to achieve better performance, cost, and evolvability.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Data Serialization and Data Formats go hand in hand; one converts data objects to a shareable or storable structure and the other describes how this new structure is stored or transmitted and retrieved. The choice of &lt;em&gt;how&lt;/em&gt; we serialize and the &lt;em&gt;format&lt;/em&gt; we use impacts performance, storage costs and interoperability. Getting it right is key to building efficient, scalable, and maintainable data pipelines.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#data-serialization&quot; id=&quot;markdown-toc-data-serialization&quot;&gt;Data Serialization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-formats-characteristics&quot; id=&quot;markdown-toc-data-formats-characteristics&quot;&gt;Data Formats Characteristics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#standardized-textual-formats&quot; id=&quot;markdown-toc-standardized-textual-formats&quot;&gt;Standardized Textual Formats&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#xml&quot; id=&quot;markdown-toc-xml&quot;&gt;XML&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#json&quot; id=&quot;markdown-toc-json&quot;&gt;JSON&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#csv&quot; id=&quot;markdown-toc-csv&quot;&gt;CSV&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#binary-data-formats&quot; id=&quot;markdown-toc-binary-data-formats&quot;&gt;Binary Data Formats&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#apache-avro&quot; id=&quot;markdown-toc-apache-avro&quot;&gt;Apache Avro&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#apache-parquet&quot; id=&quot;markdown-toc-apache-parquet&quot;&gt;Apache Parquet&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#apache-orc-optimized-row-columnar&quot; id=&quot;markdown-toc-apache-orc-optimized-row-columnar&quot;&gt;Apache ORC (Optimized Row Columnar)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#choosing-the-right-format&quot; id=&quot;markdown-toc-choosing-the-right-format&quot;&gt;Choosing the Right Format&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;data-serialization&quot;&gt;Data Serialization&lt;/h2&gt;

&lt;p&gt;The seemingly simple act of storing data or sending it across a network involves a fundamental process: &lt;strong&gt;data serialization&lt;/strong&gt;. This is the conversion of data objects, residing in potentially complex in-memory structures (like objects, lists, trees in our code), into a byte stream suitable for persistent storage or network transmission. Once data arrives at its destination, the reverse process, &lt;strong&gt;deserialization&lt;/strong&gt; (or parsing/decoding), reconstructs the original object structures from the byte sequence.&lt;/p&gt;

&lt;p&gt;For example, in the context of databases, when a process is writing data to the database, the data is initially encoded into a sequence of bytes and then stored. Later when another process tries to read data from the database, it needs to decode it first. Similarly the communication between web services through REST APIs involves encoding the request by the client before sending it. Once the server receives it, it decodes the request, process it and then encode the response to be sent back to the client. The latter makes the last deserialization of this exchange.&lt;/p&gt;

&lt;p&gt;Data serialization is ideal for storing data efficiently as serialized data takes up less storage space. This results in faster data transfer and reduced latency as data can be transmitted quickly and efficiently over networks. In addition, it enhances flexibility and interoperability making data exchange seamless across different applications and networks.&lt;/p&gt;

&lt;p&gt;With this understanding and examples of the data serialization process and its application, in the coming sections we will look into the types and characteristics of common data formats.&lt;/p&gt;

&lt;h2 id=&quot;data-formats-characteristics&quot;&gt;Data Formats Characteristics&lt;/h2&gt;

&lt;p&gt;Before going through each data format separately, let’s start by understanding general characteristics we will be using when evaluating how they behave, what they are good for and where they might fall short.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Human Readability&lt;/strong&gt;: Can humans easily open and understand the data with a text editor?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compressibility:&lt;/strong&gt; How well does the format compress and how much space does it take? This is important for saving storage and network bandwidth.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Speed and Performance&lt;/strong&gt;: How quickly can the format be read/written?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Splittable:&lt;/strong&gt; Can a single large file be processed in parallel chunks? This is essential for distributed data processing frameworks such as Apache Spark.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Schema Support&lt;/strong&gt;: Does the format have a defined &lt;strong&gt;schema&lt;/strong&gt; (structure definition)? Schema allows for validation and consistent data interpretation.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Self-describing:&lt;/strong&gt; Does the file embed its own schema or metadata about its structure? This simplifies reading without needing external schema definitions.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Schema Evolution:&lt;/strong&gt; How well does the format handle changes (adding/removing fields) over time while maintaining compatibility?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interoperability&lt;/strong&gt;: Can it be easily used across languages, tools, platforms?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;standardized-textual-formats&quot;&gt;Standardized Textual Formats&lt;/h2&gt;

&lt;p&gt;Many programming languages provide built-in mechanisms for encoding in-memory objects into byte sequences like Python’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pickle&lt;/code&gt; module. While these are easy to use, the encoding is tightly coupled to the specific language used making it very difficult or impossible to read the data in a different programming languages. In addition, the processes of encoding and decoding are usually CPU intensive and result in a sizeable encoded data. Not to mention that they are open to security vulnerabilities when malicious byte sequence is decoded that causes the application to instantiate unintended classes, potentially leading to arbitrary code execution.&lt;/p&gt;

&lt;p&gt;To overcome the limitations of language-specific formats, standardized encodings readable by multiple languages are widely used. Common examples include JSON, XML, and CSV due to their human-readability and simplicity, especially for data exchange.&lt;/p&gt;

&lt;h3 id=&quot;xml&quot;&gt;XML&lt;/h3&gt;
&lt;p&gt;XML (eXtensible Markup Language) is a nested markup format. Its hierarchical structure makes it splittable by elements, though it is often criticized for verbosity which reduces compression efficiency. It’s still widely used in enterprise environments despite declining popularity due to complexity.&lt;/p&gt;

&lt;h3 id=&quot;json&quot;&gt;JSON&lt;/h3&gt;
&lt;p&gt;JSON (JavaScript Object Notation) gained popularity due to its relative simplicity in comparison to XML and native support in web browsers. JSON offers a simpler, row-like nested structure with arrays and objects, making it both compressible and splittable. It’s self-describing (with field names), making it easier for data exchange, though schema evolution isn’t natively supported. JSON is common in web APIs, configs, and moderately complex datasets.&lt;/p&gt;

&lt;h3 id=&quot;csv&quot;&gt;CSV&lt;/h3&gt;
&lt;p&gt;CSV (Comma Separated Values) is a flat, row-based format that’s highly compressible and trivially splittable by lines. It lacks self-description and schema enforcement, making it lightweight but error-prone. It’s ideal for small, tabular data where structure is known or managed externally.&lt;/p&gt;

&lt;p&gt;Despite being readable, these textual formats share some key limitations. For instance, in both XML and CSV there is no clear distinction between a number and a string composed of digits. JSON on the other hand does separate numbers from strings but doesn’t specify numeric types or their precision. In addition, all three formats lack native support for binary data (sequences of raw bytes like images) and this usually involves encoding it into text using schemes like Base64, which increases the data size.&lt;/p&gt;

&lt;h2 id=&quot;binary-data-formats&quot;&gt;Binary Data Formats&lt;/h2&gt;

&lt;p&gt;There has been a couple of projects that converted JSON and XML into a binary representation and tried to solve some of the problems we mentioned before but the main drawback still the missing schema. For small data sets, the gains might be negligible but for large datasets or performance-critical applications, choosing the appropriate binary format offers significant advantages in size and speed. Therefore, in this section we will look into the characteristics of 3 common binary formats: Apache Avro, Apache Parquet and Apache ORC.&lt;/p&gt;

&lt;h3 id=&quot;apache-avro&quot;&gt;Apache Avro&lt;/h3&gt;

&lt;p&gt;Apache Avro is a data serialization system providing rich data structures and compact binary data format. It started in 2009 as a sub project of Hadoop as a result of &lt;a href=&quot;https://thrift.apache.org/&quot;&gt;Thrift&lt;/a&gt; not being a good fit for Hadoop’s use case. 
A key feature of Apache Avro is its robust support for schema evolution. It uses JSON-based schema definition. The schema is typically &lt;strong&gt;embedded within the data file&lt;/strong&gt; which permits full processing of the data without code generation and less type information encoded within the data resulting in smaller serialization size. 
Crucially, Avro distinguishes between the &lt;strong&gt;writer’s schema&lt;/strong&gt; (used during encoding) and the &lt;strong&gt;reader’s schema&lt;/strong&gt; (used during decoding). They don’t need to be identical, only &lt;em&gt;compatible&lt;/em&gt;, enabling robust &lt;strong&gt;schema evolution&lt;/strong&gt;.
Apache Avro is often used in write-heavy batch ingestion, streaming data messages like Apache Kafka and scenarios needing strong schema validation and evolution guarantees.&lt;/p&gt;

&lt;h3 id=&quot;apache-parquet&quot;&gt;Apache Parquet&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Apache Parquet&lt;/strong&gt; is a columnar storage format optimized for analytical workloads, developed jointly by Cloudera and Twitter in 2013 as part of the Hadoop ecosystem.
Parquet stores data in a &lt;strong&gt;column-oriented&lt;/strong&gt; layout, which means data from the same column are stored together. This design allows for &lt;strong&gt;highly efficient scans&lt;/strong&gt; when querying subsets of columns and enables advanced &lt;strong&gt;compression and encoding techniques&lt;/strong&gt; tailored per column.
Parquet supports schema evolution through metadata that tracks schema changes over time. Parquet files embed the schema, allowing readers to reconcile differences between older and newer versions using a &lt;strong&gt;merge&lt;/strong&gt; strategy.
Apache Parquet is often used in data lakes, data warehouses and large-scale analytics engines like Spark, Presto, Trino, etc.&lt;/p&gt;

&lt;h3 id=&quot;apache-orc-optimized-row-columnar&quot;&gt;Apache ORC (Optimized Row Columnar)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Apache ORC&lt;/strong&gt; (Optimized Row Columnar) is another high-performance columnar format, created in 2013 by Hortonworks to optimize Hive workloads. Like Parquet, ORC organizes data column-wise but adds features tailored for Hive, such as ACID transaction support. It also stores extensive metadata, such as min/max values and row-level statistics, enabling &lt;strong&gt;aggressive query optimizations&lt;/strong&gt;. ORC files store schema information and statistics in footers, enabling efficient reads.
While similar to Parquet in structure, ORC shines in Hive-centric workflows and &lt;strong&gt;write-once, read-many&lt;/strong&gt; batch processing jobs. Its design emphasizes &lt;strong&gt;fast scan performance&lt;/strong&gt; and &lt;strong&gt;compression ratios&lt;/strong&gt;, especially when working with large, structured datasets.&lt;/p&gt;

&lt;h2 id=&quot;choosing-the-right-format&quot;&gt;Choosing the Right Format&lt;/h2&gt;

&lt;p&gt;Choosing a format isn’t just about static storage. Systems evolve and so does the underlying data. There is no single best format and the choice will depend on some tradeoffs even though in practice pipelines end up using multiple formats for different purposes.&lt;/p&gt;

&lt;p&gt;The following table compares the key characteristics worth having in mind when choosing among the data formats we discussed:&lt;/p&gt;

&lt;div style=&quot;overflow-x: auto;&quot;&gt;
  
&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;Characteristic&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;strong&gt;XML&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;strong&gt;JSON&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;strong&gt;CSV&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Avro&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Parquet&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;strong&gt;ORC&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Human Readability&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Yes (simple)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;No&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;No&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;No&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Compressibility&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Moderate (verbose)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Moderate&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Low&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;High (binary + schema)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Very High (columnar)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Very High (columnar)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Speed &amp;amp; Performance(Read/Write)&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Slow (verbose parsing)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Decent (for small data)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Fast (simple format)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Fast&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Very Fast (columnar)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Very Fast (columnar)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Splittable&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;No&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Partial (depends on parser)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Yes (if line delimited)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Schema Support&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Optional (XSD, external)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Optional&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;No&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Schema Evolution&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Poor&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Poor&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;None&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Excellent&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Good&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Good&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Best Use Case&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Config/debugging with structure&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Debugging, API responses&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Simple tabular data&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;OLTP-like ingestion, Kafka&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;OLAP, analytics, Spark/Hadoop&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;OLAP, analytics, Hive/Spark&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Read vs. Write&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Read/debugging&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Read/debugging&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Read/debugging&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Write-heavy (streaming, Kafka)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Read-heavy (query performance)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Read-heavy (query performance)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Data Complexity&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Supports nesting&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Supports nesting&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Flat only&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Supports nesting&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Supports nesting&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Supports nesting&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;


&lt;/div&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;Table 1: Characteristics of data formats&lt;/p&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;We’ve explored the critical role of data serialization and file formats in data engineering. We saw the limitations of language-specific and simple textual formats (CSV, JSON, XML) and contrasted them with powerful, schema-driven binary formats like Avro, Parquet, and ORC. Understanding the trade-offs—read/write performance, compression, splittability, schema evolution, and human readability—is vital for choosing the right tool for the job.&lt;/p&gt;

&lt;p&gt;These file formats often form the storage layer for modern &lt;strong&gt;Open Table Formats&lt;/strong&gt; (Apache Iceberg, Apache Hudi, Delta Lake), which add transactional capabilities, time travel, and enhanced schema management on top – a powerful combination and perhaps a topic for a future deep dive!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.datanami.com/2018/05/16/big-data-file-formats-demystified/&quot;&gt;https://www.datanami.com/2018/05/16/big-data-file-formats-demystified/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://luminousmen.com/post/big-data-file-formats&quot;&gt;https://luminousmen.com/post/big-data-file-formats&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.confluent.io/learn/data-serialization/&quot;&gt;https://www.confluent.io/learn/data-serialization/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://d9nich.medium.com/json-xml-protobuf-thrift-avro-or-everything-you-need-to-know-about-encoding-data-6077a7e769e2&quot;&gt;https://d9nich.medium.com/json-xml-protobuf-thrift-avro-or-everything-you-need-to-know-about-encoding-data-6077a7e769e2&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><summary type="html">In this article, we will explore the importance of data encoding and how to choose the right data format, weather it is simple CSVs or binary formats like Avro and Parquet, in order to achieve better performance, cost, and evolvability.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" /><media:content medium="image" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Migrating from Google Domains to Cloudflare</title><link href="https://www.firasesbai.com/articles/2025/01/19/google-domains-cloudflare-migration.html" rel="alternate" type="text/html" title="Migrating from Google Domains to Cloudflare" /><published>2025-01-19T00:00:00+00:00</published><updated>2025-01-19T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2025/01/19/google-domains-cloudflare-migration</id><content type="html" xml:base="https://www.firasesbai.com/articles/2025/01/19/google-domains-cloudflare-migration.html">&lt;p&gt;&lt;em&gt;In this article, I will outline how I migrated from Google Domains, due to its shutdown, to Cloudflare all while explaining some key terms and concepts.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;On 15.06.2023, Google announced that Google Domains is shutting down and Squarespace is buying all customer accounts. I was a happy customer ever since I started this site and chose Google Domains to host its domain until this announcement.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-a-domain-registrar&quot; id=&quot;markdown-toc-what-is-a-domain-registrar&quot;&gt;What is a Domain Registrar?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-a-dns-provider&quot; id=&quot;markdown-toc-what-is-a-dns-provider&quot;&gt;What is a DNS Provider?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#what-are-dns-records&quot; id=&quot;markdown-toc-what-are-dns-records&quot;&gt;What are DNS Records?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#domain-name-structure&quot; id=&quot;markdown-toc-domain-name-structure&quot;&gt;Domain Name Structure&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#why-cloudflare&quot; id=&quot;markdown-toc-why-cloudflare&quot;&gt;Why Cloudflare?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#migration-steps&quot; id=&quot;markdown-toc-migration-steps&quot;&gt;Migration Steps&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;what-is-a-domain-registrar&quot;&gt;What is a Domain Registrar?&lt;/h2&gt;

&lt;p&gt;A domain registrar is an organization that allows you to register and manage your domain name. Think of it like a middleman between you and the internet – they help facilitate communication between your domain name and the servers that host your website.&lt;/p&gt;

&lt;h2 id=&quot;what-is-a-dns-provider&quot;&gt;What is a DNS Provider?&lt;/h2&gt;

&lt;p&gt;A Domain Name System (DNS) provider is a service that manages the settings for your domain name. It handles DNS records, which are used to connect your domain name to IP addresses or other details.&lt;/p&gt;

&lt;p&gt;This works through &lt;strong&gt;Authoritative Name Servers (NS)&lt;/strong&gt; managed by the DNS provider and act like the “brain” of your domain. They store and update your DNS records to keep everything accurate and working correctly.&lt;/p&gt;

&lt;p&gt;There are DNS hosting providers that offer domain registration and vice versa such as Cloudflare but the two services should not be confused.&lt;/p&gt;

&lt;p&gt;For more information on the communication flow between your browser, the DNS provider and your web server, check the resources section.&lt;/p&gt;

&lt;h2 id=&quot;what-are-dns-records&quot;&gt;What are DNS Records?&lt;/h2&gt;

&lt;p&gt;DNS records are like the phonebook of the internet. They help connect your domain name (e.g., example.com) to an IP address or other relevant information. Think of it like a map that helps your website find its way on the web.&lt;/p&gt;

&lt;p&gt;There are several types of DNS records, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;A Record&lt;/strong&gt; : Maps a domain or subdomain to an IPv4 address.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;AAAA Record&lt;/strong&gt; : Maps a domain or subdomain to an IPv6 address.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;CNAME Record&lt;/strong&gt; : Creates an alias or nickname for a domain or subdomain, pointing it to another domain name. This is often used for creating subdomains or for pointing one domain to another.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MX Record&lt;/strong&gt; : Specifies the mail servers responsible for receiving email messages on behalf of a domain.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TXT Record&lt;/strong&gt; : Stores arbitrary text data for various purposes, including domain verification and email authentication (SPF, DKIM).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;NS Record&lt;/strong&gt; : Specifies the authoritative name servers for a domain. These servers hold the DNS records for the domain.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;domain-name-structure&quot;&gt;Domain Name Structure&lt;/h2&gt;

&lt;p&gt;The diagram below decomposes the structure of a domain name:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/21_domain_name_structure_diagram.png&quot; alt=&quot;domain name structure diagram&quot; /&gt;
  &lt;figcaption&gt;Figure 1: Domain Name Structure Diagram - &lt;a href=&quot;https://love2dev.com/blog/domain-names/&quot;&gt;Image Source&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;why-cloudflare&quot;&gt;Why Cloudflare?&lt;/h2&gt;

&lt;p&gt;Cloudflare is a popular choice and it stood out for me for the following features:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ease of use with simple and clean interface&lt;/li&gt;
  &lt;li&gt;Free DNS Management and configuration of your DNS settings.&lt;/li&gt;
  &lt;li&gt;Protection against attacks, including a built-in firewall and DDoS mitigation.&lt;/li&gt;
  &lt;li&gt;Content caching and image optimization to speed up your site and enhance its performance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;migration-steps&quot;&gt;Migration Steps&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Add Your Domain to Cloudflare
    &lt;ul&gt;
      &lt;li&gt;Sign up for a Cloudflare account if you don’t already have one.&lt;/li&gt;
      &lt;li&gt;Log in and add your domain. In Cloudflare, domains are referred to as “zones.”&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Update the Nameservers in Google Domains
    &lt;ul&gt;
      &lt;li&gt;Log in to your Google Domains account.&lt;/li&gt;
      &lt;li&gt;Find the nameserver settings for your domain and replace them with the nameservers provided by Cloudflare. This step tells the internet to start using Cloudflare to manage your DNS.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Verify Zone Activation in Cloudflare
    &lt;ul&gt;
      &lt;li&gt;Cloudflare will automatically check the nameserver changes. Once the changes are detected, it will activate your domain (zone) on their platform.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Initiate the Transfer from Google Domains
    &lt;ul&gt;
      &lt;li&gt;In Google Domains, initiate the transfer process. You’ll receive an authorization code (sometimes called an EPP code) to use during the transfer.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Complete the Transfer in Cloudflare
    &lt;ul&gt;
      &lt;li&gt;In your Cloudflare account, start the transfer process. Enter the authorization code and update your billing information as required.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Configure Email Forwarding (Optional)
    &lt;ul&gt;
      &lt;li&gt;If you used Google Domains for email forwarding, you can set up similar forwarding in Cloudflare to ensure uninterrupted email service.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Approve the Transfer
    &lt;ul&gt;
      &lt;li&gt;Google Domains will send you an email to confirm the transfer. Approve the transfer to speed up the process, which can otherwise take up to 5 days.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Transfer Completion
    &lt;ul&gt;
      &lt;li&gt;Once the transfer is complete, you’ll receive a confirmation email from Cloudflare. Your domain is now fully managed by Cloudflare.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;As a website owner, understanding how DNS records work, the involved entities in play, their interactions and how to manage the site’s domain settings are important. This article explained these key concepts as part of a migration from the domain registrar Google Domains to Cloudflare and its free DNS managment service.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.bytebytego.com/p/what-happens-when-you-type-a-url&quot;&gt;https://blog.bytebytego.com/p/what-happens-when-you-type-a-url&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.bytebytego.com/p/how-does-the-domain-name-system-dns&quot;&gt;https://blog.bytebytego.com/p/how-does-the-domain-name-system-dns&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.bytebytego.com/i/132279282/url-uri-urn-do-you-know-the-differences&quot;&gt;https://blog.bytebytego.com/i/132279282/url-uri-urn-do-you-know-the-differences&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Blogging" /><summary type="html">In this article, I will outline how I migrated from Google Domains, due to its shutdown, to Cloudflare all while explaining some key terms and concepts.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" /><media:content medium="image" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Level Up Your SQL Skills As a Data Engineer</title><link href="https://www.firasesbai.com/articles/2024/12/30/level-up-sql-skills-data-engineer.html" rel="alternate" type="text/html" title="Level Up Your SQL Skills As a Data Engineer" /><published>2024-12-30T00:00:00+00:00</published><updated>2024-12-30T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2024/12/30/level-up-sql-skills-data-engineer</id><content type="html" xml:base="https://www.firasesbai.com/articles/2024/12/30/level-up-sql-skills-data-engineer.html">&lt;p&gt;&lt;em&gt;Mastering SQL and understanding what can be done with it is crucial in making you a better data engineer.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This article is your starting point to leveling up your SQL skills. We will start with a refresher and then move on to more advanced topics and optimizations techniques all packed with concrete examples and a final case study to wrap it all up.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#sql-overview&quot; id=&quot;markdown-toc-sql-overview&quot;&gt;SQL Overview&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sql-query-order-of-execution&quot; id=&quot;markdown-toc-sql-query-order-of-execution&quot;&gt;SQL Query Order of Execution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#advanced-sql&quot; id=&quot;markdown-toc-advanced-sql&quot;&gt;Advanced SQL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#subquery-vs-cte-vs-temp-table&quot; id=&quot;markdown-toc-subquery-vs-cte-vs-temp-table&quot;&gt;Subquery vs CTE vs Temp Table&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#what-is-a-subquery&quot; id=&quot;markdown-toc-what-is-a-subquery&quot;&gt;What is a Subquery?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#what-is-a-cte&quot; id=&quot;markdown-toc-what-is-a-cte&quot;&gt;What is a CTE?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#what-is-a-temp-table&quot; id=&quot;markdown-toc-what-is-a-temp-table&quot;&gt;What is a Temp Table?&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#window-functions&quot; id=&quot;markdown-toc-window-functions&quot;&gt;Window Functions&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#so-what-exactly-are-window-functions&quot; id=&quot;markdown-toc-so-what-exactly-are-window-functions&quot;&gt;So what exactly are Window functions?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#breakdown-of-window-functions&quot; id=&quot;markdown-toc-breakdown-of-window-functions&quot;&gt;Breakdown of Window functions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sql-query-optimization-techniques&quot; id=&quot;markdown-toc-sql-query-optimization-techniques&quot;&gt;SQL Query Optimization Techniques&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#case-study-nyc-citi-bike-trips&quot; id=&quot;markdown-toc-case-study-nyc-citi-bike-trips&quot;&gt;Case Study: NYC Citi Bike Trips&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;sql-overview&quot;&gt;SQL Overview&lt;/h2&gt;

&lt;p&gt;There are 5 components of the SQL language:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data Definition Language (DDL)&lt;/strong&gt;: Used to define the structure that holds the data. It includes commands like:
    &lt;ul&gt;
      &lt;li&gt;CREATE: Used to create objects in the database (e.g., tables).&lt;/li&gt;
      &lt;li&gt;ALTER: Used to modify the structure of an existing database object.&lt;/li&gt;
      &lt;li&gt;DROP: Used to delete objects from the database.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Manipulation Language (DML)&lt;/strong&gt;: deals with the manipulation of the data itself. Common DML commands include:
    &lt;ul&gt;
      &lt;li&gt;INSERT: Used to add new rows of data into a table.&lt;/li&gt;
      &lt;li&gt;UPDATE: Used to modify existing data within a table.&lt;/li&gt;
      &lt;li&gt;DELETE: Used to remove rows from a table.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Control Language (DCL)&lt;/strong&gt;: concerned with the rights, permissions, and other controls of the database system. It includes commands like:
    &lt;ul&gt;
      &lt;li&gt;GRANT: Gives users access privileges to database.&lt;/li&gt;
      &lt;li&gt;REVOKE: Takes back privileges granted with the GRANT command.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transaction Control Language (TCL)&lt;/strong&gt;: deals with transactions within a database. Transactions allow for control over groups of SQL statements. Common TCL commands include:
    &lt;ul&gt;
      &lt;li&gt;COMMIT: Saves changes made during the current transaction.&lt;/li&gt;
      &lt;li&gt;ROLLBACK: Restores the database to its original state since the last COMMIT.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Query Language (DQL)&lt;/strong&gt;: used to retrieve data from the database. The primary command in DQL is:
    &lt;ul&gt;
      &lt;li&gt;SELECT: Retrieves data from one or more tables.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These components together provide a comprehensive set of tools to interact with and manage databases using SQL.&lt;/p&gt;

&lt;h2 id=&quot;sql-query-order-of-execution&quot;&gt;SQL Query Order of Execution&lt;/h2&gt;

&lt;p&gt;For a given SQL query, the SQL engine will execute its clauses in a specific standard order in order to process your query and return the desired results.&lt;/p&gt;

&lt;p&gt;Understanding the order in which a SQL query is executed is important and will allow you to optimize your queries by minimizing the amount of data processed and improving query execution times. In addition, it will result in writing better and more efficient queries which consume less resources and lead to faster response times and less constraints on the database server.&lt;/p&gt;

&lt;p&gt;The following table summarizes the SQL query order of execution:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Order&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Clause&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Function&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;From/Join&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Determines table(s) from which data will be queried&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Where&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Filters data on rows&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Group By&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Checks if you have aggregations&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Having&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Filters data based on specified groups&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Select&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Selects which columns you want to see returned&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Order By&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Sorts the data returned&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Limit&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Limits the number of rows returned&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;Table 1: SQL query order of execution&lt;/p&gt;

&lt;h2 id=&quot;advanced-sql&quot;&gt;Advanced SQL&lt;/h2&gt;

&lt;h2 id=&quot;subquery-vs-cte-vs-temp-table&quot;&gt;Subquery vs CTE vs Temp Table&lt;/h2&gt;

&lt;h3 id=&quot;what-is-a-subquery&quot;&gt;What is a Subquery?&lt;/h3&gt;

&lt;p&gt;Subquery, also known as inner query, is a query nested inside another SQL query. Subqueries are enclosed within parentheses and can be placed in various parts of a SQL statement such as the SELECT, FROM, WHERE, or HAVING clauses.&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;   
&lt;span class=&quot;no&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;departments&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
   &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
   &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
   &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DECIMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
   &lt;span class=&quot;n&quot;&gt;department_id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;departments&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'HR'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Finance'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Marketing'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;VALUES&lt;/span&gt; 
   &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'John Doe'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
   &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Jane Smith'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
   &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Alice Johnson'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
   &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Bob Williams'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;55000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Suppose we want to retrieve all the employees that work in &lt;strong&gt;HR&lt;/strong&gt; department:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;   
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
	&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;departments&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'HR'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Subqueries are a powerful feature of SQL allowing for more complex and dynamic queries by enabling you to use the results of one query as a condition or value in another.&lt;/p&gt;

&lt;h3 id=&quot;what-is-a-cte&quot;&gt;What is a CTE?&lt;/h3&gt;

&lt;p&gt;CTE stands for Common Table Expression. It is a named temporary result set that exist only for the duration of the main query.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Basic Syntax:&lt;/em&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CTE&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cte_name&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CTE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;definition&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;here&lt;/span&gt;
	&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;column1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;column2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
	&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_name&lt;/span&gt;
	&lt;span class=&quot;no&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conditions&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CTE&lt;/span&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cte_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;CTEs are useful for improving the readability and maintainability of complex queries. In addition, when you need to use the same subquery result multiple times within a larger query, it avoids duplicating complex logic and can make queries more readable and easier to maintain.&lt;/p&gt;

&lt;h3 id=&quot;what-is-a-temp-table&quot;&gt;What is a Temp Table?&lt;/h3&gt;

&lt;p&gt;A temporary table in SQL is a table that exists temporarily on the database server.&lt;/p&gt;

&lt;p&gt;Unlike CTEs that exist only in the context of the query in which they are defined, Temp tables can be created and used just like regular database tables, but they are dropped automatically when the session ends or when explicitly dropped by the user.&lt;/p&gt;

&lt;p&gt;Temp Tables are useful for holding intermediate results that you want to reuse multiple times within a session and allow to break down complex tasks into smaller, more manageable tasks.&lt;/p&gt;

&lt;h2 id=&quot;window-functions&quot;&gt;Window Functions&lt;/h2&gt;

&lt;p&gt;SQL Window functions show up in pretty much every data engineering interview nowadays. Therefore, it is important to understand the key concepts related to this powerful feature.&lt;/p&gt;

&lt;h3 id=&quot;so-what-exactly-are-window-functions&quot;&gt;So what exactly are Window functions?&lt;/h3&gt;

&lt;p&gt;Window functions allow you to perform calculations across a set of table rows related to the current row. This is different from aggregate functions, which summarize data into a single output row for each group.&lt;/p&gt;

&lt;h3 id=&quot;breakdown-of-window-functions&quot;&gt;Breakdown of Window functions&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Partitioning&lt;/strong&gt;: Window functions are typically used with an &lt;strong&gt;OVER clause&lt;/strong&gt;, which defines the window of rows over which the function will operate. This clause can partition the result set into groups of rows based on one or more column values.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ordering&lt;/strong&gt;: Within each partition, you can specify an &lt;strong&gt;ORDER BY&lt;/strong&gt; clause to define the order in which the rows are processed by the window function.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Window Frame&lt;/strong&gt;: This defines the subset of rows within the partition to which the function is applied. The frame can be defined as rows preceding or following the current row, or between a range of rows.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are two main categories of window functions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Aggregate Window Functions:&lt;/strong&gt; These functions resemble regular aggregate functions (SUM, COUNT, AVG, etc.) but operate within the window instead of across the entire dataset. This allows you to calculate things like &lt;strong&gt;running totals&lt;/strong&gt; or &lt;strong&gt;moving averages&lt;/strong&gt;.&lt;/p&gt;

    &lt;p&gt;Commonly used SQL Aggregate Window Functions include:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;COUNT&lt;/strong&gt;() counts the number of rows in a specified column across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;SUM&lt;/strong&gt;() computes the sum of values within a specified column across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;AVG&lt;/strong&gt;() calculates the average of a selected group of values across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;MIN&lt;/strong&gt;() retrieves the lowest value from a particular column across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;MAX&lt;/strong&gt;() fetches the highest value from a specific column across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;FIRST_VALUE&lt;/strong&gt;() returns the first value in a designated column across a defined window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;LAST_VALUE&lt;/strong&gt;() provides the last value in a given column across a defined window.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ranking Window Functions:&lt;/strong&gt; These functions assign a rank or order to each row based on a specified value. Examples include ROW_NUMBER(), RANK(), and DENSE_RANK(). These are useful for identifying &lt;strong&gt;top performers&lt;/strong&gt;, assigning &lt;strong&gt;unique sequential identifiers&lt;/strong&gt;, or &lt;strong&gt;grouping data into buckets&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To better illustrate the syntax of the window function, let’s take the following example:&lt;/p&gt;

&lt;p&gt;Suppose we have a table &lt;strong&gt;employees&lt;/strong&gt;:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DECIMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;VALUES&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Alice'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'HR'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;50000.00&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Bob'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'HR'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Charlie'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Engineering'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'David'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Engineering'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Eve'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Engineering'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;90000.00&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We want to calculate the average salary for each departement:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_salary_department&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The result would be:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_salary_department&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;------------------------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Alice&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;50000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;55000.00&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Bob&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;55000.00&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Charlie&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;David&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Eve&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;90000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt;   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The window function calculates the average salary for each row in the result set, but it doesn’t change the number of rows returned. Each row retains its original data, but we also get a new column with the average salary for the department of that row.&lt;/p&gt;

&lt;p&gt;However, using a &lt;strong&gt;Group By&lt;/strong&gt;, the result set is reduced to one row per department, where each row represents a distinct department.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_salary_department&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_salary_department&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;------------------------------------&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;55000.00&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To better illustrate the difference between ROW_NUMBER(), RANK(), and DENSE_RANK(), we will update our employees table with the following values:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;   
&lt;span class=&quot;o&quot;&gt;-------------------------------------------&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Alice&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Bob&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Charlie&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;David&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Eve&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;75000.00&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Frank&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt;   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Ranking the employees within their departments based on their salaries results in the following queries:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;ROW_NUMBER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_number&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_number&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;-------------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Bob&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Frank&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Alice&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Charlie&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;David&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Eve&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;75000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Each Row has a unique number regardless of ties.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;RANK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;--------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Bob&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Frank&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Alice&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Charlie&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;David&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Eve&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;75000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt; 
&lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;DENSE_RANK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dense_rank&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;emp_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emp_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;department&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dense_rank&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;-------------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Bob&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Frank&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;70000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Alice&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;HR&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;60000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Charlie&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;David&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;80000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Eve&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Engineering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;75000.00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The difference between RANK and DENSE_RANK is the gaps between the ranking in case of ties. You can check this by looking at the row of Alice and Eve where their rank is 3 with RANK but 2 with DENSE_RANK.&lt;/p&gt;

&lt;h2 id=&quot;sql-query-optimization-techniques&quot;&gt;SQL Query Optimization Techniques&lt;/h2&gt;

&lt;p&gt;Since SQL is declarative, there are typically many alternative ways to execute a given query, with widely varying performance. When a query is submitted to the database, the query optimizer evaluates different possible plans or query execution plans which are sequences of steps used to access data. Once determined, the most efficient query is then returned.&lt;/p&gt;

&lt;p&gt;Many database systems provide tools to view the query plan, either graphically or in text format. This helps developers understand and optimize query performance.&lt;/p&gt;

&lt;p&gt;Regularly reviewing and analyzing query execution plans to understand how queries are executed and identify potential performance issues is very helpful. In addition, knowing and applying other optimization techinques can enahance the performance of your system. Here are some general tips for query optimization:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use column names instead of * in a SELECT statement. This reduces the amount of data transferred and processed.&lt;/li&gt;
  &lt;li&gt;Use the most appropriate and efficient data types for your columns to save space and improve performance.&lt;/li&gt;
  &lt;li&gt;Create indexes on columns that are frequently used in WHERE clauses, JOIN conditions, and as part of ORDER BY clauses for faster data retrievel.&lt;/li&gt;
  &lt;li&gt;Use appropriate join types(INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL JOIN) and ensure that join conditions are based on indexed columns.&lt;/li&gt;
  &lt;li&gt;Consider the order of joins: join smaller tables first to reduce the size of intermediate results.&lt;/li&gt;
  &lt;li&gt;Use INNER JOINs where possible as it’s usually faster than OUTER JOINs.&lt;/li&gt;
  &lt;li&gt;Use subqueries only when necessary and consider alternatives like JOINs or Common Table Expressions (CTEs) to simplify and optimize complex queries&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;case-study-nyc-citi-bike-trips&quot;&gt;Case Study: NYC Citi Bike Trips&lt;/h2&gt;

&lt;p&gt;In this section we will try to apply some of the learnings from previous sections to answer some questions about the Citi Bike Trips dataset using SQL.&lt;/p&gt;

&lt;p&gt;This dataset contains information about trips of the Citi Bike share program. It is hosted and available in Google BigQuery and included in the free tier processing. For more information, check &lt;a href=&quot;https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-citi-bike?project=propane-cooler-150809&quot;&gt;this link&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Each question is followed by the corresponding SQL query and its output. For better readability the output of some queries is limited to 3 rows.&lt;/p&gt;

&lt;p&gt;The answer and expected output are hidden. Try to answer the questions to test your understanding before revealing them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Which trips lasted longer than 30 minutes?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;end_station_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;bikeid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;usertype&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   
   &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_station_name&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bikeid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;usertype&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;------------------------------------------------------------------------------------&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;16930&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;South&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Whitehall&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;NYCBS&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Depot&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BAL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DYR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14826&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Subscriber&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;547&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Ave&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;NYCBS&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Depot&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BAL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DYR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;22094&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Subscriber&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;442403&lt;/span&gt;       &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;E&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Avenue&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;A&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;NYCBS&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Depot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DEL&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16592&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Customer&lt;/span&gt;   
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is the average trip duration for each user type (Subscriber and Customer)?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;usertype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;ROUND&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;average_trip_duration&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;usertype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   
   &lt;span class=&quot;n&quot;&gt;usertype&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;average_trip_duration&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;----------------------------------&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;Subscriber&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;806.38&lt;/span&gt;  
   &lt;span class=&quot;no&quot;&gt;Customer&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2145.51&lt;/span&gt; 
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How many trips were made each day?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;starttime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;COUNT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;-----------------------&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;2013&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;07&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;01&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16650&lt;/span&gt; 
   &lt;span class=&quot;mi&quot;&gt;2013&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;07&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;02&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;22745&lt;/span&gt; 
   &lt;span class=&quot;mi&quot;&gt;2013&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;07&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;03&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21864&lt;/span&gt; 
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Which start station has the highest number of trips?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;COUNT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;----------------------------------&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;Pershing&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Square&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;North&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;438077&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;E&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Broadway&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;423334&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Ave&lt;/span&gt;       &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;403795&lt;/span&gt; 
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Which stations had more than 1,000 trips starting from them?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;COUNT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_station_name&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;HAVING&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   
   &lt;span class=&quot;n&quot;&gt;start_duration_name&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_count&lt;/span&gt; 
   &lt;span class=&quot;o&quot;&gt;----------------------------------&lt;/span&gt; 
   &lt;span class=&quot;no&quot;&gt;Liberty&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Broadway&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;149199&lt;/span&gt;     
   &lt;span class=&quot;no&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Ave&lt;/span&gt;       &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;118394&lt;/span&gt;     
   &lt;span class=&quot;no&quot;&gt;Henry&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Grand&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;St&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;105108&lt;/span&gt;     
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is the rolling average trip duration for each bike?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;bikeid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;starttime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bikeid&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starttime&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rolling_avg&lt;/span&gt; 
      &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;bikeid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_date&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rolling_avg&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;------------------------------------------------&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;23076&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2015&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;04&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;468&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;505.2&lt;/span&gt;      
   &lt;span class=&quot;mi&quot;&gt;23076&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2015&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;04&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;332&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;869.8&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;23076&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2015&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;05&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;729&lt;/span&gt;          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;588.8&lt;/span&gt;
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What are the top 3 longest trips for each station?&lt;/strong&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Show Answer&lt;/summary&gt;
   
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;      
   &lt;span class=&quot;no&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ranked_trips&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;start_station_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;no&quot;&gt;ROW_NUMBER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_station_id&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt;
      &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`bigquery-public-data.new_york_citibike.citibike_trips`&lt;/span&gt;
   &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;SELECT&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;start_station_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ranked_trips&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
   &lt;span class=&quot;no&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_station_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;start_station_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tripduration&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;-------------------------------&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;72&lt;/span&gt;               &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2006840&lt;/span&gt; 
   &lt;span class=&quot;mi&quot;&gt;72&lt;/span&gt;               &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;792782&lt;/span&gt;  
   &lt;span class=&quot;mi&quot;&gt;72&lt;/span&gt;               &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;594321&lt;/span&gt;  
   
   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;In this article, we explored on a high level topics of different difficulty levels of the SQL language. Hopefully the examples and the case study helped in clarifying these concepts but this is only the tip of the iceberg. Writing clearer and more efficient SQL queries requires practice. The resources section contains valuable materials to support you further in your learning journey.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Query_plan&quot;&gt;https://en.wikipedia.org/wiki/Query_plan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://sqlzoo.net/wiki/SQL_Tutorial&quot;&gt;https://sqlzoo.net/wiki/SQL_Tutorial&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.windowfunctions.com/&quot;&gt;https://www.windowfunctions.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://datalemur.com/sql-tutorial&quot;&gt;https://datalemur.com/sql-tutorial&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://selectstarsql.com/&quot;&gt;https://selectstarsql.com/&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><summary type="html">Mastering SQL and understanding what can be done with it is crucial in making you a better data engineer.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" /><media:content medium="image" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">System Desing Interview Blueprint</title><link href="https://www.firasesbai.com/articles/2024/12/08/system-design-interview-blueprint.html" rel="alternate" type="text/html" title="System Desing Interview Blueprint" /><published>2024-12-08T00:00:00+00:00</published><updated>2024-12-08T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2024/12/08/system-design-interview-blueprint</id><content type="html" xml:base="https://www.firasesbai.com/articles/2024/12/08/system-design-interview-blueprint.html">&lt;p&gt;&lt;em&gt;This article contains general guidelines and a reference framework to use when approaching system design interview.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;System design interview is a key component of the technical interview process that is no longer limited to big tech companies or traditional software engineering positions. Even though each company is different, a system design round is not uncommon for data engineering positions especially for senior and more experienced roles.&lt;/p&gt;

&lt;p&gt;The purpose of this step is to assess your ability to design large-scale, complex software systems from scratch focusing on your problem solving skills and communication and collaboration capabilities.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#general-concepts&quot; id=&quot;markdown-toc-general-concepts&quot;&gt;General Concepts&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#api-and-web-development&quot; id=&quot;markdown-toc-api-and-web-development&quot;&gt;API and Web Development&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#security&quot; id=&quot;markdown-toc-security&quot;&gt;Security&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#software-architecture&quot; id=&quot;markdown-toc-software-architecture&quot;&gt;Software Architecture&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#database-and-storage&quot; id=&quot;markdown-toc-database-and-storage&quot;&gt;Database and storage&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#caching-and-performance&quot; id=&quot;markdown-toc-caching-and-performance&quot;&gt;Caching and performance&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#workflow&quot; id=&quot;markdown-toc-workflow&quot;&gt;Workflow&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#step-1-design-scope&quot; id=&quot;markdown-toc-step-1-design-scope&quot;&gt;Step 1: Design Scope&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#general-questions&quot; id=&quot;markdown-toc-general-questions&quot;&gt;General questions&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#problem-specific-questions&quot; id=&quot;markdown-toc-problem-specific-questions&quot;&gt;Problem specific questions&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#non-functional-requirements&quot; id=&quot;markdown-toc-non-functional-requirements&quot;&gt;Non Functional Requirements&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#back-of-the-envelope-estimation&quot; id=&quot;markdown-toc-back-of-the-envelope-estimation&quot;&gt;Back of the envelope estimation&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#step-2-high-level-design&quot; id=&quot;markdown-toc-step-2-high-level-design&quot;&gt;Step 2: High Level Design&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#step-3-design-deep-dive&quot; id=&quot;markdown-toc-step-3-design-deep-dive&quot;&gt;Step 3: Design Deep Dive&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#step-4-wrap-up&quot; id=&quot;markdown-toc-step-4-wrap-up&quot;&gt;Step 4: Wrap up&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#common-system-design-use-cases&quot; id=&quot;markdown-toc-common-system-design-use-cases&quot;&gt;Common System Design Use Cases&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;general-concepts&quot;&gt;General Concepts&lt;/h2&gt;

&lt;p&gt;While there is no shortage of information or resources on the internet when it comes to system design interview preparation, following is a list of some concepts and topics that I personnaly found common and almost always used in every system and thus you should be familiar with before going to the interview:&lt;/p&gt;

&lt;h3 id=&quot;api-and-web-development&quot;&gt;API and Web Development&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://bytebytego.com/guides/a-cheatsheet-on-comparing-api-architectural-styles/&quot;&gt;API Architecture Styles&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://bytebytego.com/guides/a-cheat-sheet-for-api-designs/&quot;&gt;API Design&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;API Gateway&lt;/strong&gt;: An API gateway acts as a single entry point for clients accessing APIss providing centralized management. It can perform tasks like:
    &lt;ul&gt;
      &lt;li&gt;parameter validation of HTTP requests&lt;/li&gt;
      &lt;li&gt;allow-list/deny-list checks&lt;/li&gt;
      &lt;li&gt;authentication and authorization via identity provider&lt;/li&gt;
      &lt;li&gt;apply rate limiting rules&lt;/li&gt;
      &lt;li&gt;routing and service discovery&lt;/li&gt;
      &lt;li&gt;protocol conversion to backend microservice&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rate Limiter&lt;/strong&gt;: a rate limiter is used to control the rate of traffic requests sent by a client or a service. If the requests count hits the threshold defined by the rate limiter, all the following reuqests are blocked. The benefits of using a rate limiter include preventing resource starvation caused by Denial of Service (DoS) attack and reducing cost by requiring fewer servers and preventing these from being overloaded. 
Some popular rate limiting algorithms include:
    &lt;ul&gt;
      &lt;li&gt;Token bucket&lt;/li&gt;
      &lt;li&gt;Leaky bucket&lt;/li&gt;
      &lt;li&gt;Fixed window&lt;/li&gt;
      &lt;li&gt;Sliding window&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;For more information check out &lt;a href=&quot;https://www.geeksforgeeks.org/rate-limiting-algorithms-system-design/&quot;&gt;this link&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Proxy&lt;/strong&gt;: A proxy server acts as an intermediary between clients and a server, handling requests from the client and forwarding them to the server. It can be used for various purposes, including filtering content, providing anonymity, and caching web pages.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reverse Proxy&lt;/strong&gt;: A reverse proxy sits in front of one or more servers and acts as a single entry point for clients accessing those servers. It handles incoming requests, caches content, provides load balancing, and can also enhance security by hiding the actual server IP addresses and handling encryption and decryption of SSL communications.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer?tab=readme-ov-file#load-balancer&quot;&gt;Load Balancer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;security&quot;&gt;Security&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://bytebytego.com/guides/session-cookie-jwt-token-sso-and-oauth-2/&quot;&gt;User Identity Management&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;HTTPS&lt;/strong&gt;: secures web communication by building upon TCP. It starts with a &lt;strong&gt;TLS handshake&lt;/strong&gt;: your browser validates the website’s identity using its SSL/TLS certificate (which contains its public key) and is verified by a trusted CA. This public key is then used in &lt;strong&gt;asymmetric encryption&lt;/strong&gt; to securely exchange a shared secret key. Once established, all subsequent data transfer is encrypted using this shared secret key via much faster &lt;strong&gt;symmetric encryption&lt;/strong&gt;. Asymmetric encryption is slower, so it’s only used for the initial secure setup, while faster symmetric encryption handles the continuous data flow, so this two-phase approach ensures both secure identity verification and efficient data privacy.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;software-architecture&quot;&gt;Software Architecture&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Blue-Green Deployment&lt;/strong&gt;: With blue-green deployment, we have two identical environments: one is staging (blue) and the other is production (green). The staging environment is one version ahead of production. Once testing is done in the staging environment, user traffic is switched to the staging environment, and the staging becomes the production. This deployment strategy is simple to perform rollback, but having two identical production quality environments could be expensive.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Canary Deployment&lt;/strong&gt;: A canary deployment upgrades services gradually, each time to a subset of users. It is cheaper than blue-green deployment and easy to perform rollback. However, since there is no staging environment, we have to test on production. This process is more complicated because we need to monitor the canary while gradually migrating more and more users away from the old version.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;database-and-storage&quot;&gt;Database and storage&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Database choice&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
  &lt;img src=&quot;/assets/images/articles/20_database_choice.png&quot; alt=&quot;comparison between types and characteristics of databases&quot; /&gt;
  &lt;figcaption&gt;Figure 1: Types of Databases - &lt;a href=&quot;https://blog.bytebytego.com/p/understanding-database-types&quot;&gt;Image Source&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.geeksforgeeks.org/consistent-hashing/&quot;&gt;Consistent hashing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pessimistic vs Optimistic Locking&lt;/strong&gt;: Pessimistic locking assumes conflicts will occur and locks the data before any changes are made. It prevents other users from accessing and updating the data until the lock is released. The most common way to implement this is by using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT... FOR UPDATE&lt;/code&gt;. 
Optimistic locking assumes conflicts are rare. It allows multiple users to access data simultaneously and checks for conflicts when changes are committed. If a conflict is detected, the operation is rolled back. The most common way to implement it is by adding a version column to your database table.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;caching-and-performance&quot;&gt;Caching and performance&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer?tab=readme-ov-file#content-delivery-network&quot;&gt;Content Delivery Network (CDN)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt;: it improves load times and can reduce the load on your servers and databases. It is important to understand the different layers where caching can be applied, their advantages and disadvantages and strategies to update your cache. These would include:
    &lt;ul&gt;
      &lt;li&gt;Client caching&lt;/li&gt;
      &lt;li&gt;CDN caching&lt;/li&gt;
      &lt;li&gt;Web server caching&lt;/li&gt;
      &lt;li&gt;Database caching&lt;/li&gt;
      &lt;li&gt;Application caching&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;workflow&quot;&gt;Workflow&lt;/h2&gt;

&lt;h3 id=&quot;step-1-design-scope&quot;&gt;Step 1: Design Scope&lt;/h3&gt;

&lt;p&gt;Generally you will be tasked with designing a well known system or application that is used by hundreds if not millions of users with a broad and ambiguous statement. Obviously coming up with all the potential problems, edge cases and details around the ultimate solution is not a one session task. The system in question came to its current state after years of cumulative efforts from multiple engineering teams and designing something similar in the current context and scope is not a realistic expectation nor a feasible task. Therefore, a good starting point would be to define the scope of the design and what you want to achieve during the interview.&lt;/p&gt;

&lt;h4 id=&quot;general-questions&quot;&gt;General questions&lt;/h4&gt;

&lt;p&gt;Start by asking some general questions to better understand the requirements. Make sure to take notes of any assumptions and decisions made along the way.&lt;/p&gt;

&lt;p&gt;Following are some questions to consider:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What are the most important features?&lt;/li&gt;
  &lt;li&gt;Is this a mobile app, a web app or both?&lt;/li&gt;
  &lt;li&gt;How many Daily Active Users (DAU) does the product have?&lt;/li&gt;
  &lt;li&gt;Can we leverage some of the existing cloud infrastructure provided by Amazon, Google or Microsoft?&lt;/li&gt;
  &lt;li&gt;Is encryption required?&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;problem-specific-questions&quot;&gt;Problem specific questions&lt;/h4&gt;

&lt;p&gt;Building up on these, make sure to dive deeper in your conversation with your interviewer on more problem specific questions to clarify any ambiguities.&lt;/p&gt;

&lt;h4 id=&quot;non-functional-requirements&quot;&gt;Non Functional Requirements&lt;/h4&gt;

&lt;p&gt;After clarifying the requirements, it is important to understand the non functional aspects of your system which will guide you in your design choices since they are a crucial part of any large scale system.&lt;/p&gt;

&lt;p&gt;Some areas to consider would be:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reliability&lt;/li&gt;
  &lt;li&gt;Scalability&lt;/li&gt;
  &lt;li&gt;High Availability&lt;/li&gt;
  &lt;li&gt;Fault tolerance&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;back-of-the-envelope-estimation&quot;&gt;Back of the envelope estimation&lt;/h4&gt;

&lt;p&gt;A final part of defining your scope would involve doing back-of-the-envelope calculations. Weather your interviewer asks you to do it or not, these estimations help you assess which design will meet your requirements.&lt;/p&gt;

&lt;p&gt;These calculations will be based on the requirements and agreed upon assumptions form your previous questions and common performance numbers. You you should familiarize yourself with these numbers &lt;a href=&quot;https://github.com/donnemartin/system-design-primer?tab=readme-ov-file#appendix&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;step-2-high-level-design&quot;&gt;Step 2: High Level Design&lt;/h3&gt;

&lt;p&gt;After clarifying the design scope, now it is time to identify the key components of your system. These are the high level components that you are going to work with for the rest of the interview. As you progress, you will be adding more details to your design along the way so the point here is to really start at a high level even if it seems oversimplified. This will serve as a baseline as you work with the interviewer on identifying the right level of detail needed.&lt;/p&gt;

&lt;h3 id=&quot;step-3-design-deep-dive&quot;&gt;Step 3: Design Deep Dive&lt;/h3&gt;

&lt;p&gt;Based on your domain of expertise, choose the part you feel most comfortable with and start diving deeper on its key components. For example, when starting at the database layer you could discuss the factors to consider when selecting the appropriate database technology such as scalability, performance and data consistency and model. For someone else this could be the API layer where they can discuss the appropriate architecture style to choose and give an example of some API endpoints requests, parameters and responses.&lt;/p&gt;

&lt;p&gt;While covering different parts of the system, it is important to consider system optimizations and cost savings aspects to ensure your system handles the requirements previously identified in the most efficient way.&lt;/p&gt;

&lt;p&gt;Make sure to also discuss some scenarios and user journeys to demonstrate how your proposed system supports how the users would eventually interact with it.&lt;/p&gt;

&lt;h3 id=&quot;step-4-wrap-up&quot;&gt;Step 4: Wrap up&lt;/h3&gt;

&lt;p&gt;At this stage you should be approaching the end of the session. It could be useful to give the interviewer a recap of your design. Since there is always something to improve, use this opportunity to mention potential improvements in order to handle more scale or refinements you could do if you had more time especially if you had to do some tradeoffs at the beginning. Discussing things like monitoring and logging and error handling in case of failures of different components in your system are worth touching upon and would demonstrate your critical thinking.&lt;/p&gt;

&lt;h2 id=&quot;common-system-design-use-cases&quot;&gt;Common System Design Use Cases&lt;/h2&gt;

&lt;p&gt;Following is a list of common system design questions and real world applications each with a set of unique challenges, requirements and type of data.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;File storage and collaboration platform
    &lt;ul&gt;
      &lt;li&gt;Dropbox&lt;/li&gt;
      &lt;li&gt;Google Drive&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Messaging application
    &lt;ul&gt;
      &lt;li&gt;Slack&lt;/li&gt;
      &lt;li&gt;Facebook messenger&lt;/li&gt;
      &lt;li&gt;Whatsapp&lt;/li&gt;
      &lt;li&gt;WeChat&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Music streaming platform
    &lt;ul&gt;
      &lt;li&gt;Spotify&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;News feed system
    &lt;ul&gt;
      &lt;li&gt;Facebook news feed&lt;/li&gt;
      &lt;li&gt;Instagram feed&lt;/li&gt;
      &lt;li&gt;Twitter timeline&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ride sharing app
    &lt;ul&gt;
      &lt;li&gt;Uber&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Video streaming service
    &lt;ul&gt;
      &lt;li&gt;Netflix&lt;/li&gt;
      &lt;li&gt;Youtube&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Online Marketplace
    &lt;ul&gt;
      &lt;li&gt;Airbnb&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;E-commerce Platform
    &lt;ul&gt;
      &lt;li&gt;Amazon.com&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;This article presented a mental model with a logical set of steps to follow when approaching a system design interview enriched with pointers to an opinionated set of topics and concepts to review beforehand.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning and good luck on your system design interview!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.goodreads.com/en/book/show/54109255&quot;&gt;https://www.goodreads.com/en/book/show/54109255&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.goodreads.com/en/book/show/60631342&quot;&gt;https://www.goodreads.com/en/book/show/60631342&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ByteByteGoHq/system-design-101&quot;&gt;https://github.com/ByteByteGoHq/system-design-101&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://bytebytego.com/guides/how-to-deploy-services/&quot;&gt;https://bytebytego.com/guides/how-to-deploy-services/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://bytebytego.com/guides/8-common-system-design-problems-and-solutions/&quot;&gt;https://bytebytego.com/guides/8-common-system-design-problems-and-solutions/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer&quot;&gt;https://github.com/donnemartin/system-design-primer&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><category term="General" /><summary type="html">This article contains general guidelines and a reference framework to use when approaching system design interview.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" /><media:content medium="image" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Evolution of Analytical Data Architectures: From Data Warehouses to Lakehouses</title><link href="https://www.firasesbai.com/articles/2024/11/17/evolution-analytical-data-architectures.html" rel="alternate" type="text/html" title="Evolution of Analytical Data Architectures: From Data Warehouses to Lakehouses" /><published>2024-11-17T00:00:00+00:00</published><updated>2024-11-17T00:00:00+00:00</updated><id>https://www.firasesbai.com/articles/2024/11/17/evolution-analytical-data-architectures</id><content type="html" xml:base="https://www.firasesbai.com/articles/2024/11/17/evolution-analytical-data-architectures.html">&lt;p&gt;&lt;em&gt;In this article, we will go through a brief overview of the journey from the foundational data warehouses to the data lakes and up to the emerging concept of the data lakehouse.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The evolution of data management has been driven by the growing complexity and scale of modern data needs. Organizations have sought different solutions over the years for handling diverse data types while optimizing for cost efficiency.&lt;/p&gt;

&lt;p&gt;This article explores the key transitions from one analytical architecture to the other and the challenges that shaped each phase.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So let’s get started!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1&gt; Contents &lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#data-warehouses&quot; id=&quot;markdown-toc-data-warehouses&quot;&gt;Data Warehouses&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-lakes&quot; id=&quot;markdown-toc-data-lakes&quot;&gt;Data Lakes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#two-tier-architecture-data-warehouse--data-lake&quot; id=&quot;markdown-toc-two-tier-architecture-data-warehouse--data-lake&quot;&gt;Two-Tier Architecture: Data Warehouse + Data Lake&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-lakehouses&quot; id=&quot;markdown-toc-data-lakehouses&quot;&gt;Data Lakehouses&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#what-is-a-table-format&quot; id=&quot;markdown-toc-what-is-a-table-format&quot;&gt;What is a Table Format?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#open-table-formats&quot; id=&quot;markdown-toc-open-table-formats&quot;&gt;Open Table Formats&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#recap&quot; id=&quot;markdown-toc-recap&quot;&gt;Recap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;data-warehouses&quot;&gt;Data Warehouses&lt;/h2&gt;

&lt;p&gt;The concept of data warehousing emerged in the late 1980s as a response to the growing need for businesses to make data-driven decisions. In fact, the proliferation of applications and the resulting disparate data across the organization resulted in a tedious manual process of querying and finding the right data with the correct version in order to avoid incorrect decisions.&lt;/p&gt;

&lt;p&gt;As a result, the &lt;em&gt;Data Warehouse&lt;/em&gt; was born.&lt;/p&gt;

&lt;p&gt;A data warehouse is a centralized repository for storing and managing large amounts of data from various sources.&lt;/p&gt;

&lt;p&gt;Data Warehouse is not the same as a database but rather typically built on top of data copied from other databases and addresses several limitations of traditional operational databases:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Centralization&lt;/strong&gt;: They provided a single source of truth for enterprise-wide data.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Historical analysis&lt;/strong&gt;: Unlike operational systems focused on current data, warehouses allowed for trend analysis over time.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Complex querying&lt;/strong&gt;: Designed for analytical processing, they could handle complex queries more efficiently than transaction-oriented databases.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data quality&lt;/strong&gt;: The ETL (Extract, Transform, Load) process helped in cleaning and standardizing data before loading it into the warehouse.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, as data types evolved and volumes grew exponentially, data warehouses faced mainly the following challenges:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: The increasing volume and velocity of data required expensive hardware and software to store and process data. The cost of these solutions made it difficult for organizations to store all their data.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Flexibility&lt;/strong&gt;: The rigid schema-on-write approach made it difficult to accommodate rapidly changing data requirements and the growth of semi-structured and unstructured data types.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These limitations set the stage for the next evolution in analytical data architecture: the &lt;strong&gt;Data Lake&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;data-lakes&quot;&gt;Data Lakes&lt;/h2&gt;

&lt;p&gt;As mentioned, the concept of a data lake emerged as a response to the limitations of traditional data warehouses, which were costly, proprietary, and unable to handle the diverse and voluminous data generated by modern businesses.&lt;/p&gt;

&lt;p&gt;Initially data lakes were almost exclusively implemented on &lt;strong&gt;&lt;em&gt;Hadoop&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Hadoop is an open-source platform that enables the storage and processing of large datasets across distributed computing environments. The original development of Hadoop goes back to 2003 when Google released two papers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Google File System (GFS)&lt;/em&gt;&lt;/strong&gt;: a way to store data across distributed machines&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Google MapReduce&lt;/em&gt;&lt;/strong&gt;: a programming model for distributed data processing on top of GFS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This research paved the way for Yahoo to bootstrap the Hadoop project. Later on, a shift towards modern data lakes appeared that leverages cloud platforms.&lt;/p&gt;

&lt;p&gt;Cloud platforms offer elasticity and cost efficiency especially with the need for data lakes to support a wider range of users and use cases including machine learning.&lt;/p&gt;

&lt;p&gt;While data lakes offer a lot of improvements over data warehouses including enabling organizations to scale their data storage in a more cost-effective way and flexibility with their schema on-read approach, it is also important to note that they also come with challenges.&lt;/p&gt;

&lt;p&gt;Following are some of the key challenges associated with data lakes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data Reliability&lt;/strong&gt;: Data lakes can suffer from reliability issues due to broken data pipelines and the need for continuous reprocessing of missing or corrupted data. This often occurs when write operations fail partially, requiring data engineers to clean up and reprocess the data, which can be time-consuming and resource-intensive.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Quality&lt;/strong&gt;: Ensuring high data quality is a significant challenge in data lakes, as they store raw, unprocessed data that may be inconsistent or incomplete. Poor data quality can negatively impact downstream analytics and decision-making processes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Governance&lt;/strong&gt;: Implementing effective data governance in data lakes is complex due to the variety and volume of data. Ensuring data integrity, security, and compliance with regulations such as GDPR and CCPA is challenging, especially when it comes to deleting or updating data.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Silos&lt;/strong&gt;: Without proper management, data lakes can become data swamps, where data is isolated and inaccessible, leading to the creation of data silos. This hinders collaboration and limits the organization’s ability to extract valuable insights from the data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In an attempt to address these challenges, a common approach organizations ended up deploying was the &lt;strong&gt;Two-Tier Architecture&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;two-tier-architecture-data-warehouse--data-lake&quot;&gt;Two-Tier Architecture: Data Warehouse + Data Lake&lt;/h2&gt;

&lt;p&gt;This architecture involves using a data lake as the first tier for data ingestion and storage, followed by a data warehouse as the second tier for structured analytics and reporting.&lt;/p&gt;

&lt;p&gt;This leverages the cost effective storage and flexibility of the data lake to store the large volumes of raw data. In addition, through ETL processes, data will be moved from the lake to the data warehouse where security, compliance, and optimized performance for analytical queries are ensured.&lt;/p&gt;

&lt;p&gt;This sounds like the perfect combination and the answer to all the previously mentioned challenges. In practice however this has several drawbacks. It results in higher costs because of the redundant data stored across both systems and the maintenance costs of both infrastructures. Also managing two separate systems can be quite complex for users.&lt;/p&gt;

&lt;p&gt;Luckily the evolution did not stop here and the data lakehouse architecture emerged to the rescue which aims to combine the best features of both data warehouses and data lakes but into a single, unified architecture.&lt;/p&gt;

&lt;h2 id=&quot;data-lakehouses&quot;&gt;Data Lakehouses&lt;/h2&gt;

&lt;p&gt;Data Lakehouses combine the best elements of both data lakes and data warehouses.&lt;/p&gt;

&lt;p&gt;They are enabled by a new system design: implementing similar data structures, data management features and ACID transactions to those in a data warehouse directly on top of low cost cloud storage in open file formats of the data lake for flexibility and scale.&lt;/p&gt;

&lt;p&gt;One of the key technology advancements that have enabled the data lakehouse architecture is a &lt;strong&gt;table format&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;what-is-a-table-format&quot;&gt;What is a Table Format?&lt;/h3&gt;

&lt;p&gt;Table format is a metadata layer that allows tools to interact with data lake storage like a traditional database. Since data in a data lake is usually stretched across several files, the metadata layer contains information about which files are part of different table versions to offer rich management features like ACID-compliant transactions.&lt;/p&gt;

&lt;p&gt;In addition, the metadata layers enable other features common in data lakehouses such as:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Schema evolution&lt;/strong&gt;: accommodate data that is changing over time by easily changing a table current’s schema&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Partition evolution&lt;/strong&gt;: allows us to update the partition scheme of a table without having to rewrite all the previous data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Time Travel&lt;/strong&gt;: query a table at previous states&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;open-table-formats&quot;&gt;Open Table Formats&lt;/h3&gt;

&lt;p&gt;Multiple projects have emerged as open source table format technologies to allow community development, drive standardization efforts and avoid vendor lock in. The term open table format gained prominence with the rise of the data lakehouse concept and become a way to collectively refer to these technologies.&lt;/p&gt;

&lt;p&gt;Among these are Apache Iceberg, Apache Hudi, and Databricks Delta Lake.&lt;/p&gt;

&lt;p&gt;The following table summarizes differences between these open table formats and how each has a different approach to supporting common features of data lakehouses.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Apache Iceberg&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Apache Hudi&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Delta Lake&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Origin&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Originated at Netflix and then become part of the Apache Software Foundation&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Originated at Uber and then become part of the Apache Software Foundation&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Developed by Databricks and is now an independent open-source sub-project of the Linux Foundation Projects&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Metadata Layer&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Catalogue&lt;/strong&gt;: maintain a list of existing Iceberg tables and keeps a reference to a table’s current metadata file known as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;metadata.json&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Timeline&lt;/strong&gt;: event log recording all table actions in an ordered manner, with events kept for a specified period.&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Transaction Log&lt;/strong&gt;: Log files similar to Git commits to capture files added and removed from the table since the last commit and Log checkpoints that summarize a group of log files so each individual log file doesn’t have to be read to construct the list of files in the dataset.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Schema Evolution&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;In-place table evolution: schema updates are metadata changes and no data files need to be rewritten to perform the update. Iceberg supports the following schema evolution changes: &lt;ul&gt;&lt;li&gt;&lt;i&gt;Add&lt;/i&gt; -- add a new column to the table or to a nested struct&lt;/li&gt;&lt;li&gt;&lt;i&gt;Drop&lt;/i&gt; -- remove an existing column from the table or a nested struct&lt;/li&gt;&lt;li&gt;&lt;i&gt;Rename&lt;/i&gt; -- rename an existing column or field in a nested struct&lt;/li&gt;&lt;li&gt;&lt;i&gt;Update&lt;/i&gt; -- widen the type of a column, struct field, map key, map value, or list element&lt;/li&gt;&lt;li&gt;&lt;i&gt;Reorder&lt;/i&gt; -- change the order of columns or fields in a nested struct&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Supports schema evolution on write out of the box and an experimental schema evolution on read feature. Schema evolution on write supports backward compatible scenarios such as adding a nullable field, promoting data types or handling missing columns.&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Schema evolution is disabled by default. This is referred to as schema enforcement. You can enable it by:&lt;ul&gt;&lt;li&gt;&lt;i&gt;mergeSchema&lt;/i&gt;: applies for a single write to a single table &lt;/li&gt;&lt;li&gt;&lt;i&gt;autoMerge&lt;/i&gt;: activates schema evolution for writes to any table&lt;/li&gt;&lt;/ul&gt; Delta lake supports the following types of schema changes: &lt;ul&gt;&lt;li&gt;Adding new columns (at arbitrary positions)&lt;/li&gt;&lt;li&gt;Reordering existing columns&lt;/li&gt;&lt;li&gt;Renaming existing columns&lt;/li&gt;&lt;/ul&gt; When attempting to write data with a new schema, Delta Lake compares the new schema with the existing schema stored in the transaction log. It checks if the schema change is compatible and allowed based on the current settings (e.g., if mergeSchema is enabled). If the change is allowed, Delta Lake creates a new transaction that includes:&lt;ul&gt;&lt;li&gt;An &quot;update metadata&quot; action to modify the table's schema&lt;/li&gt;&lt;li&gt;&quot;Add file&quot; actions for the new data files&lt;/li&gt;&lt;/ul&gt; If the transaction is successful, these changes are committed to the transaction log as a new entry. After the commit, the latest table state, including the new schema, is reflected in the next checkpoint file &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Partition Evolution&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Partition evolution is a metadata operation and does not eagerly rewrite files. When you evolve a partition spec, the old data written with an earlier spec remains unchanged. New data is written using the new spec in a new layout. Metadata for each of the partition versions is kept separately.&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Hudi considers partition evolution as anti-pattern and avoids such scheme&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Delta lake does not natively support partition evolution without rewriting the entire table&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Time Travel&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Every change to an Iceberg table creates a new snapshot. Queries can access the table’s list of snapshots to return results from older versions. Queries can be executed using: &lt;ul&gt;&lt;li&gt;specific snapshot id&lt;/li&gt;&lt;li&gt;timestamp when a snapshot was the current at that time&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;The internal timeline log used by Hudi enables time travel queries support using a point in time syntax with timestamps&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Delta lake will inspect the transaction log and figure out which files should be read for each given version. It also supports time travel by timestamp without having to figure out the exact version.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;Table 1: Open Table Formats Comparison&lt;/p&gt;

&lt;p&gt;With this we have reached the end of this post, I hope you enjoyed it!&lt;/p&gt;

&lt;p&gt;If you have any remarks or questions, please don’t hesitate and do drop a comment below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;In this article, we covered the advantages and challenges of different data analytics architecture and how these led to the current development of the data lakehouse concept. In addition, we compared internal structures of open table formats to better understand their importance in enabling the data lakehouse architecture.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Happy learning!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.databricks.com/blog/2021/05/19/evolution-to-the-data-lakehouse.html&quot;&gt;https://www.databricks.com/blog/2021/05/19/evolution-to-the-data-lakehouse.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.dremio.com/blog/exploring-the-architecture-of-apache-iceberg-delta-lake-and-apache-hudi/&quot;&gt;https://www.dremio.com/blog/exploring-the-architecture-of-apache-iceberg-delta-lake-and-apache-hudi/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.dremio.com/blog/comparison-of-data-lake-table-formats-apache-iceberg-apache-hudi-and-delta-lake/&quot;&gt;https://www.dremio.com/blog/comparison-of-data-lake-table-formats-apache-iceberg-apache-hudi-and-delta-lake/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.databricks.com/glossary/data-lakehouse&quot;&gt;https://www.databricks.com/glossary/data-lakehouse&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://hudi.apache.org/docs/hudi_stack&quot;&gt;https://hudi.apache.org/docs/hudi_stack&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://iceberg.apache.org/concepts/catalog/&quot;&gt;https://iceberg.apache.org/concepts/catalog/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.delta.io/latest/delta-intro.html&quot;&gt;https://docs.delta.io/latest/delta-intro.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://delta.io/blog/2023-02-08-delta-lake-schema-evolution/&quot;&gt;https://delta.io/blog/2023-02-08-delta-lake-schema-evolution/&lt;/a&gt;&lt;/p&gt;</content><author><name>Firas Esbai</name></author><category term="articles" /><category term="Data Engineering" /><category term="Data Architecture" /><summary type="html">In this article, we will go through a brief overview of the journey from the foundational data warehouses to the data lakes and up to the emerging concept of the data lakehouse.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" /><media:content medium="image" url="https://www.firasesbai.com/assets/images/default-sep-tag-image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>